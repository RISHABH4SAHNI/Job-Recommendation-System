{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b31c7cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 80\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier\u001b[39;00m\n\u001b[0;32m     79\u001b[0m model \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m---> 80\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m     83\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "data['description'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the 'role_description' and 'description' columns\n",
    "data['job_description'] = data['role_description'] + ' ' + data['description']\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['cleaned_text'] = data['job_description'].apply(preprocess_text)\n",
    "\n",
    "# Skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the cleaned text\n",
    "X = tfidf.fit_transform(data['cleaned_text'])\n",
    "\n",
    "# Encode the skills\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(data['skills'])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a multi-label classifier\n",
    "model = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "hamming = hamming_loss(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Hamming Loss: {hamming}')\n",
    "print(f'F1 Score (Micro): {f1}')\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e8c808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 86\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier\u001b[39;00m\n\u001b[0;32m     85\u001b[0m model \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m---> 86\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m     89\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "data['description'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the 'role_description' and 'description' columns\n",
    "data['job_description'] = data['role_description'] + ' ' + data['description']\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['cleaned_text'] = data['job_description'].apply(preprocess_text)\n",
    "\n",
    "# Skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Remove rows with empty skill sets\n",
    "data = data[data['skills'].map(len) > 0]\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the cleaned text\n",
    "X = tfidf.fit_transform(data['cleaned_text'])\n",
    "\n",
    "# Encode the skills\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(data['skills'])\n",
    "\n",
    "# Check if there are any classes with all zeros and remove them\n",
    "y = y[:, y.sum(axis=0) > 0]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a multi-label classifier\n",
    "model = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "hamming = hamming_loss(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Hamming Loss: {hamming}')\n",
    "print(f'F1 Score (Micro): {f1}')\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e84ac8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        cleaned_text  \\\n",
      "0  looking intern responsibilities responsibiliti...   \n",
      "1  internship job description human resource inte...   \n",
      "2  marketing intern lyskraft integral part market...   \n",
      "3  job description good advanced excel vlookup pi...   \n",
      "4  easyv seeking dynamic enthusiastic product man...   \n",
      "\n",
      "                                              skills  \n",
      "0  [kotlin, jetpack compose, android sdk, firebas...  \n",
      "1  [excel, hr, communication, multitasking, micro...  \n",
      "2  [marketing, social media, content creation, co...  \n",
      "3  [excel, sales, hr, operations, communication, ...  \n",
      "4  [rest, excel, marketing, product management, s...  \n",
      "Class distribution (number of positive samples per class): [  7 124  16   1  13   7   1  13   1  23  99   8   3   6   1   2  87   1\n",
      "  30   2  13  12   1   1   1   5   5   8  21  54  13   3  28   8   5  37\n",
      "   1   8   3  13   8  21 170   9   6  49  29  37   2   4  22  18   1   1\n",
      "   4   3]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 97\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier\u001b[39;00m\n\u001b[0;32m     96\u001b[0m model \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m---> 97\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "data['description'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the 'role_description' and 'description' columns\n",
    "data['job_description'] = data['role_description'] + ' ' + data['description']\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['cleaned_text'] = data['job_description'].apply(preprocess_text)\n",
    "\n",
    "# Skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Print the first few rows to check the extracted skills\n",
    "print(data[['cleaned_text', 'skills']].head())\n",
    "\n",
    "# Remove rows with empty skill sets\n",
    "data = data[data['skills'].map(len) > 0]\n",
    "\n",
    "# Ensure there is more than one class in the target variable\n",
    "if len(data) == 0:\n",
    "    raise ValueError(\"No data available after skill extraction. Please check the skill extraction process.\")\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the cleaned text\n",
    "X = tfidf.fit_transform(data['cleaned_text'])\n",
    "\n",
    "# Encode the skills\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(data['skills'])\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Class distribution (number of positive samples per class):\", y.sum(axis=0))\n",
    "\n",
    "# Ensure each class has more than one sample\n",
    "if len(set(y.sum(axis=0))) == 1:\n",
    "    raise ValueError(\"The data contains only one class. Please ensure there's variability in the skills.\")\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a multi-label classifier\n",
    "model = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "hamming = hamming_loss(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Hamming Loss: {hamming}')\n",
    "print(f'F1 Score (Micro): {f1}')\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eed11b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 88\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier\u001b[39;00m\n\u001b[0;32m     87\u001b[0m model \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m---> 88\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m     91\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "data['description'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the 'role_description' and 'description' columns\n",
    "data['job_description'] = data['role_description'] + ' ' + data['description']\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['cleaned_text'] = data['job_description'].apply(preprocess_text)\n",
    "\n",
    "# Skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Remove rows with empty skill sets\n",
    "data = data[data['skills'].map(len) > 0]\n",
    "\n",
    "# Ensure there are at least two classes present\n",
    "unique_classes = data['skills'].explode().unique()\n",
    "if len(unique_classes) < 2:\n",
    "    raise ValueError(\"There are not enough unique classes present in the data.\")\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the cleaned text\n",
    "X = tfidf.fit_transform(data['cleaned_text'])\n",
    "\n",
    "# Encode the skills\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(data['skills'])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a multi-label classifier\n",
    "model = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "hamming = hamming_loss(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Hamming Loss: {hamming}')\n",
    "print(f'F1 Score (Micro): {f1}')\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c0eb8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes: ['kotlin' 'jetpack compose' 'android sdk' 'firebase' 'rest' 'json' 'proto'\n",
      " 'r' 'excel' 'hr' 'communication' 'multitasking' 'microsoft office' 'ai'\n",
      " 'recruitment' 'marketing' 'social media' 'content creation' 'sales'\n",
      " 'operations' 'product management' 'research' 'problem solving'\n",
      " 'collaboration' 'market research' 'python' 'analytical skills'\n",
      " 'organizational skills' 'inventory management' 'sql' 'data visualization'\n",
      " 'b2b' 'java' 'javascript' 'product marketing' 'project management'\n",
      " 'business development' 'lead generation' 'seo' 'aws' 'logistics'\n",
      " 'procurement' 'supply chain management' 'machine learning' 'tableau'\n",
      " 'power bi' 'react' 'big data' 'agile' 'email marketing' 'cloud computing'\n",
      " 'scrum' 'statistical analysis' 'content strategy' 'tensorflow'\n",
      " 'deep learning']\n",
      "Shape of encoded labels: (170, 56)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 90\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier\u001b[39;00m\n\u001b[0;32m     89\u001b[0m model \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m---> 90\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m     93\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "data['description'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the 'role_description' and 'description' columns\n",
    "data['job_description'] = data['role_description'] + ' ' + data['description']\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['cleaned_text'] = data['job_description'].apply(preprocess_text)\n",
    "\n",
    "# Skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Remove rows with empty skill sets\n",
    "data = data[data['skills'].map(len) > 0]\n",
    "\n",
    "# Ensure there are at least two classes present\n",
    "unique_classes = data['skills'].explode().unique()\n",
    "if len(unique_classes) < 2:\n",
    "    raise ValueError(\"There are not enough unique classes present in the data.\")\n",
    "\n",
    "# Print unique classes and shape of encoded labels\n",
    "print(\"Unique Classes:\", unique_classes)\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(data['skills'])\n",
    "print(\"Shape of encoded labels:\", y.shape)\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the cleaned text\n",
    "X = tfidf.fit_transform(data['cleaned_text'])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a multi-label classifier\n",
    "model = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "hamming = hamming_loss(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Hamming Loss: {hamming}')\n",
    "print(f'F1 Score (Micro): {f1}')\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d5c2efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes (Filtered): ['kotlin' 'jetpack compose' 'android sdk' 'firebase' 'rest' 'json' 'proto'\n",
      " 'r' 'excel' 'hr' 'communication' 'multitasking' 'microsoft office' 'ai'\n",
      " 'recruitment' 'marketing' 'social media' 'content creation' 'sales'\n",
      " 'operations' 'product management' 'research' 'problem solving'\n",
      " 'collaboration' 'market research' 'python' 'analytical skills'\n",
      " 'organizational skills' 'inventory management' 'sql' 'data visualization'\n",
      " 'b2b' 'java' 'javascript' 'product marketing' 'project management'\n",
      " 'business development' 'lead generation' 'seo' 'aws' 'logistics'\n",
      " 'procurement' 'supply chain management' 'machine learning' 'tableau'\n",
      " 'power bi' 'react' 'big data' 'agile' 'email marketing' 'cloud computing'\n",
      " 'scrum' 'statistical analysis' 'content strategy' 'tensorflow'\n",
      " 'deep learning']\n",
      "Shape of encoded labels (Filtered): (170, 56)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 97\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier on filtered data\u001b[39;00m\n\u001b[0;32m     96\u001b[0m model_filtered \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m---> 97\u001b[0m \u001b[43mmodel_filtered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_filtered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_pred_filtered \u001b[38;5;241m=\u001b[39m model_filtered\u001b[38;5;241m.\u001b[39mpredict(X_test_filtered)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "data['description'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the 'role_description' and 'description' columns\n",
    "data['job_description'] = data['role_description'] + ' ' + data['description']\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['cleaned_text'] = data['job_description'].apply(preprocess_text)\n",
    "\n",
    "# Skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Count the number of samples per class\n",
    "class_counts = data['skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data[data['skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering\n",
    "unique_classes_filtered = data_filtered['skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    raise ValueError(\"There are not enough unique classes present in the filtered data.\")\n",
    "\n",
    "# Print unique classes and shape of encoded labels\n",
    "print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_filtered = mlb.fit_transform(data_filtered['skills'])\n",
    "print(\"Shape of encoded labels (Filtered):\", y_filtered.shape)\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the cleaned text\n",
    "X_filtered = tfidf.fit_transform(data_filtered['cleaned_text'])\n",
    "\n",
    "# Split the filtered data into training and test sets\n",
    "X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(\n",
    "    X_filtered, y_filtered, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a multi-label classifier on filtered data\n",
    "model_filtered = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model_filtered.fit(X_train_filtered, y_train_filtered)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_filtered = model_filtered.predict(X_test_filtered)\n",
    "\n",
    "# Calculate evaluation metrics for filtered data\n",
    "hamming_filtered = hamming_loss(y_test_filtered, y_pred_filtered)\n",
    "f1_filtered = f1_score(y_test_filtered, y_pred_filtered, average='micro')\n",
    "accuracy_filtered = accuracy_score(y_test_filtered, y_pred_filtered)\n",
    "\n",
    "print(f'Hamming Loss (Filtered): {hamming_filtered}')\n",
    "print(f'F1 Score (Micro) (Filtered): {f1_filtered}')\n",
    "print(f'Accuracy (Filtered): {accuracy_filtered}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7faec252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes (Filtered): ['kotlin jetpack compose android sdk firebase rest json proto r'\n",
      " 'excel hr communication multitasking microsoft office ai r recruitment'\n",
      " 'marketing social media content creation communication ai r'\n",
      " 'excel sales hr operations communication ai r'\n",
      " 'rest excel marketing product management sales research problem solving communication collaboration ai r market research'\n",
      " 'marketing product management research communication collaboration ai r market research'\n",
      " 'python proto research communication ai r'\n",
      " 'excel marketing sales research operations analytical skills communication organizational skills microsoft office ai r market research inventory management'\n",
      " 'python sql excel data visualization marketing sales hr research problem solving communication ai r sql b2b'\n",
      " 'sales research ai r' 'product management problem solving r'\n",
      " 'excel hr problem solving communication r' 'excel marketing ai r'\n",
      " 'rest excel hr operations communication organizational skills ai r recruitment'\n",
      " 'java javascript analytical skills problem solving ai r'\n",
      " 'excel marketing content creation communication ai r project management'\n",
      " 'marketing sales business development hr communication collaboration ai r lead generation'\n",
      " 'rest excel data visualization marketing social media seo content creation sales research problem solving communication microsoft office ai r lead generation b2b market research product marketing'\n",
      " 'excel marketing sales hr communication ai r' 'excel r'\n",
      " 'rest aws excel marketing hr research communication ai r market research logistics'\n",
      " 'sql excel sales operations problem solving communication ai r sql logistics procurement inventory management'\n",
      " 'excel marketing sales hr research problem solving communication microsoft office ai r lead generation market research'\n",
      " 'sql excel operations problem solving communication ai r sql'\n",
      " 'rest excel communication ai r supply chain management'\n",
      " 'excel analytical skills problem solving communication ai r'\n",
      " 'excel sales communication r'\n",
      " 'python sql excel data visualization sales communication collaboration ai machine learning r sql tableau power bi'\n",
      " 'python sql excel ai machine learning r sql'\n",
      " 'java proto javascript aws excel product management hr research communication ai r'\n",
      " 'excel marketing social media communication ai r lead generation'\n",
      " 'sales research analytical skills communication ai r'\n",
      " 'java javascript react problem solving communication r'\n",
      " 'marketing social media content creation research analytical skills communication ai r market research'\n",
      " 'hr r' 'sales r' 'excel marketing social media communication ai r'\n",
      " 'python ai r' 'excel sales problem solving communication r'\n",
      " 'python java sql aws operations ai big data r sql'\n",
      " 'marketing social media r' 'excel marketing sales communication ai r'\n",
      " 'sales hr research communication r market research'\n",
      " 'excel research operations ai r tableau power bi'\n",
      " 'marketing sales research communication ai r market research'\n",
      " 'excel marketing business development hr research operations analytical skills communication collaboration microsoft office ai r market research'\n",
      " 'python java sql javascript react collaboration r sql' 'marketing r' 'r'\n",
      " 'communication ai r'\n",
      " 'excel marketing sales business development hr communication ai r'\n",
      " 'rest excel hr research communication microsoft office ai r'\n",
      " 'excel analytical skills problem solving communication collaboration r agile'\n",
      " 'excel marketing social media hr research communication collaboration ai r email marketing'\n",
      " 'rest excel marketing social media business development hr research communication ai r'\n",
      " 'excel marketing hr research collaboration ai r lead generation b2b project management'\n",
      " 'excel marketing hr operations communication collaboration multitasking ai r logistics'\n",
      " 'python java javascript aws ai r'\n",
      " 'rest excel marketing social media hr research ai r email marketing'\n",
      " 'business development r' 'python java javascript ai r'\n",
      " 'python aws excel operations problem solving communication collaboration ai machine learning r'\n",
      " 'sql excel problem solving communication ai r sql power bi'\n",
      " 'python sql cloud computing aws excel react hr problem solving communication ai r sql agile scrum'\n",
      " 'excel marketing social media sales research analytical skills communication microsoft office ai r market research'\n",
      " 'operations r'\n",
      " 'excel business development hr operations analytical skills communication ai r'\n",
      " 'sql excel data visualization analytical skills communication ai r sql tableau power bi'\n",
      " 'python research problem solving ai r'\n",
      " 'statistical analysis r tableau power bi' 'sql r sql'\n",
      " 'rest excel hr communication organizational skills ai r recruitment'\n",
      " 'excel research operations analytical skills communication ai r'\n",
      " 'excel operations communication organizational skills ai r project management'\n",
      " 'marketing sales business development research operations problem solving communication ai r market research'\n",
      " 'rest excel react product management hr analytical skills problem solving communication collaboration ai r'\n",
      " 'excel research problem solving communication ai r' 'r agile scrum'\n",
      " 'marketing r b2b' 'operations communication ai r'\n",
      " 'proto communication ai r agile'\n",
      " 'excel sales communication collaboration ai r'\n",
      " 'rest marketing sales communication ai r'\n",
      " 'excel sales hr communication ai r' 'research collaboration ai r b2b'\n",
      " 'rest excel marketing social media seo content creation research communication ai r content strategy'\n",
      " 'python java sql javascript aws react operations problem solving ai r sql b2b'\n",
      " 'excel marketing social media sales business development hr communication organizational skills ai r'\n",
      " 'rest marketing social media sales hr research communication microsoft office ai r market research'\n",
      " 'aws excel marketing social media hr ai r content strategy'\n",
      " 'proto hr collaboration ai r'\n",
      " 'excel business development communication ai r'\n",
      " 'excel communication microsoft office ai r agile'\n",
      " 'sql excel hr problem solving communication ai r sql'\n",
      " 'excel marketing social media content creation research ai r'\n",
      " 'rest excel marketing social media communication collaboration ai r'\n",
      " 'sql excel hr communication ai r sql project management agile'\n",
      " 'excel research problem solving communication r market research'\n",
      " 'excel hr operations ai r recruitment' 'excel communication ai r'\n",
      " 'python research problem solving communication ai r' 'ai r'\n",
      " 'rest excel hr research operations analytical skills communication microsoft office ai r market research'\n",
      " 'aws excel marketing sales business development hr communication collaboration organizational skills ai r b2b'\n",
      " 'excel analytical skills problem solving ai r project management logistics'\n",
      " 'proto aws communication ai r project management'\n",
      " 'java rest javascript research ai r'\n",
      " 'excel marketing research communication microsoft office ai r market research project management'\n",
      " 'java sql javascript r sql'\n",
      " 'rest excel marketing sales hr research operations communication collaboration ai r'\n",
      " 'excel problem solving communication ai r project management'\n",
      " 'python problem solving ai machine learning tensorflow r'\n",
      " 'java javascript excel react hr problem solving communication collaboration ai r'\n",
      " 'rest ai r' 'excel research analytical skills communication r'\n",
      " 'rest hr r' 'rest proto research r' 'react r'\n",
      " 'aws excel data visualization hr research operations problem solving communication collaboration ai r market research project management'\n",
      " 'research r' 'rest excel r' 'python sql aws ai r sql'\n",
      " 'marketing business development hr communication r'\n",
      " 'marketing sales business development communication ai r'\n",
      " 'excel sales problem solving communication collaboration ai machine learning r agile'\n",
      " 'react problem solving communication ai r' 'rest hr ai r'\n",
      " 'hr organizational skills microsoft office ai r recruitment'\n",
      " 'python research ai machine learning deep learning tensorflow r'\n",
      " 'marketing sales r'\n",
      " 'excel marketing seo problem solving communication ai r'\n",
      " 'rest excel hr research operations communication ai r project management'\n",
      " 'rest sales research ai r market research'\n",
      " 'aws excel marketing business development hr communication collaboration ai r content strategy'\n",
      " 'excel marketing social media content creation communication ai r'\n",
      " 'excel marketing product management sales hr research communication ai r market research project management'\n",
      " 'marketing social media research communication ai r market research'\n",
      " 'marketing sales operations communication r product marketing logistics'\n",
      " 'sql excel data visualization operations analytical skills communication ai r sql'\n",
      " 'rest marketing product management sales research operations ai r project management'\n",
      " 'hr communication ai r'\n",
      " 'rest excel hr operations communication organizational skills multitasking microsoft office ai r recruitment'\n",
      " 'excel product management operations communication ai r project management'\n",
      " 'problem solving r' 'marketing social media seo content creation ai r'\n",
      " 'python java rest javascript excel problem solving ai r'\n",
      " 'excel operations problem solving communication ai r'\n",
      " 'rest marketing social media hr communication collaboration ai r']\n",
      "Shape of encoded labels (Filtered): (170, 28)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 99\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier on filtered data\u001b[39;00m\n\u001b[0;32m     98\u001b[0m model_filtered \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m---> 99\u001b[0m \u001b[43mmodel_filtered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_filtered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m    102\u001b[0m y_pred_filtered \u001b[38;5;241m=\u001b[39m model_filtered\u001b[38;5;241m.\u001b[39mpredict(X_test_filtered)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "data['description'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the 'role_description' and 'description' columns\n",
    "data['job_description'] = data['role_description'] + ' ' + data['description']\n",
    "\n",
    "# List of skills\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function for text cleaning and skills extraction\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return ' '.join(extracted_skills)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['extracted_skills'] = data['job_description'].apply(preprocess_text)\n",
    "\n",
    "# Filter out samples without extracted skills\n",
    "data_filtered = data[data['extracted_skills'].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "# Count the number of samples per class\n",
    "class_counts = data_filtered['extracted_skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data_filtered[data_filtered['extracted_skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering\n",
    "unique_classes_filtered = data_filtered['extracted_skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    raise ValueError(\"There are not enough unique classes present in the filtered data.\")\n",
    "\n",
    "# Print unique classes and shape of encoded labels\n",
    "print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_filtered = mlb.fit_transform(data_filtered['extracted_skills'])\n",
    "print(\"Shape of encoded labels (Filtered):\", y_filtered.shape)\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the cleaned text\n",
    "X_text_filtered = tfidf.fit_transform(data_filtered['extracted_skills'])\n",
    "\n",
    "# Convert skills list into a binary vector representation\n",
    "skills_vector = np.array([[1 if skill in skills else 0 for skill in skills_list] for skills in data_filtered['extracted_skills']])\n",
    "\n",
    "# Concatenate TF-IDF vector and skills vector\n",
    "X_filtered = np.hstack((X_text_filtered.toarray(), skills_vector))\n",
    "\n",
    "# Split the filtered data into training and test sets\n",
    "X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(\n",
    "    X_filtered, y_filtered, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a multi-label classifier on filtered data\n",
    "model_filtered = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model_filtered.fit(X_train_filtered, y_train_filtered)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_filtered = model_filtered.predict(X_test_filtered)\n",
    "\n",
    "# Calculate evaluation metrics for filtered data\n",
    "hamming_filtered = hamming_loss(y_test_filtered, y_pred_filtered)\n",
    "f1_filtered = f1_score(y_test_filtered, y_pred_filtered, average='micro')\n",
    "accuracy_filtered = accuracy_score(y_test_filtered, y_pred_filtered)\n",
    "\n",
    "print(f'Hamming Loss (Filtered): {hamming_filtered}')\n",
    "print(f'F1 Score (Micro) (Filtered): {f1_filtered}')\n",
    "print(f'Accuracy (Filtered): {accuracy_filtered}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a94a3ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes (Filtered): ['kotlin jetpack compose android sdk firebase rest json proto r'\n",
      " 'excel hr communication multitasking microsoft office ai r recruitment'\n",
      " 'marketing social media content creation communication ai r'\n",
      " 'excel sales hr operations communication ai r'\n",
      " 'rest excel marketing product management sales research problem solving communication collaboration ai r market research'\n",
      " 'marketing product management research communication collaboration ai r market research'\n",
      " 'python proto research communication ai r'\n",
      " 'excel marketing sales research operations analytical skills communication organizational skills microsoft office ai r market research inventory management'\n",
      " 'python sql excel data visualization marketing sales hr research problem solving communication ai r sql b2b'\n",
      " 'sales research ai r' 'product management problem solving r'\n",
      " 'excel hr problem solving communication r' 'excel marketing ai r'\n",
      " 'rest excel hr operations communication organizational skills ai r recruitment'\n",
      " 'java javascript analytical skills problem solving ai r'\n",
      " 'excel marketing content creation communication ai r project management'\n",
      " 'marketing sales business development hr communication collaboration ai r lead generation'\n",
      " 'rest excel data visualization marketing social media seo content creation sales research problem solving communication microsoft office ai r lead generation b2b market research product marketing'\n",
      " 'excel marketing sales hr communication ai r' 'excel r'\n",
      " 'rest aws excel marketing hr research communication ai r market research logistics'\n",
      " 'sql excel sales operations problem solving communication ai r sql logistics procurement inventory management'\n",
      " 'excel marketing sales hr research problem solving communication microsoft office ai r lead generation market research'\n",
      " 'sql excel operations problem solving communication ai r sql'\n",
      " 'rest excel communication ai r supply chain management'\n",
      " 'excel analytical skills problem solving communication ai r'\n",
      " 'excel sales communication r'\n",
      " 'python sql excel data visualization sales communication collaboration ai machine learning r sql tableau power bi'\n",
      " 'python sql excel ai machine learning r sql'\n",
      " 'java proto javascript aws excel product management hr research communication ai r'\n",
      " 'excel marketing social media communication ai r lead generation'\n",
      " 'sales research analytical skills communication ai r'\n",
      " 'java javascript react problem solving communication r'\n",
      " 'marketing social media content creation research analytical skills communication ai r market research'\n",
      " 'hr r' 'sales r' 'excel marketing social media communication ai r'\n",
      " 'python ai r' 'excel sales problem solving communication r'\n",
      " 'python java sql aws operations ai big data r sql'\n",
      " 'marketing social media r' 'excel marketing sales communication ai r'\n",
      " 'sales hr research communication r market research'\n",
      " 'excel research operations ai r tableau power bi'\n",
      " 'marketing sales research communication ai r market research'\n",
      " 'excel marketing business development hr research operations analytical skills communication collaboration microsoft office ai r market research'\n",
      " 'python java sql javascript react collaboration r sql' 'marketing r' 'r'\n",
      " 'communication ai r'\n",
      " 'excel marketing sales business development hr communication ai r'\n",
      " 'rest excel hr research communication microsoft office ai r'\n",
      " 'excel analytical skills problem solving communication collaboration r agile'\n",
      " 'excel marketing social media hr research communication collaboration ai r email marketing'\n",
      " 'rest excel marketing social media business development hr research communication ai r'\n",
      " 'excel marketing hr research collaboration ai r lead generation b2b project management'\n",
      " 'excel marketing hr operations communication collaboration multitasking ai r logistics'\n",
      " 'python java javascript aws ai r'\n",
      " 'rest excel marketing social media hr research ai r email marketing'\n",
      " 'business development r' 'python java javascript ai r'\n",
      " 'python aws excel operations problem solving communication collaboration ai machine learning r'\n",
      " 'sql excel problem solving communication ai r sql power bi'\n",
      " 'python sql cloud computing aws excel react hr problem solving communication ai r sql agile scrum'\n",
      " 'excel marketing social media sales research analytical skills communication microsoft office ai r market research'\n",
      " 'operations r'\n",
      " 'excel business development hr operations analytical skills communication ai r'\n",
      " 'sql excel data visualization analytical skills communication ai r sql tableau power bi'\n",
      " 'python research problem solving ai r'\n",
      " 'statistical analysis r tableau power bi' 'sql r sql'\n",
      " 'rest excel hr communication organizational skills ai r recruitment'\n",
      " 'excel research operations analytical skills communication ai r'\n",
      " 'excel operations communication organizational skills ai r project management'\n",
      " 'marketing sales business development research operations problem solving communication ai r market research'\n",
      " 'rest excel react product management hr analytical skills problem solving communication collaboration ai r'\n",
      " 'excel research problem solving communication ai r' 'r agile scrum'\n",
      " 'marketing r b2b' 'operations communication ai r'\n",
      " 'proto communication ai r agile'\n",
      " 'excel sales communication collaboration ai r'\n",
      " 'rest marketing sales communication ai r'\n",
      " 'excel sales hr communication ai r' 'research collaboration ai r b2b'\n",
      " 'rest excel marketing social media seo content creation research communication ai r content strategy'\n",
      " 'python java sql javascript aws react operations problem solving ai r sql b2b'\n",
      " 'excel marketing social media sales business development hr communication organizational skills ai r'\n",
      " 'rest marketing social media sales hr research communication microsoft office ai r market research'\n",
      " 'aws excel marketing social media hr ai r content strategy'\n",
      " 'proto hr collaboration ai r'\n",
      " 'excel business development communication ai r'\n",
      " 'excel communication microsoft office ai r agile'\n",
      " 'sql excel hr problem solving communication ai r sql'\n",
      " 'excel marketing social media content creation research ai r'\n",
      " 'rest excel marketing social media communication collaboration ai r'\n",
      " 'sql excel hr communication ai r sql project management agile'\n",
      " 'excel research problem solving communication r market research'\n",
      " 'excel hr operations ai r recruitment' 'excel communication ai r'\n",
      " 'python research problem solving communication ai r' 'ai r'\n",
      " 'rest excel hr research operations analytical skills communication microsoft office ai r market research'\n",
      " 'aws excel marketing sales business development hr communication collaboration organizational skills ai r b2b'\n",
      " 'excel analytical skills problem solving ai r project management logistics'\n",
      " 'proto aws communication ai r project management'\n",
      " 'java rest javascript research ai r'\n",
      " 'excel marketing research communication microsoft office ai r market research project management'\n",
      " 'java sql javascript r sql'\n",
      " 'rest excel marketing sales hr research operations communication collaboration ai r'\n",
      " 'excel problem solving communication ai r project management'\n",
      " 'python problem solving ai machine learning tensorflow r'\n",
      " 'java javascript excel react hr problem solving communication collaboration ai r'\n",
      " 'rest ai r' 'excel research analytical skills communication r'\n",
      " 'rest hr r' 'rest proto research r' 'react r'\n",
      " 'aws excel data visualization hr research operations problem solving communication collaboration ai r market research project management'\n",
      " 'research r' 'rest excel r' 'python sql aws ai r sql'\n",
      " 'marketing business development hr communication r'\n",
      " 'marketing sales business development communication ai r'\n",
      " 'excel sales problem solving communication collaboration ai machine learning r agile'\n",
      " 'react problem solving communication ai r' 'rest hr ai r'\n",
      " 'hr organizational skills microsoft office ai r recruitment'\n",
      " 'python research ai machine learning deep learning tensorflow r'\n",
      " 'marketing sales r'\n",
      " 'excel marketing seo problem solving communication ai r'\n",
      " 'rest excel hr research operations communication ai r project management'\n",
      " 'rest sales research ai r market research'\n",
      " 'aws excel marketing business development hr communication collaboration ai r content strategy'\n",
      " 'excel marketing social media content creation communication ai r'\n",
      " 'excel marketing product management sales hr research communication ai r market research project management'\n",
      " 'marketing social media research communication ai r market research'\n",
      " 'marketing sales operations communication r product marketing logistics'\n",
      " 'sql excel data visualization operations analytical skills communication ai r sql'\n",
      " 'rest marketing product management sales research operations ai r project management'\n",
      " 'hr communication ai r'\n",
      " 'rest excel hr operations communication organizational skills multitasking microsoft office ai r recruitment'\n",
      " 'excel product management operations communication ai r project management'\n",
      " 'problem solving r' 'marketing social media seo content creation ai r'\n",
      " 'python java rest javascript excel problem solving ai r'\n",
      " 'excel operations problem solving communication ai r'\n",
      " 'rest marketing social media hr communication collaboration ai r']\n",
      "Shape of encoded labels (Filtered): (170, 28)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [162, 170]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 97\u001b[0m\n\u001b[0;32m     94\u001b[0m X_filtered \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack((X_text_filtered\u001b[38;5;241m.\u001b[39mtoarray(), skills_vector))\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Split the filtered data into training and test sets\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier on filtered data\u001b[39;00m\n\u001b[0;32m    101\u001b[0m model_filtered \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2559\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2559\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2561\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2562\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2564\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \n\u001b[0;32m    426\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 443\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [162, 170]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "data['description'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the 'role_description' and 'description' columns\n",
    "data['job_description'] = data['role_description'] + ' ' + data['description']\n",
    "\n",
    "# List of skills\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function for text cleaning and skills extraction\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return ' '.join(extracted_skills)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['extracted_skills'] = data['job_description'].apply(preprocess_text)\n",
    "\n",
    "# Filter out samples without extracted skills\n",
    "data_filtered = data[data['extracted_skills'].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "# Count the number of samples per class\n",
    "class_counts = data_filtered['extracted_skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data_filtered[data_filtered['extracted_skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering\n",
    "unique_classes_filtered = data_filtered['extracted_skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    raise ValueError(\"There are not enough unique classes present in the filtered data.\")\n",
    "\n",
    "# Print unique classes and shape of encoded labels\n",
    "print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_filtered = mlb.fit_transform(data_filtered['extracted_skills'])\n",
    "print(\"Shape of encoded labels (Filtered):\", y_filtered.shape)\n",
    "\n",
    "# Filter out samples with only one class\n",
    "samples_with_multiple_classes = data_filtered[data_filtered['extracted_skills'].apply(lambda x: len(x.split()) > 1)]\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the cleaned text\n",
    "X_text_filtered = tfidf.fit_transform(samples_with_multiple_classes['extracted_skills'])\n",
    "\n",
    "# Convert skills list into a binary vector representation\n",
    "skills_vector = np.array([[1 if skill in skills else 0 for skill in skills_list] for skills in samples_with_multiple_classes['extracted_skills']])\n",
    "\n",
    "# Concatenate TF-IDF vector and skills vector\n",
    "X_filtered = np.hstack((X_text_filtered.toarray(), skills_vector))\n",
    "\n",
    "# Split the filtered data into training and test sets\n",
    "X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(\n",
    "    X_filtered, y_filtered, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a multi-label classifier on filtered data\n",
    "model_filtered = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model_filtered.fit(X_train_filtered, y_train_filtered)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_filtered = model_filtered.predict(X_test_filtered)\n",
    "\n",
    "# Calculate evaluation metrics for filtered data\n",
    "hamming_filtered = hamming_loss(y_test_filtered, y_pred_filtered)\n",
    "f1_filtered = f1_score(y_test_filtered, y_pred_filtered, average='micro')\n",
    "accuracy_filtered = accuracy_score(y_test_filtered, y_pred_filtered)\n",
    "\n",
    "print(f'Hamming Loss (Filtered): {hamming_filtered}')\n",
    "print(f'F1 Score (Micro) (Filtered): {f1_filtered}')\n",
    "print(f'Accuracy (Filtered): {accuracy_filtered}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a02729c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_text_filtered: (162, 70)\n",
      "Shape of skills_vector: (162, 68)\n",
      "Shape of y_filtered: (170, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_text_filtered:\", X_text_filtered.shape)\n",
    "print(\"Shape of skills_vector:\", skills_vector.shape)\n",
    "print(\"Shape of y_filtered:\", y_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61dc2233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes (Filtered): ['kotlin' 'jetpack compose' 'android sdk' 'firebase' 'rest' 'json' 'proto'\n",
      " 'r' 'excel' 'hr' 'communication' 'multitasking' 'microsoft office' 'ai'\n",
      " 'recruitment' 'marketing' 'social media' 'content creation' 'sales'\n",
      " 'operations' 'product management' 'research' 'problem solving'\n",
      " 'collaboration' 'market research' 'python' 'analytical skills'\n",
      " 'organizational skills' 'inventory management' 'sql' 'data visualization'\n",
      " 'b2b' 'java' 'javascript' 'product marketing' 'project management'\n",
      " 'business development' 'lead generation' 'seo' 'aws' 'logistics'\n",
      " 'procurement' 'supply chain management' 'machine learning' 'tableau'\n",
      " 'power bi' 'react' 'big data' 'agile' 'email marketing' 'cloud computing'\n",
      " 'scrum' 'statistical analysis' 'content strategy' 'tensorflow'\n",
      " 'deep learning']\n",
      "Shape of encoded labels (Filtered): (170, 56)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 106\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier on filtered data\u001b[39;00m\n\u001b[0;32m    105\u001b[0m model_filtered \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m--> 106\u001b[0m \u001b[43mmodel_filtered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_filtered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m    109\u001b[0m y_pred_filtered \u001b[38;5;241m=\u001b[39m model_filtered\u001b[38;5;241m.\u001b[39mpredict(X_test_filtered)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "data['description'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the 'role_description' and 'description' columns\n",
    "data['job_description'] = data['role_description'] + ' ' + data['description']\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['cleaned_text'] = data['job_description'].apply(preprocess_text)\n",
    "\n",
    "# Skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Count the number of samples per class\n",
    "class_counts = data['skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data[data['skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering\n",
    "unique_classes_filtered = data_filtered['skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    raise ValueError(\"There are not enough unique classes present in the filtered data.\")\n",
    "\n",
    "# Print unique classes and shape of encoded labels\n",
    "print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_filtered = mlb.fit_transform(data_filtered['skills'])\n",
    "print(\"Shape of encoded labels (Filtered):\", y_filtered.shape)\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the cleaned text\n",
    "X_text_filtered = tfidf.fit_transform(data_filtered['cleaned_text'])\n",
    "\n",
    "# Concatenate TF-IDF features and skills vector\n",
    "skills_vector = np.zeros((X_text_filtered.shape[0], len(skills_list)), dtype=int)\n",
    "for i, skills in enumerate(data_filtered['skills']):\n",
    "    for skill in skills:\n",
    "        skills_vector[i, skills_list.index(skill)] = 1\n",
    "\n",
    "X_filtered = np.hstack((X_text_filtered.toarray(), skills_vector))\n",
    "\n",
    "# Split the filtered data into training and test sets\n",
    "X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(\n",
    "    X_filtered, y_filtered, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a multi-label classifier on filtered data\n",
    "model_filtered = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model_filtered.fit(X_train_filtered, y_train_filtered)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_filtered = model_filtered.predict(X_test_filtered)\n",
    "\n",
    "# Calculate evaluation metrics for filtered data\n",
    "hamming_filtered = hamming_loss(y_test_filtered, y_pred_filtered)\n",
    "f1_filtered = f1_score(y_test_filtered, y_pred_filtered, average='micro')\n",
    "accuracy_filtered = accuracy_score(y_test_filtered, y_pred_filtered)\n",
    "\n",
    "print(f'Hamming Loss (Filtered): {hamming_filtered}')\n",
    "print(f'F1 Score (Micro) (Filtered): {f1_filtered}')\n",
    "print(f'Accuracy (Filtered): {accuracy_filtered}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c6de0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes (Filtered): ['kotlin' 'jetpack compose' 'android sdk' 'firebase' 'rest' 'json' 'proto'\n",
      " 'r' 'excel' 'hr' 'communication' 'multitasking' 'microsoft office' 'ai'\n",
      " 'recruitment' 'marketing' 'social media' 'content creation' 'sales'\n",
      " 'operations' 'product management' 'research' 'problem solving'\n",
      " 'collaboration' 'market research' 'python' 'analytical skills'\n",
      " 'organizational skills' 'inventory management' 'sql' 'data visualization'\n",
      " 'b2b' 'java' 'javascript' 'product marketing' 'project management'\n",
      " 'business development' 'lead generation' 'seo' 'aws' 'logistics'\n",
      " 'procurement' 'supply chain management' 'machine learning' 'tableau'\n",
      " 'power bi' 'react' 'big data' 'agile' 'email marketing' 'cloud computing'\n",
      " 'scrum' 'statistical analysis' 'content strategy' 'tensorflow'\n",
      " 'deep learning']\n",
      "Shape of encoded labels (Filtered): (170, 56)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 106\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier on filtered data\u001b[39;00m\n\u001b[0;32m    105\u001b[0m model_filtered \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m--> 106\u001b[0m \u001b[43mmodel_filtered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_filtered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m    109\u001b[0m y_pred_filtered \u001b[38;5;241m=\u001b[39m model_filtered\u001b[38;5;241m.\u001b[39mpredict(X_test_filtered)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "data['description'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the 'role_description' and 'description' columns\n",
    "data['job_description'] = data['role_description'] + ' ' + data['description']\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['cleaned_text'] = data['job_description'].apply(preprocess_text)\n",
    "\n",
    "# Skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Count the number of samples per class\n",
    "class_counts = data['skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data[data['skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering\n",
    "unique_classes_filtered = data_filtered['skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    raise ValueError(\"There are not enough unique classes present in the filtered data.\")\n",
    "\n",
    "# Print unique classes and shape of encoded labels\n",
    "print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "mlb = MultiLabelBinarizer(classes=unique_classes_filtered)\n",
    "y_filtered = mlb.fit_transform(data_filtered['skills'])\n",
    "print(\"Shape of encoded labels (Filtered):\", y_filtered.shape)\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the cleaned text\n",
    "X_text_filtered = tfidf.fit_transform(data_filtered['cleaned_text'])\n",
    "\n",
    "# Concatenate TF-IDF features and skills vector\n",
    "skills_vector = np.zeros((X_text_filtered.shape[0], len(unique_classes_filtered)), dtype=int)\n",
    "for i, skills in enumerate(data_filtered['skills']):\n",
    "    for skill in skills:\n",
    "        skills_vector[i, np.where(unique_classes_filtered == skill)[0][0]] = 1\n",
    "\n",
    "X_filtered = np.hstack((X_text_filtered.toarray(), skills_vector))\n",
    "\n",
    "# Split the filtered data into training and test sets\n",
    "X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(\n",
    "    X_filtered, y_filtered, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a multi-label classifier on filtered data\n",
    "model_filtered = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model_filtered.fit(X_train_filtered, y_train_filtered)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_filtered = model_filtered.predict(X_test_filtered)\n",
    "\n",
    "# Calculate evaluation metrics for filtered data\n",
    "hamming_filtered = hamming_loss(y_test_filtered, y_pred_filtered)\n",
    "f1_filtered = f1_score(y_test_filtered, y_pred_filtered, average='micro')\n",
    "accuracy_filtered = accuracy_score(y_test_filtered, y_pred_filtered)\n",
    "\n",
    "print(f'Hamming Loss (Filtered): {hamming_filtered}')\n",
    "print(f'F1 Score (Micro) (Filtered): {f1_filtered}')\n",
    "print(f'Accuracy (Filtered): {accuracy_filtered}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f1bcdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes (Filtered): ['kotlin' 'jetpack compose' 'android sdk' 'firebase' 'rest' 'json' 'proto'\n",
      " 'r' 'excel' 'hr' 'communication' 'multitasking' 'microsoft office' 'ai'\n",
      " 'recruitment' 'marketing' 'social media' 'content creation' 'sales'\n",
      " 'operations' 'product management' 'research' 'problem solving'\n",
      " 'collaboration' 'market research' 'python' 'analytical skills'\n",
      " 'organizational skills' 'inventory management' 'sql' 'data visualization'\n",
      " 'b2b' 'java' 'javascript' 'product marketing' 'project management'\n",
      " 'business development' 'lead generation' 'seo' 'aws' 'logistics'\n",
      " 'procurement' 'supply chain management' 'machine learning' 'tableau'\n",
      " 'power bi' 'react' 'big data' 'agile' 'email marketing' 'cloud computing'\n",
      " 'scrum' 'statistical analysis' 'content strategy' 'tensorflow'\n",
      " 'deep learning']\n",
      "Shape of encoded labels (Filtered): (170, 56)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 114\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier on filtered data\u001b[39;00m\n\u001b[0;32m    113\u001b[0m model_filtered \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m--> 114\u001b[0m \u001b[43mmodel_filtered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_filtered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m    117\u001b[0m y_pred_filtered \u001b[38;5;241m=\u001b[39m model_filtered\u001b[38;5;241m.\u001b[39mpredict(X_test_filtered)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "data['description'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the 'role_description' and 'description' columns\n",
    "data['job_description'] = data['role_description'] + ' ' + data['description']\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['cleaned_text'] = data['job_description'].apply(preprocess_text)\n",
    "\n",
    "# Skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Count the number of samples per class\n",
    "class_counts = data['skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data[data['skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Ensure each class has at least two samples\n",
    "min_class_samples = 2\n",
    "class_counts_filtered = data_filtered['skills'].explode().value_counts()\n",
    "valid_classes_filtered = class_counts_filtered[class_counts_filtered >= min_class_samples].index\n",
    "\n",
    "# Filter data again to keep only samples with valid classes\n",
    "data_filtered = data_filtered[data_filtered['skills'].apply(lambda x: any(skill in valid_classes_filtered for skill in x))]\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering again\n",
    "unique_classes_filtered = data_filtered['skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    raise ValueError(\"There are not enough unique classes present in the filtered data after removing classes with fewer than two samples.\")\n",
    "\n",
    "# Print unique classes and shape of encoded labels again\n",
    "print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "mlb = MultiLabelBinarizer(classes=unique_classes_filtered)\n",
    "y_filtered = mlb.fit_transform(data_filtered['skills'])\n",
    "print(\"Shape of encoded labels (Filtered):\", y_filtered.shape)\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the cleaned text\n",
    "X_text_filtered = tfidf.fit_transform(data_filtered['cleaned_text'])\n",
    "\n",
    "# Concatenate TF-IDF features and skills vector\n",
    "skills_vector = np.zeros((X_text_filtered.shape[0], len(skills_list)), dtype=int)\n",
    "for i, skills in enumerate(data_filtered['skills']):\n",
    "    for skill in skills:\n",
    "        skills_vector[i, skills_list.index(skill)] = 1\n",
    "\n",
    "X_filtered = np.hstack((X_text_filtered.toarray(), skills_vector))\n",
    "\n",
    "# Split the filtered data into training and test sets\n",
    "X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(\n",
    "    X_filtered, y_filtered, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a multi-label classifier on filtered data\n",
    "model_filtered = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model_filtered.fit(X_train_filtered, y_train_filtered)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_filtered = model_filtered.predict(X_test_filtered)\n",
    "\n",
    "# Calculate evaluation metrics for filtered data\n",
    "hamming_filtered = hamming_loss(y_test_filtered, y_pred_filtered)\n",
    "f1_filtered = f1_score(y_test_filtered, y_pred_filtered, average='micro')\n",
    "accuracy_filtered = accuracy_score(y_test_filtered, y_pred_filtered)\n",
    "\n",
    "print(f'Hamming Loss (Filtered): {hamming_filtered}')\n",
    "print(f'F1 Score (Micro) (Filtered): {f1_filtered}')\n",
    "print(f'Accuracy (Filtered): {accuracy_filtered}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbd9ba23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes (Filtered): ['kotlin' 'jetpack compose' 'android sdk' 'firebase' 'rest' 'json' 'proto'\n",
      " 'r' 'excel' 'hr' 'communication' 'multitasking' 'microsoft office' 'ai'\n",
      " 'recruitment' 'marketing' 'social media' 'content creation' 'sales'\n",
      " 'operations' 'product management' 'research' 'problem solving'\n",
      " 'collaboration' 'market research' 'python' 'analytical skills'\n",
      " 'organizational skills' 'inventory management' 'sql' 'data visualization'\n",
      " 'b2b' 'java' 'javascript' 'product marketing' 'project management'\n",
      " 'business development' 'lead generation' 'seo' 'aws' 'logistics'\n",
      " 'procurement' 'supply chain management' 'machine learning' 'tableau'\n",
      " 'power bi' 'react' 'big data' 'agile' 'email marketing' 'cloud computing'\n",
      " 'scrum' 'statistical analysis' 'content strategy' 'tensorflow'\n",
      " 'deep learning']\n",
      "Shape of encoded labels (Filtered): (161, 56)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 109\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier on filtered data\u001b[39;00m\n\u001b[0;32m    108\u001b[0m model_filtered \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m--> 109\u001b[0m \u001b[43mmodel_filtered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_filtered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m    112\u001b[0m y_pred_filtered \u001b[38;5;241m=\u001b[39m model_filtered\u001b[38;5;241m.\u001b[39mpredict(X_test_filtered)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "data['description'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the 'role_description' and 'description' columns\n",
    "data['job_description'] = data['role_description'] + ' ' + data['description']\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['cleaned_text'] = data['job_description'].apply(preprocess_text)\n",
    "\n",
    "# Skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Count the number of samples per class\n",
    "class_counts = data['skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data[data['skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Remove samples belonging to classes with only one sample\n",
    "data_filtered = data_filtered[data_filtered['skills'].apply(lambda x: len(x) > 1)]\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering again\n",
    "unique_classes_filtered = data_filtered['skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    raise ValueError(\"There are not enough unique classes present in the filtered data after removing classes with fewer than two samples.\")\n",
    "\n",
    "# Print unique classes and shape of encoded labels\n",
    "print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_filtered = mlb.fit_transform(data_filtered['skills'])\n",
    "print(\"Shape of encoded labels (Filtered):\", y_filtered.shape)\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the cleaned text\n",
    "X_text_filtered = tfidf.fit_transform(data_filtered['cleaned_text'])\n",
    "\n",
    "# Concatenate TF-IDF features and skills vector\n",
    "skills_vector = np.zeros((X_text_filtered.shape[0], len(skills_list)), dtype=int)\n",
    "for i, skills in enumerate(data_filtered['skills']):\n",
    "    for skill in skills:\n",
    "        skills_vector[i, skills_list.index(skill)] = 1\n",
    "\n",
    "X_filtered = np.hstack((X_text_filtered.toarray(), skills_vector))\n",
    "\n",
    "# Split the filtered data into training and test sets\n",
    "X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(\n",
    "    X_filtered, y_filtered, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a multi-label classifier on filtered data\n",
    "model_filtered = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model_filtered.fit(X_train_filtered, y_train_filtered)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_filtered = model_filtered.predict(X_test_filtered)\n",
    "\n",
    "# Calculate evaluation metrics for filtered data\n",
    "hamming_filtered = hamming_loss(y_test_filtered, y_pred_filtered)\n",
    "f1_filtered = f1_score(y_test_filtered, y_pred_filtered, average='micro')\n",
    "accuracy_filtered = accuracy_score(y_test_filtered, y_pred_filtered)\n",
    "\n",
    "print(f'Hamming Loss (Filtered): {hamming_filtered}')\n",
    "print(f'F1 Score (Micro) (Filtered): {f1_filtered}')\n",
    "print(f'Accuracy (Filtered): {accuracy_filtered}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "572be6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes (Filtered): ['kotlin' 'jetpack compose' 'android sdk' 'firebase' 'rest' 'json' 'proto'\n",
      " 'r' 'excel' 'hr' 'communication' 'multitasking' 'microsoft office' 'ai'\n",
      " 'recruitment' 'marketing' 'social media' 'content creation' 'sales'\n",
      " 'operations' 'product management' 'research' 'problem solving'\n",
      " 'collaboration' 'market research' 'python' 'analytical skills'\n",
      " 'organizational skills' 'inventory management' 'sql' 'data visualization'\n",
      " 'b2b' 'java' 'javascript' 'product marketing' 'project management'\n",
      " 'business development' 'lead generation' 'seo' 'aws' 'logistics'\n",
      " 'procurement' 'supply chain management' 'machine learning' 'tableau'\n",
      " 'power bi' 'react' 'big data' 'agile' 'email marketing' 'cloud computing'\n",
      " 'scrum' 'statistical analysis' 'content strategy' 'tensorflow'\n",
      " 'deep learning']\n",
      "Counts per Class (Filtered):\n",
      "r                          161\n",
      "ai                         124\n",
      "communication               99\n",
      "excel                       87\n",
      "marketing                   54\n",
      "research                    49\n",
      "problem solving             37\n",
      "sales                       37\n",
      "sql                         36\n",
      "hr                          30\n",
      "rest                        29\n",
      "operations                  28\n",
      "collaboration               23\n",
      "social media                22\n",
      "market research             21\n",
      "python                      21\n",
      "analytical skills           16\n",
      "microsoft office            13\n",
      "project management          13\n",
      "business development        13\n",
      "aws                         13\n",
      "java                        13\n",
      "javascript                  12\n",
      "react                        9\n",
      "proto                        8\n",
      "content creation             8\n",
      "organizational skills        8\n",
      "product management           8\n",
      "machine learning             8\n",
      "b2b                          7\n",
      "agile                        7\n",
      "data visualization           6\n",
      "recruitment                  6\n",
      "power bi                     5\n",
      "lead generation              5\n",
      "logistics                    5\n",
      "seo                          4\n",
      "tableau                      4\n",
      "multitasking                 3\n",
      "product marketing            3\n",
      "content strategy             3\n",
      "tensorflow                   3\n",
      "inventory management         2\n",
      "email marketing              2\n",
      "scrum                        2\n",
      "cloud computing              1\n",
      "statistical analysis         1\n",
      "kotlin                       1\n",
      "big data                     1\n",
      "supply chain management      1\n",
      "procurement                  1\n",
      "jetpack compose              1\n",
      "json                         1\n",
      "firebase                     1\n",
      "android sdk                  1\n",
      "deep learning                1\n",
      "Name: skills, dtype: int64\n",
      "Unique Classes (Filtered): ['kotlin' 'jetpack compose' 'android sdk' 'firebase' 'rest' 'json' 'proto'\n",
      " 'r' 'excel' 'hr' 'communication' 'multitasking' 'microsoft office' 'ai'\n",
      " 'recruitment' 'marketing' 'social media' 'content creation' 'sales'\n",
      " 'operations' 'product management' 'research' 'problem solving'\n",
      " 'collaboration' 'market research' 'python' 'analytical skills'\n",
      " 'organizational skills' 'inventory management' 'sql' 'data visualization'\n",
      " 'b2b' 'java' 'javascript' 'product marketing' 'project management'\n",
      " 'business development' 'lead generation' 'seo' 'aws' 'logistics'\n",
      " 'procurement' 'supply chain management' 'machine learning' 'tableau'\n",
      " 'power bi' 'react' 'big data' 'agile' 'email marketing' 'cloud computing'\n",
      " 'scrum' 'statistical analysis' 'content strategy' 'tensorflow'\n",
      " 'deep learning']\n",
      "Counts per Class (Filtered):\n",
      "r                          161\n",
      "ai                         124\n",
      "communication               99\n",
      "excel                       87\n",
      "marketing                   54\n",
      "research                    49\n",
      "problem solving             37\n",
      "sales                       37\n",
      "sql                         36\n",
      "hr                          30\n",
      "rest                        29\n",
      "operations                  28\n",
      "collaboration               23\n",
      "social media                22\n",
      "market research             21\n",
      "python                      21\n",
      "analytical skills           16\n",
      "microsoft office            13\n",
      "project management          13\n",
      "business development        13\n",
      "aws                         13\n",
      "java                        13\n",
      "javascript                  12\n",
      "react                        9\n",
      "proto                        8\n",
      "content creation             8\n",
      "organizational skills        8\n",
      "product management           8\n",
      "machine learning             8\n",
      "b2b                          7\n",
      "agile                        7\n",
      "data visualization           6\n",
      "recruitment                  6\n",
      "power bi                     5\n",
      "lead generation              5\n",
      "logistics                    5\n",
      "seo                          4\n",
      "tableau                      4\n",
      "multitasking                 3\n",
      "product marketing            3\n",
      "content strategy             3\n",
      "tensorflow                   3\n",
      "inventory management         2\n",
      "email marketing              2\n",
      "scrum                        2\n",
      "cloud computing              1\n",
      "statistical analysis         1\n",
      "kotlin                       1\n",
      "big data                     1\n",
      "supply chain management      1\n",
      "procurement                  1\n",
      "jetpack compose              1\n",
      "json                         1\n",
      "firebase                     1\n",
      "android sdk                  1\n",
      "deep learning                1\n",
      "Name: skills, dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 115\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier on filtered data\u001b[39;00m\n\u001b[0;32m    114\u001b[0m model_filtered \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m--> 115\u001b[0m \u001b[43mmodel_filtered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m    118\u001b[0m y_pred_filtered \u001b[38;5;241m=\u001b[39m model_filtered\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "data['description'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the 'role_description' and 'description' columns\n",
    "data['job_description'] = data['role_description'] + ' ' + data['description']\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['cleaned_text'] = data['job_description'].apply(preprocess_text)\n",
    "\n",
    "# Skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Count the number of samples per class\n",
    "class_counts = data['skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data[data['skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Remove samples belonging to classes with only one sample\n",
    "data_filtered = data_filtered[data_filtered['skills'].apply(lambda x: len(x) > 1)]\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering again\n",
    "unique_classes_filtered = data_filtered['skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    raise ValueError(\"There are not enough unique classes present in the filtered data after removing classes with fewer than two samples.\")\n",
    "\n",
    "# Print unique classes and their counts\n",
    "print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "print(\"Counts per Class (Filtered):\")\n",
    "print(data_filtered['skills'].explode().value_counts())\n",
    "\n",
    "# Remove samples belonging to classes with only one sample after the filtering process\n",
    "data_filtered = data_filtered[data_filtered['skills'].apply(lambda x: len(x) > 1)]\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering again\n",
    "unique_classes_filtered = data_filtered['skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    raise ValueError(\"There are not enough unique classes present in the filtered data after removing classes with fewer than two samples.\")\n",
    "\n",
    "# Print unique classes and their\n",
    "# Print unique classes and their counts\n",
    "print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "print(\"Counts per Class (Filtered):\")\n",
    "print(data_filtered['skills'].explode().value_counts())\n",
    "\n",
    "# Transform skills into binary labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(data_filtered['skills'])\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=1000, lowercase=False)\n",
    "X = vectorizer.fit_transform(data_filtered['cleaned_text'])\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a multi-label classifier on filtered data\n",
    "model_filtered = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model_filtered.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_filtered = model_filtered.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "f1 = f1_score(y_test, y_pred_filtered, average='micro')\n",
    "hamming = hamming_loss(y_test, y_pred_filtered)\n",
    "accuracy = accuracy_score(y_test, y_pred_filtered)\n",
    "\n",
    "print(\"F1 Score (Micro):\", f1)\n",
    "print(\"Hamming Loss:\", hamming)\n",
    "print(\"Accuracy Score:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "136ad5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes (Filtered): ['kotlin' 'jetpack compose' 'android sdk' 'firebase' 'rest' 'json' 'proto'\n",
      " 'r' 'excel' 'hr' 'communication' 'multitasking' 'microsoft office' 'ai'\n",
      " 'recruitment' 'marketing' 'social media' 'content creation' 'sales'\n",
      " 'operations' 'product management' 'research' 'problem solving'\n",
      " 'collaboration' 'market research' 'python' 'analytical skills'\n",
      " 'organizational skills' 'inventory management' 'sql' 'data visualization'\n",
      " 'b2b' 'java' 'javascript' 'product marketing' 'project management'\n",
      " 'business development' 'lead generation' 'seo' 'aws' 'logistics'\n",
      " 'procurement' 'supply chain management' 'machine learning' 'tableau'\n",
      " 'power bi' 'react' 'big data' 'agile' 'email marketing' 'cloud computing'\n",
      " 'scrum' 'statistical analysis' 'content strategy' 'tensorflow'\n",
      " 'deep learning']\n",
      "Counts per Class (Filtered):\n",
      "r                          161\n",
      "ai                         124\n",
      "communication               99\n",
      "excel                       87\n",
      "marketing                   54\n",
      "research                    49\n",
      "problem solving             37\n",
      "sales                       37\n",
      "sql                         36\n",
      "hr                          30\n",
      "rest                        29\n",
      "operations                  28\n",
      "collaboration               23\n",
      "social media                22\n",
      "market research             21\n",
      "python                      21\n",
      "analytical skills           16\n",
      "microsoft office            13\n",
      "project management          13\n",
      "business development        13\n",
      "aws                         13\n",
      "java                        13\n",
      "javascript                  12\n",
      "react                        9\n",
      "proto                        8\n",
      "content creation             8\n",
      "organizational skills        8\n",
      "product management           8\n",
      "machine learning             8\n",
      "b2b                          7\n",
      "agile                        7\n",
      "data visualization           6\n",
      "recruitment                  6\n",
      "power bi                     5\n",
      "lead generation              5\n",
      "logistics                    5\n",
      "seo                          4\n",
      "tableau                      4\n",
      "multitasking                 3\n",
      "product marketing            3\n",
      "content strategy             3\n",
      "tensorflow                   3\n",
      "inventory management         2\n",
      "email marketing              2\n",
      "scrum                        2\n",
      "cloud computing              1\n",
      "statistical analysis         1\n",
      "kotlin                       1\n",
      "big data                     1\n",
      "supply chain management      1\n",
      "procurement                  1\n",
      "jetpack compose              1\n",
      "json                         1\n",
      "firebase                     1\n",
      "android sdk                  1\n",
      "deep learning                1\n",
      "Name: skills, dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 101\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier on filtered data\u001b[39;00m\n\u001b[0;32m    100\u001b[0m model_filtered \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m--> 101\u001b[0m \u001b[43mmodel_filtered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m    104\u001b[0m y_pred_filtered \u001b[38;5;241m=\u001b[39m model_filtered\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "data['description'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the 'role_description' and 'description' columns\n",
    "data['job_description'] = data['role_description'] + ' ' + data['description']\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['cleaned_text'] = data['job_description'].apply(preprocess_text)\n",
    "\n",
    "# Skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Count the number of samples per class\n",
    "class_counts = data['skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data[data['skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Remove samples belonging to classes with only one sample\n",
    "data_filtered = data_filtered[data_filtered['skills'].apply(lambda x: len(x) > 1)]\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering again\n",
    "unique_classes_filtered = data_filtered['skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    raise ValueError(\"There are not enough unique classes present in the filtered data after removing classes with fewer than two samples.\")\n",
    "\n",
    "# Print unique classes and their counts\n",
    "print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "print(\"Counts per Class (Filtered):\")\n",
    "print(data_filtered['skills'].explode().value_counts())\n",
    "\n",
    "# Transform skills into binary labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(data_filtered['skills'])\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=1000, lowercase=False)\n",
    "X = vectorizer.fit_transform(data_filtered['cleaned_text'])\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a multi-label classifier on filtered data\n",
    "model_filtered = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model_filtered.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_filtered = model_filtered.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "f1 = f1_score(y_test, y_pred_filtered, average='micro')\n",
    "hamming = hamming_loss(y_test, y_pred_filtered)\n",
    "accuracy = accuracy_score(y_test, y_pred_filtered)\n",
    "\n",
    "print(\"F1 Score (Micro):\", f1)\n",
    "print(\"Hamming Loss:\", hamming)\n",
    "print(\"Accuracy Score:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94382c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes (Filtered): ['kotlin' 'jetpack compose' 'android sdk' 'firebase' 'rest' 'json' 'proto'\n",
      " 'r' 'excel' 'hr' 'communication' 'multitasking' 'microsoft office' 'ai'\n",
      " 'recruitment' 'marketing' 'social media' 'content creation' 'sales'\n",
      " 'operations' 'product management' 'research' 'problem solving'\n",
      " 'collaboration' 'market research' 'python' 'analytical skills'\n",
      " 'organizational skills' 'inventory management' 'sql' 'data visualization'\n",
      " 'b2b' 'java' 'javascript' 'product marketing' 'project management'\n",
      " 'business development' 'lead generation' 'seo' 'aws' 'logistics'\n",
      " 'procurement' 'supply chain management' 'machine learning' 'tableau'\n",
      " 'power bi' 'react' 'big data' 'agile' 'email marketing' 'cloud computing'\n",
      " 'scrum' 'statistical analysis' 'content strategy' 'tensorflow'\n",
      " 'deep learning']\n",
      "Counts per Class (Filtered):\n",
      "r                          161\n",
      "ai                         124\n",
      "communication               99\n",
      "excel                       87\n",
      "marketing                   54\n",
      "research                    49\n",
      "problem solving             37\n",
      "sales                       37\n",
      "sql                         36\n",
      "hr                          30\n",
      "rest                        29\n",
      "operations                  28\n",
      "collaboration               23\n",
      "social media                22\n",
      "market research             21\n",
      "python                      21\n",
      "analytical skills           16\n",
      "microsoft office            13\n",
      "project management          13\n",
      "business development        13\n",
      "aws                         13\n",
      "java                        13\n",
      "javascript                  12\n",
      "react                        9\n",
      "proto                        8\n",
      "content creation             8\n",
      "organizational skills        8\n",
      "product management           8\n",
      "machine learning             8\n",
      "b2b                          7\n",
      "agile                        7\n",
      "data visualization           6\n",
      "recruitment                  6\n",
      "power bi                     5\n",
      "lead generation              5\n",
      "logistics                    5\n",
      "seo                          4\n",
      "tableau                      4\n",
      "multitasking                 3\n",
      "product marketing            3\n",
      "content strategy             3\n",
      "tensorflow                   3\n",
      "inventory management         2\n",
      "email marketing              2\n",
      "scrum                        2\n",
      "cloud computing              1\n",
      "statistical analysis         1\n",
      "kotlin                       1\n",
      "big data                     1\n",
      "supply chain management      1\n",
      "procurement                  1\n",
      "jetpack compose              1\n",
      "json                         1\n",
      "firebase                     1\n",
      "android sdk                  1\n",
      "deep learning                1\n",
      "Name: skills, dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 101\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier on filtered data\u001b[39;00m\n\u001b[0;32m    100\u001b[0m model_filtered \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m--> 101\u001b[0m \u001b[43mmodel_filtered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m    104\u001b[0m y_pred_filtered \u001b[38;5;241m=\u001b[39m model_filtered\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "data['description'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the 'role_description' and 'description' columns\n",
    "data['job_description'] = data['role_description'] + ' ' + data['description']\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['cleaned_text'] = data['job_description'].apply(preprocess_text)\n",
    "\n",
    "# Skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Count the number of samples per class\n",
    "class_counts = data['skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data[data['skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Remove samples belonging to classes with only one sample\n",
    "data_filtered = data_filtered[data_filtered['skills'].apply(lambda x: len(x) > 1)]\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering again\n",
    "unique_classes_filtered = data_filtered['skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    raise ValueError(\"There are not enough unique classes present in the filtered data after removing classes with fewer than two samples.\")\n",
    "\n",
    "# Print unique classes and their counts\n",
    "print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "print(\"Counts per Class (Filtered):\")\n",
    "print(data_filtered['skills'].explode().value_counts())\n",
    "\n",
    "# Transform skills into binary labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(data_filtered['skills'])\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=1000, lowercase=False)\n",
    "X = vectorizer.fit_transform(data_filtered['cleaned_text'])\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a multi-label classifier on filtered data\n",
    "model_filtered = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model_filtered.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_filtered = model_filtered.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "f1 = f1_score(y_test, y_pred_filtered, average='micro')\n",
    "hamming = hamming_loss(y_test, y_pred_filtered)\n",
    "accuracy = accuracy_score(y_test, y_pred_filtered)\n",
    "\n",
    "print(\"F1 Score (Micro):\", f1)\n",
    "print(\"Hamming Loss:\", hamming)\n",
    "print(\"Accuracy Score:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f494c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes (Filtered): ['kotlin' 'jetpack compose' 'android sdk' 'firebase' 'rest' 'json' 'proto'\n",
      " 'r' 'excel' 'hr' 'communication' 'multitasking' 'microsoft office' 'ai'\n",
      " 'recruitment' 'marketing' 'social media' 'content creation' 'sales'\n",
      " 'operations' 'product management' 'research' 'problem solving'\n",
      " 'collaboration' 'market research' 'python' 'analytical skills'\n",
      " 'organizational skills' 'inventory management' 'sql' 'data visualization'\n",
      " 'b2b' 'java' 'javascript' 'product marketing' 'project management'\n",
      " 'business development' 'lead generation' 'seo' 'aws' 'logistics'\n",
      " 'procurement' 'supply chain management' 'machine learning' 'tableau'\n",
      " 'power bi' 'react' 'big data' 'agile' 'email marketing' 'cloud computing'\n",
      " 'scrum' 'statistical analysis' 'content strategy' 'tensorflow'\n",
      " 'deep learning']\n",
      "Counts per Class (Filtered):\n",
      "r                          161\n",
      "ai                         124\n",
      "communication               99\n",
      "excel                       87\n",
      "marketing                   54\n",
      "research                    49\n",
      "problem solving             37\n",
      "sales                       37\n",
      "sql                         36\n",
      "hr                          30\n",
      "rest                        29\n",
      "operations                  28\n",
      "collaboration               23\n",
      "social media                22\n",
      "market research             21\n",
      "python                      21\n",
      "analytical skills           16\n",
      "microsoft office            13\n",
      "project management          13\n",
      "business development        13\n",
      "aws                         13\n",
      "java                        13\n",
      "javascript                  12\n",
      "react                        9\n",
      "proto                        8\n",
      "content creation             8\n",
      "organizational skills        8\n",
      "product management           8\n",
      "machine learning             8\n",
      "b2b                          7\n",
      "agile                        7\n",
      "data visualization           6\n",
      "recruitment                  6\n",
      "power bi                     5\n",
      "lead generation              5\n",
      "logistics                    5\n",
      "seo                          4\n",
      "tableau                      4\n",
      "multitasking                 3\n",
      "product marketing            3\n",
      "content strategy             3\n",
      "tensorflow                   3\n",
      "inventory management         2\n",
      "email marketing              2\n",
      "scrum                        2\n",
      "cloud computing              1\n",
      "statistical analysis         1\n",
      "kotlin                       1\n",
      "big data                     1\n",
      "supply chain management      1\n",
      "procurement                  1\n",
      "jetpack compose              1\n",
      "json                         1\n",
      "firebase                     1\n",
      "android sdk                  1\n",
      "deep learning                1\n",
      "Name: skills, dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 111\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier on filtered data\u001b[39;00m\n\u001b[0;32m    110\u001b[0m model_filtered \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m--> 111\u001b[0m \u001b[43mmodel_filtered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m    114\u001b[0m y_pred_filtered \u001b[38;5;241m=\u001b[39m model_filtered\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "data['description'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the 'role_description' and 'description' columns\n",
    "data['job_description'] = data['role_description'] + ' ' + data['description']\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['cleaned_text'] = data['job_description'].apply(preprocess_text)\n",
    "\n",
    "# Skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Count the number of samples per class\n",
    "class_counts = data['skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data[data['skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Remove samples belonging to classes with only one sample\n",
    "data_filtered = data_filtered[data_filtered['skills'].apply(lambda x: len(x) > 1)]\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering again\n",
    "unique_classes_filtered = data_filtered['skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    raise ValueError(\"There are not enough unique classes present in the filtered data after removing classes with fewer than two samples.\")\n",
    "\n",
    "# Print unique classes and their counts\n",
    "print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "print(\"Counts per Class (Filtered):\")\n",
    "print(data_filtered['skills'].explode().value_counts())\n",
    "\n",
    "# Transform skills into binary labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(data_filtered['skills'])\n",
    "\n",
    "# Filter out outlier classes\n",
    "class_counts_filtered = np.sum(labels, axis=0)\n",
    "valid_class_indices = np.where(class_counts_filtered >= 2)[0]\n",
    "\n",
    "# Filter the labels and keep only valid classes\n",
    "filtered_labels = labels[:, valid_class_indices]\n",
    "\n",
    "# Filter the TF-IDF features based on valid classes\n",
    "X_filtered = X[:, valid_class_indices]\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=1000, lowercase=False)\n",
    "X = vectorizer.fit_transform(data_filtered['cleaned_text'])\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_filtered, filtered_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a multi-label classifier on filtered data\n",
    "model_filtered = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model_filtered.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_filtered = model_filtered.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "f1 = f1_score(y_test, y_pred_filtered, average='micro')\n",
    "hamming = hamming_loss(y_test, y_pred_filtered)\n",
    "accuracy = accuracy_score(y_test, y_pred_filtered)\n",
    "\n",
    "print(\"F1 Score (Micro):\", f1)\n",
    "print(\"Hamming Loss:\", hamming)\n",
    "print(\"Accuracy Score:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5189434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes (Filtered): ['rest' 'proto' 'r' 'excel' 'hr' 'communication' 'multitasking'\n",
      " 'microsoft office' 'ai' 'recruitment' 'marketing' 'social media'\n",
      " 'content creation' 'sales' 'operations' 'product management' 'research'\n",
      " 'problem solving' 'collaboration' 'market research' 'python'\n",
      " 'analytical skills' 'organizational skills' 'inventory management' 'sql'\n",
      " 'data visualization' 'b2b' 'java' 'javascript' 'product marketing'\n",
      " 'project management' 'business development' 'lead generation' 'seo' 'aws'\n",
      " 'logistics' 'machine learning' 'tableau' 'power bi' 'react' 'agile'\n",
      " 'email marketing' 'scrum' 'content strategy' 'tensorflow']\n",
      "Counts per Class (Filtered):\n",
      "r                        161\n",
      "ai                       124\n",
      "communication             99\n",
      "excel                     87\n",
      "marketing                 54\n",
      "research                  49\n",
      "problem solving           37\n",
      "sales                     37\n",
      "sql                       36\n",
      "hr                        30\n",
      "rest                      29\n",
      "operations                28\n",
      "collaboration             23\n",
      "social media              22\n",
      "market research           21\n",
      "python                    21\n",
      "analytical skills         16\n",
      "java                      13\n",
      "business development      13\n",
      "microsoft office          13\n",
      "project management        13\n",
      "aws                       13\n",
      "javascript                12\n",
      "react                      9\n",
      "machine learning           8\n",
      "organizational skills      8\n",
      "content creation           8\n",
      "proto                      8\n",
      "product management         8\n",
      "b2b                        7\n",
      "agile                      7\n",
      "recruitment                6\n",
      "data visualization         6\n",
      "power bi                   5\n",
      "logistics                  5\n",
      "lead generation            5\n",
      "seo                        4\n",
      "tableau                    4\n",
      "product marketing          3\n",
      "multitasking               3\n",
      "content strategy           3\n",
      "tensorflow                 3\n",
      "inventory management       2\n",
      "email marketing            2\n",
      "scrum                      2\n",
      "Name: skills, dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 112\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier on filtered data\u001b[39;00m\n\u001b[0;32m    111\u001b[0m model_filtered \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m--> 112\u001b[0m \u001b[43mmodel_filtered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m    115\u001b[0m y_pred_filtered \u001b[38;5;241m=\u001b[39m model_filtered\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "data['description'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the 'role_description' and 'description' columns\n",
    "data['job_description'] = data['role_description'] + ' ' + data['description']\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['cleaned_text'] = data['job_description'].apply(preprocess_text)\n",
    "\n",
    "# Skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Count the number of samples per class\n",
    "class_counts = data['skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data[data['skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Remove samples belonging to classes with only one sample\n",
    "data_filtered = data_filtered[data_filtered['skills'].apply(lambda x: len(x) > 1)]\n",
    "\n",
    "# Filter out outliers and delete them\n",
    "outlier_classes = class_counts[class_counts < 2].index\n",
    "data_filtered['skills'] = data_filtered['skills'].apply(lambda x: [skill for skill in x if skill not in outlier_classes])\n",
    "\n",
    "# Reset index after deleting rows\n",
    "data_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert filtered data to features and labels\n",
    "X_filtered = data_filtered['cleaned_text']\n",
    "y_filtered = data_filtered.drop(columns=['cleaned_text'])\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering again\n",
    "unique_classes_filtered = data_filtered['skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    raise ValueError(\"There are not enough unique classes present in the filtered data after removing classes with fewer than two samples.\")\n",
    "\n",
    "# Print unique classes and their counts\n",
    "print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "print(\"Counts per Class (Filtered):\")\n",
    "print(data_filtered['skills'].explode().value_counts())\n",
    "\n",
    "# Transform skills into binary labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(data_filtered['skills'])\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=1000, lowercase=False)\n",
    "X = vectorizer.fit_transform(data_filtered['cleaned_text'])\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a multi-label classifier on filtered data\n",
    "model_filtered = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model_filtered.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_filtered = model_filtered.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "f1 = f1_score(y_test, y_pred_filtered, average='micro')\n",
    "hamming = hamming_loss(y_test, y_pred_filtered)\n",
    "accuracy = accuracy_score(y_test, y_pred_filtered)\n",
    "\n",
    "print(\"F1 Score (Micro):\", f1)\n",
    "print(\"Hamming Loss:\", hamming)\n",
    "print(\"Accuracy Score:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c7d0424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes (Filtered): ['rest' 'proto' 'r' 'excel' 'hr' 'communication' 'multitasking'\n",
      " 'microsoft office' 'ai' 'recruitment' 'marketing' 'social media'\n",
      " 'content creation' 'sales' 'operations' 'product management' 'research'\n",
      " 'problem solving' 'collaboration' 'market research' 'python'\n",
      " 'analytical skills' 'organizational skills' 'inventory management' 'sql'\n",
      " 'data visualization' 'b2b' 'java' 'javascript' 'product marketing'\n",
      " 'project management' 'business development' 'lead generation' 'seo' 'aws'\n",
      " 'logistics' 'machine learning' 'tableau' 'power bi' 'react' 'agile'\n",
      " 'email marketing' 'scrum' 'content strategy' 'tensorflow']\n",
      "Counts per Class (Filtered):\n",
      "r                        161\n",
      "ai                       124\n",
      "communication             99\n",
      "excel                     87\n",
      "marketing                 54\n",
      "research                  49\n",
      "problem solving           37\n",
      "sales                     37\n",
      "sql                       36\n",
      "hr                        30\n",
      "rest                      29\n",
      "operations                28\n",
      "collaboration             23\n",
      "social media              22\n",
      "market research           21\n",
      "python                    21\n",
      "analytical skills         16\n",
      "java                      13\n",
      "business development      13\n",
      "microsoft office          13\n",
      "project management        13\n",
      "aws                       13\n",
      "javascript                12\n",
      "react                      9\n",
      "machine learning           8\n",
      "organizational skills      8\n",
      "content creation           8\n",
      "proto                      8\n",
      "product management         8\n",
      "b2b                        7\n",
      "agile                      7\n",
      "recruitment                6\n",
      "data visualization         6\n",
      "power bi                   5\n",
      "logistics                  5\n",
      "lead generation            5\n",
      "seo                        4\n",
      "tableau                    4\n",
      "product marketing          3\n",
      "multitasking               3\n",
      "content strategy           3\n",
      "tensorflow                 3\n",
      "inventory management       2\n",
      "email marketing            2\n",
      "scrum                      2\n",
      "Name: skills, dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 112\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier on filtered data\u001b[39;00m\n\u001b[0;32m    111\u001b[0m model_filtered \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m--> 112\u001b[0m \u001b[43mmodel_filtered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m    115\u001b[0m y_pred_filtered \u001b[38;5;241m=\u001b[39m model_filtered\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "data['description'].fillna('', inplace=True)\n",
    "\n",
    "# Combine the 'role_description' and 'description' columns\n",
    "data['job_description'] = data['role_description'] + ' ' + data['description']\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['cleaned_text'] = data['job_description'].apply(preprocess_text)\n",
    "\n",
    "# Skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Count the number of samples per class\n",
    "class_counts = data['skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data[data['skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Remove samples belonging to classes with only one sample\n",
    "data_filtered = data_filtered[data_filtered['skills'].apply(lambda x: len(x) > 1)]\n",
    "\n",
    "# Filter out outliers and delete them\n",
    "outlier_classes = class_counts[class_counts < 2].index\n",
    "data_filtered['skills'] = data_filtered['skills'].apply(lambda x: [skill for skill in x if skill not in outlier_classes])\n",
    "\n",
    "# Reset index after deleting rows\n",
    "data_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert filtered data to features and labels\n",
    "X_filtered = data_filtered['cleaned_text']\n",
    "y_filtered = data_filtered.drop(columns=['cleaned_text'])\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering again\n",
    "unique_classes_filtered = data_filtered['skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    print(\"There are not enough unique classes present in the filtered data after removing classes with fewer than two samples.\")\n",
    "else:\n",
    "    # Print unique classes and their counts\n",
    "    print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "    print(\"Counts per Class (Filtered):\")\n",
    "    print(data_filtered['skills'].explode().value_counts())\n",
    "\n",
    "    # Transform skills into binary labels\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    labels = mlb.fit_transform(data_filtered['skills'])\n",
    "\n",
    "    # TF-IDF Vectorization\n",
    "    vectorizer = TfidfVectorizer(max_features=1000, lowercase=False)\n",
    "    X = vectorizer.fit_transform(data_filtered['cleaned_text'])\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a multi-label classifier on filtered data\n",
    "    model_filtered = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "    model_filtered.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_filtered = model_filtered.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    f1 = f1_score(y_test, y_pred_filtered, average='micro')\n",
    "    hamming = hamming_loss(y_test, y_pred_filtered)\n",
    "    accuracy = accuracy_score(y_test, y_pred_filtered)\n",
    "\n",
    "    print(\"F1 Score (Micro):\", f1)\n",
    "    print(\"Hamming Loss:\", hamming)\n",
    "    print(\"Accuracy Score:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb019c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train: (128, 45)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of y_train:\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02d4fa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in y_train: [0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in y_train:\", np.unique(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9db23085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts per class in y_train:\n",
      "[  5  97  12   8   5  12  18  76   5   1   3   2  64  25   2  10   9   3\n",
      "   3   6  17  44  10   1  20   7   4  27   7   0  11   7  16 128   8   4\n",
      "  40  23  32   2   2  18  12   3   3]\n"
     ]
    }
   ],
   "source": [
    "class_counts_train = np.sum(y_train, axis=0)\n",
    "print(\"Counts per class in y_train:\")\n",
    "print(class_counts_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc014c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique counts of class labels in y_train: [  0   1   2   3   4   5   6   7   8   9  10  11  12  16  17  18  20  23\n",
      "  25  27  32  40  44  64  76  97 128]\n"
     ]
    }
   ],
   "source": [
    "unique_counts_train = np.unique(class_counts_train)\n",
    "print(\"Unique counts of class labels in y_train:\", unique_counts_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d64ddce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_filtered: (128, 44)\n",
      "Shape of y_train_filtered: (128, 44)\n"
     ]
    }
   ],
   "source": [
    "# Find indices of classes with at least one sample\n",
    "indices = np.where(class_counts_train > 0)[0]\n",
    "\n",
    "# Filter X_train and y_train\n",
    "X_train_filtered = X_train[:, indices]\n",
    "y_train_filtered = y_train[:, indices]\n",
    "\n",
    "# Print the shape of filtered data\n",
    "print(\"Shape of X_train_filtered:\", X_train_filtered.shape)\n",
    "print(\"Shape of y_train_filtered:\", y_train_filtered.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e141fa3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier on filtered data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model_filtered \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel_filtered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_filtered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m      6\u001b[0m y_pred_filtered \u001b[38;5;241m=\u001b[39m model_filtered\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "# Train a multi-label classifier on filtered data\n",
    "model_filtered = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model_filtered.fit(X_train_filtered, y_train_filtered)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_filtered = model_filtered.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "f1 = f1_score(y_test, y_pred_filtered, average='micro')\n",
    "hamming = hamming_loss(y_test, y_pred_filtered)\n",
    "accuracy = accuracy_score(y_test, y_pred_filtered)\n",
    "\n",
    "print(\"F1 Score (Micro):\", f1)\n",
    "print(\"Hamming Loss:\", hamming)\n",
    "print(\"Accuracy Score:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5664866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in y_train_filtered: [0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in y_train_filtered:\", np.unique(y_train_filtered))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f895b160",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Fit the model to the corresponding label column\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_filtered\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Append the trained model to the list\u001b[39;00m\n\u001b[0;32m     13\u001b[0m models\u001b[38;5;241m.\u001b[39mappend(model)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize a list to store individual models\n",
    "models = []\n",
    "\n",
    "# Train a logistic regression model for each label\n",
    "for i in range(y_train_filtered.shape[1]):\n",
    "    # Initialize a logistic regression model\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    # Fit the model to the corresponding label column\n",
    "    model.fit(X_train_filtered, y_train_filtered[:, i])\n",
    "    # Append the trained model to the list\n",
    "    models.append(model)\n",
    "\n",
    "# Predict on the test set for each label\n",
    "y_pred_filtered = np.array([model.predict(X_test) for model in models]).T\n",
    "\n",
    "# Evaluate the model\n",
    "f1 = f1_score(y_test, y_pred_filtered, average='micro')\n",
    "hamming = hamming_loss(y_test, y_pred_filtered)\n",
    "accuracy = accuracy_score(y_test, y_pred_filtered)\n",
    "\n",
    "print(\"F1 Score (Micro):\", f1)\n",
    "print(\"Hamming Loss:\", hamming)\n",
    "print(\"Accuracy Score:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a4a1033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_filtered: (128, 44)\n",
      "Sample of y_train_filtered: [[0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0\n",
      "  0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      "  0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1\n",
      "  0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      "  0 1 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of y_train_filtered:\", y_train_filtered.shape)\n",
    "print(\"Sample of y_train_filtered:\", y_train_filtered[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a6d51be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of samples with only zeros: []\n",
      "Indices of columns with only zeros: []\n"
     ]
    }
   ],
   "source": [
    "# Check for samples with only zeros\n",
    "zero_samples = np.where(~y_train_filtered.any(axis=1))[0]\n",
    "print(\"Indices of samples with only zeros:\", zero_samples)\n",
    "\n",
    "# Check for columns with only zeros\n",
    "zero_columns = np.where(~y_train_filtered.any(axis=0))[0]\n",
    "print(\"Indices of columns with only zeros:\", zero_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e35837b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes (Filtered): ['rest' 'proto' 'r' 'excel' 'hr' 'communication' 'multitasking'\n",
      " 'microsoft office' 'ai' 'recruitment' 'marketing' 'social media'\n",
      " 'content creation' 'sales' 'operations' 'product management' 'research'\n",
      " 'problem solving' 'collaboration' 'market research' 'python'\n",
      " 'analytical skills' 'organizational skills' 'inventory management' 'sql'\n",
      " 'data visualization' 'b2b' 'java' 'javascript' 'product marketing'\n",
      " 'project management' 'business development' 'lead generation' 'seo' 'aws'\n",
      " 'logistics' 'machine learning' 'tableau' 'power bi' 'react' 'agile'\n",
      " 'email marketing' 'scrum' 'content strategy' 'tensorflow']\n",
      "Counts per Class (Filtered):\n",
      "r                        161\n",
      "ai                       124\n",
      "communication             99\n",
      "excel                     87\n",
      "marketing                 54\n",
      "research                  49\n",
      "problem solving           37\n",
      "sales                     37\n",
      "sql                       36\n",
      "hr                        30\n",
      "rest                      29\n",
      "operations                28\n",
      "collaboration             23\n",
      "social media              22\n",
      "market research           21\n",
      "python                    21\n",
      "analytical skills         16\n",
      "java                      13\n",
      "business development      13\n",
      "microsoft office          13\n",
      "project management        13\n",
      "aws                       13\n",
      "javascript                12\n",
      "react                      9\n",
      "machine learning           8\n",
      "organizational skills      8\n",
      "content creation           8\n",
      "proto                      8\n",
      "product management         8\n",
      "b2b                        7\n",
      "agile                      7\n",
      "recruitment                6\n",
      "data visualization         6\n",
      "power bi                   5\n",
      "logistics                  5\n",
      "lead generation            5\n",
      "seo                        4\n",
      "tableau                    4\n",
      "product marketing          3\n",
      "multitasking               3\n",
      "content strategy           3\n",
      "tensorflow                 3\n",
      "inventory management       2\n",
      "email marketing            2\n",
      "scrum                      2\n",
      "Name: skills, dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 123\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier on filtered data\u001b[39;00m\n\u001b[0;32m    122\u001b[0m model_filtered \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m--> 123\u001b[0m \u001b[43mmodel_filtered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m    126\u001b[0m y_pred_filtered \u001b[38;5;241m=\u001b[39m model_filtered\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "data['description'].fillna('', inplace=True)\n",
    "\n",
    "# Function to combine role_description and description, handling empty values\n",
    "def combine_descriptions(row):\n",
    "    if row['role_description'] and row['description']:  # If both columns are non-empty\n",
    "        return row['role_description'] + ' ' + row['description']\n",
    "    elif row['role_description']:  # If only role_description is non-empty\n",
    "        return row['role_description']\n",
    "    elif row['description']:  # If only description is non-empty\n",
    "        return row['description']\n",
    "    else:  # If both are empty, handle as needed (e.g., assign a placeholder)\n",
    "        return 'No job description available'\n",
    "\n",
    "# Apply the function to combine descriptions\n",
    "data['job_description'] = data.apply(combine_descriptions, axis=1)\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['cleaned_text'] = data['job_description'].apply(preprocess_text)\n",
    "\n",
    "# Skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Count the number of samples per class\n",
    "class_counts = data['skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data[data['skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Remove samples belonging to classes with only one sample\n",
    "data_filtered = data_filtered[data_filtered['skills'].apply(lambda x: len(x) > 1)]\n",
    "\n",
    "# Filter out outliers and delete them\n",
    "outlier_classes = class_counts[class_counts < 2].index\n",
    "data_filtered['skills'] = data_filtered['skills'].apply(lambda x: [skill for skill in x if skill not in outlier_classes])\n",
    "\n",
    "# Reset index after deleting rows\n",
    "data_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert filtered data to features and labels\n",
    "X_filtered = data_filtered['cleaned_text']\n",
    "y_filtered = data_filtered.drop(columns=['cleaned_text'])\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering again\n",
    "unique_classes_filtered = data_filtered['skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    print(\"There are not enough unique classes present in the filtered data after removing classes with fewer than two samples.\")\n",
    "else:\n",
    "    # Print unique classes and their counts\n",
    "    print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "    print(\"Counts per Class (Filtered):\")\n",
    "    print(data_filtered['skills'].explode().value_counts())\n",
    "\n",
    "    # Transform skills into binary labels\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    labels = mlb.fit_transform(data_filtered['skills'])\n",
    "\n",
    "    # TF-IDF Vectorization\n",
    "    vectorizer = TfidfVectorizer(max_features=1000, lowercase=False)\n",
    "    X = vectorizer.fit_transform(data_filtered['cleaned_text'])\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a multi-label classifier on filtered data\n",
    "    model_filtered = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "    model_filtered.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_filtered = model_filtered.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    f1 = f1_score(y_test, y_pred_filtered, average='micro')\n",
    "    hamming = hamming_loss(y_test, y_pred_filtered)\n",
    "    accuracy = accuracy_score(y_test, y_pred_filtered)\n",
    "\n",
    "    print(\"F1 Score (Micro):\", f1)\n",
    "    print(\"Hamming Loss:\", hamming)\n",
    "    print(\"Accuracy Score:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbaad0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_filtered: (128, 44)\n",
      "Unique values in y_train_filtered: [0 1]\n",
      "Sample of y_train_filtered: [[0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0\n",
      "  0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      "  0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1\n",
      "  0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      "  0 1 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Shape of y_train_filtered\n",
    "print(\"Shape of y_train_filtered:\", y_train_filtered.shape)\n",
    "\n",
    "# Unique values in y_train_filtered\n",
    "unique_values = np.unique(y_train_filtered)\n",
    "print(\"Unique values in y_train_filtered:\", unique_values)\n",
    "\n",
    "# Sample of y_train_filtered\n",
    "print(\"Sample of y_train_filtered:\", y_train_filtered[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfd7ca30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of columns with only one class: [32]\n"
     ]
    }
   ],
   "source": [
    "missing_class_columns = np.where((y_train_filtered.sum(axis=0) == 0) | (y_train_filtered.sum(axis=0) == len(y_train_filtered)))[0]\n",
    "print(\"Indices of columns with only one class:\", missing_class_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "efc35c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of data in column 32 of y_train_filtered: [1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "column_32_data = y_train_filtered[:, 32]\n",
    "print(\"Sample of data in column 32 of y_train_filtered:\", column_32_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4fb53f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_filtered after removing column 32: (128, 43)\n"
     ]
    }
   ],
   "source": [
    "# Remove column 32 from y_train_filtered\n",
    "y_train_filtered = np.delete(y_train_filtered, 32, axis=1)\n",
    "\n",
    "# Verify the new shape of y_train_filtered\n",
    "print(\"Shape of y_train_filtered after removing column 32:\", y_train_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01476028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes (Filtered): [0 1]\n",
      "Counts per Class (Filtered):\n",
      "0    4820\n",
      "1     684\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier on filtered data\u001b[39;00m\n\u001b[0;32m     23\u001b[0m model_filtered \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m---> 24\u001b[0m \u001b[43mmodel_filtered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m     27\u001b[0m y_pred_filtered \u001b[38;5;241m=\u001b[39m model_filtered\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "# Ensure there are at least two unique classes present after removing the column\n",
    "unique_classes_filtered = np.unique(y_train_filtered)\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    print(\"There are not enough unique classes present in the filtered data after removing the column.\")\n",
    "else:\n",
    "    # Print unique classes and their counts\n",
    "    print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "    print(\"Counts per Class (Filtered):\")\n",
    "    print(pd.Series(y_train_filtered.flatten()).value_counts())\n",
    "\n",
    "    # Transform skills into binary labels\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    labels = mlb.fit_transform(data_filtered['skills'])\n",
    "\n",
    "    # TF-IDF Vectorization\n",
    "    vectorizer = TfidfVectorizer(max_features=1000, lowercase=False)\n",
    "    X = vectorizer.fit_transform(data_filtered['cleaned_text'])\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a multi-label classifier on filtered data\n",
    "    model_filtered = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "    model_filtered.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_filtered = model_filtered.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    f1 = f1_score(y_test, y_pred_filtered, average='micro')\n",
    "    hamming = hamming_loss(y_test, y_pred_filtered)\n",
    "    accuracy = accuracy_score(y_test, y_pred_filtered)\n",
    "\n",
    "    print(\"F1 Score (Micro):\", f1)\n",
    "    print(\"Hamming Loss:\", hamming)\n",
    "    print(\"Accuracy Score:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fdf676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "data['description'].fillna('', inplace=True)\n",
    "\n",
    "# Function to combine role_description and description, handling empty values\n",
    "def combine_descriptions(row):\n",
    "    if row['role_description'] and row['description']:  # If both columns are non-empty\n",
    "        return row['role_description'] + ' ' + row['description']\n",
    "    elif row['role_description']:  # If only role_description is non-empty\n",
    "        return row['role_description']\n",
    "    elif row['description']:  # If only description is non-empty\n",
    "        return row['description']\n",
    "    else:  # If both are empty, handle as needed (e.g., assign a placeholder)\n",
    "        return 'No job description available'\n",
    "\n",
    "# Apply the function to combine descriptions\n",
    "data['job_description'] = data.apply(combine_descriptions, axis=1)\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['cleaned_text'] = data['job_description'].apply(preprocess_text)\n",
    "\n",
    "# Skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Count the number of samples per class\n",
    "class_counts = data['skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data[data['skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Remove samples belonging to classes with only one sample\n",
    "data_filtered = data_filtered[data_filtered['skills'].apply(lambda x: len(x) > 1)]\n",
    "\n",
    "# Filter out outliers and delete them\n",
    "outlier_classes = class_counts[class_counts < 2].index\n",
    "data_filtered['skills'] = data_filtered['skills'].apply(lambda x: [skill for skill in x if skill not in outlier_classes])\n",
    "\n",
    "# Reset index after deleting rows\n",
    "data_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert filtered data to features and labels\n",
    "X_filtered = data_filtered['cleaned_text']\n",
    "y_filtered = data_filtered.drop(columns=['cleaned_text'])\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering again\n",
    "unique_classes_filtered = data_filtered['skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    print(\"There are not enough unique classes present in the filtered data after removing classes with fewer than two samples.\")\n",
    "else:\n",
    "    # Print unique classes and their counts\n",
    "    print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "    print(\"Counts per Class (Filtered):\")\n",
    "    print(data_filtered['skills'].explode().value_counts())\n",
    "\n",
    "    # Transform skills into binary labels\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    labels = mlb.fit_transform(data_filtered['skills'])\n",
    "\n",
    "    # TF-IDF Vectorization\n",
    "    vectorizer = TfidfVectorizer(max_features=1000, lowercase=False)\n",
    "    X = vectorizer.fit_transform(data_filtered['cleaned_text'])\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Ensure at least two classes in y_train and y_test\n",
    "    y_train_valid = y_train[:, y_train.sum(axis=0) > 0]\n",
    "    y_test_valid = y_test[:, y_train.sum(axis=0) > 0]\n",
    "\n",
    "    # Train a multi-label classifier on filtered data\n",
    "    model_filtered = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "    model_filtered.fit(X_train, y_train_valid)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_filtered = model_filtered.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    f1 = f1_score(y_test_valid, y_pred_filtered, average='micro')\n",
    "    hamming = hamming_loss(y_test_valid, y_pred_filtered)\n",
    "    accuracy = accuracy_score(y_test_valid, y_pred_filtered)\n",
    "\n",
    "    print(\"F1 Score (Micro):\", f1)\n",
    "    print(\"Hamming Loss:\", hamming)\n",
    "    print(\"Accuracy Score:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e1f76ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiLabelBinarizer\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, Dataset\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Merge role_description and description columns to form job_description\n",
    "df['job_description'] = df['role_description'].fillna('') + ' ' + df['description'].fillna('')\n",
    "\n",
    "# Assume 'skills' column contains the required skills as a list (e.g., [\"skill1\", \"skill2\"])\n",
    "# For example: df['skills'] = [[\"skill1\", \"skill2\"], [\"skill3\"], ...]\n",
    "\n",
    "# Convert skills to binary vector\n",
    "mlb = MultiLabelBinarizer()\n",
    "skills_encoded = mlb.fit_transform(df['skills'])\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(df['job_description'], skills_encoded, test_size=0.2, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define a custom dataset class\n",
    "class JobDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.max_len = 512\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels[idx]\n",
    "        inputs = self.tokenizer(text, return_tensors='pt', max_length=self.max_len, truncation=True, padding='max_length')\n",
    "        input_ids = inputs['input_ids'].squeeze()\n",
    "        attention_mask = inputs['attention_mask'].squeeze()\n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': torch.tensor(label, dtype=torch.float)}\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_dataset = JobDataset(train_texts, train_labels)\n",
    "val_dataset = JobDataset(val_texts, val_labels)\n",
    "test_dataset = JobDataset(test_texts, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e43b350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: torch in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.12.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.24.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.3.0-cp310-cp310-win_amd64.whl.metadata (26 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.18.0-cp310-cp310-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.3.0-cp310-cp310-win_amd64.whl.metadata (6.4 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.12.0)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.2)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch)\n",
      "  Downloading mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.24.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (10.1.0)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Downloading intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Downloading tbb-2021.12.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.3.0-cp310-cp310-win_amd64.whl (159.8 MB)\n",
      "   ---------------------------------------- 0.0/159.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.7/159.8 MB 21.5 MB/s eta 0:00:08\n",
      "   ---------------------------------------- 1.3/159.8 MB 16.0 MB/s eta 0:00:10\n",
      "   ---------------------------------------- 2.0/159.8 MB 15.8 MB/s eta 0:00:10\n",
      "    --------------------------------------- 2.3/159.8 MB 12.1 MB/s eta 0:00:14\n",
      "    --------------------------------------- 2.6/159.8 MB 11.6 MB/s eta 0:00:14\n",
      "    --------------------------------------- 2.7/159.8 MB 10.2 MB/s eta 0:00:16\n",
      "    --------------------------------------- 2.9/159.8 MB 9.4 MB/s eta 0:00:17\n",
      "    --------------------------------------- 3.1/159.8 MB 8.7 MB/s eta 0:00:18\n",
      "    --------------------------------------- 3.4/159.8 MB 8.0 MB/s eta 0:00:20\n",
      "    --------------------------------------- 3.6/159.8 MB 7.6 MB/s eta 0:00:21\n",
      "    --------------------------------------- 3.7/159.8 MB 7.4 MB/s eta 0:00:21\n",
      "    --------------------------------------- 3.9/159.8 MB 6.9 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 4.0/159.8 MB 6.6 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 4.2/159.8 MB 6.4 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 4.4/159.8 MB 6.3 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 4.6/159.8 MB 6.1 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 4.7/159.8 MB 6.0 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 5.0/159.8 MB 6.0 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 5.2/159.8 MB 6.0 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 5.4/159.8 MB 6.0 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 5.7/159.8 MB 6.0 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 5.9/159.8 MB 5.9 MB/s eta 0:00:27\n",
      "   - -------------------------------------- 6.2/159.8 MB 5.9 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 6.6/159.8 MB 6.0 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 6.9/159.8 MB 6.0 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 7.2/159.8 MB 6.1 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 7.5/159.8 MB 6.1 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 7.9/159.8 MB 6.2 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 8.2/159.8 MB 6.3 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 8.7/159.8 MB 6.4 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 9.0/159.8 MB 6.4 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 9.4/159.8 MB 6.5 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 9.8/159.8 MB 6.6 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 10.1/159.8 MB 6.6 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 10.3/159.8 MB 6.5 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 10.6/159.8 MB 6.3 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 10.8/159.8 MB 6.2 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 10.9/159.8 MB 6.0 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 11.1/159.8 MB 5.9 MB/s eta 0:00:26\n",
      "   -- ------------------------------------- 11.2/159.8 MB 5.7 MB/s eta 0:00:26\n",
      "   -- ------------------------------------- 11.4/159.8 MB 5.7 MB/s eta 0:00:27\n",
      "   -- ------------------------------------- 11.6/159.8 MB 5.6 MB/s eta 0:00:27\n",
      "   -- ------------------------------------- 11.8/159.8 MB 5.5 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 12.0/159.8 MB 5.4 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 12.2/159.8 MB 5.4 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 12.5/159.8 MB 5.3 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 12.7/159.8 MB 5.3 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 13.0/159.8 MB 5.3 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 13.3/159.8 MB 5.4 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 13.6/159.8 MB 5.5 MB/s eta 0:00:27\n",
      "   --- ------------------------------------ 13.9/159.8 MB 5.5 MB/s eta 0:00:27\n",
      "   --- ------------------------------------ 14.3/159.8 MB 5.8 MB/s eta 0:00:26\n",
      "   --- ------------------------------------ 14.6/159.8 MB 5.9 MB/s eta 0:00:25\n",
      "   --- ------------------------------------ 15.1/159.8 MB 6.1 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 15.4/159.8 MB 6.1 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 15.9/159.8 MB 6.2 MB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 16.1/159.8 MB 6.3 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 16.5/159.8 MB 6.2 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 16.8/159.8 MB 6.2 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 17.1/159.8 MB 6.2 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 17.4/159.8 MB 6.2 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 17.7/159.8 MB 6.2 MB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 17.8/159.8 MB 6.2 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 17.9/159.8 MB 6.2 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 17.9/159.8 MB 6.2 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 17.9/159.8 MB 5.7 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 18.2/159.8 MB 5.7 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 18.5/159.8 MB 5.6 MB/s eta 0:00:26\n",
      "   ---- ----------------------------------- 18.8/159.8 MB 5.6 MB/s eta 0:00:26\n",
      "   ---- ----------------------------------- 19.1/159.8 MB 5.6 MB/s eta 0:00:26\n",
      "   ---- ----------------------------------- 19.4/159.8 MB 5.5 MB/s eta 0:00:26\n",
      "   ---- ----------------------------------- 19.8/159.8 MB 5.5 MB/s eta 0:00:26\n",
      "   ----- ---------------------------------- 20.1/159.8 MB 5.6 MB/s eta 0:00:26\n",
      "   ----- ---------------------------------- 20.4/159.8 MB 5.6 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 20.8/159.8 MB 5.7 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 21.2/159.8 MB 6.0 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 21.6/159.8 MB 6.1 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 21.8/159.8 MB 6.1 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 22.0/159.8 MB 6.2 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 22.2/159.8 MB 6.2 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 22.4/159.8 MB 6.2 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 22.6/159.8 MB 6.2 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 22.7/159.8 MB 6.1 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 22.9/159.8 MB 6.1 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 23.0/159.8 MB 6.0 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 23.2/159.8 MB 6.0 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 23.5/159.8 MB 5.9 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 23.7/159.8 MB 5.9 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 24.0/159.8 MB 5.9 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 24.2/159.8 MB 5.8 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 24.4/159.8 MB 5.8 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 24.7/159.8 MB 5.7 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 25.0/159.8 MB 5.7 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 25.3/159.8 MB 5.7 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 25.6/159.8 MB 5.6 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 25.9/159.8 MB 5.7 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 26.2/159.8 MB 5.6 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 26.6/159.8 MB 5.6 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 26.8/159.8 MB 5.7 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 27.2/159.8 MB 5.7 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 27.5/159.8 MB 5.7 MB/s eta 0:00:24\n",
      "   ------ --------------------------------- 27.9/159.8 MB 5.7 MB/s eta 0:00:24\n",
      "   ------- -------------------------------- 28.3/159.8 MB 6.2 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 28.5/159.8 MB 6.2 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 28.7/159.8 MB 6.2 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 28.9/159.8 MB 6.2 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 29.2/159.8 MB 6.1 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 29.4/159.8 MB 6.1 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 29.7/159.8 MB 6.1 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 30.0/159.8 MB 6.0 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 30.3/159.8 MB 6.0 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 30.6/159.8 MB 6.0 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 30.8/159.8 MB 5.9 MB/s eta 0:00:22\n",
      "   ------- -------------------------------- 31.0/159.8 MB 5.8 MB/s eta 0:00:23\n",
      "   ------- -------------------------------- 31.1/159.8 MB 5.8 MB/s eta 0:00:23\n",
      "   ------- -------------------------------- 31.3/159.8 MB 5.7 MB/s eta 0:00:23\n",
      "   ------- -------------------------------- 31.5/159.8 MB 5.6 MB/s eta 0:00:23\n",
      "   ------- -------------------------------- 31.8/159.8 MB 5.5 MB/s eta 0:00:24\n",
      "   -------- ------------------------------- 32.0/159.8 MB 5.5 MB/s eta 0:00:24\n",
      "   -------- ------------------------------- 32.3/159.8 MB 5.5 MB/s eta 0:00:24\n",
      "   -------- ------------------------------- 32.6/159.8 MB 5.5 MB/s eta 0:00:24\n",
      "   -------- ------------------------------- 32.8/159.8 MB 5.5 MB/s eta 0:00:23\n",
      "   -------- ------------------------------- 33.0/159.8 MB 5.6 MB/s eta 0:00:23\n",
      "   -------- ------------------------------- 33.3/159.8 MB 5.7 MB/s eta 0:00:23\n",
      "   -------- ------------------------------- 33.5/159.8 MB 5.7 MB/s eta 0:00:22\n",
      "   -------- ------------------------------- 33.8/159.8 MB 5.8 MB/s eta 0:00:22\n",
      "   -------- ------------------------------- 34.1/159.8 MB 5.8 MB/s eta 0:00:22\n",
      "   -------- ------------------------------- 34.4/159.8 MB 5.9 MB/s eta 0:00:22\n",
      "   -------- ------------------------------- 34.8/159.8 MB 6.0 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 35.1/159.8 MB 6.0 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 35.4/159.8 MB 6.0 MB/s eta 0:00:21\n",
      "   -------- ------------------------------- 35.7/159.8 MB 6.1 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 36.1/159.8 MB 6.1 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 36.4/159.8 MB 6.0 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 36.7/159.8 MB 6.0 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 36.8/159.8 MB 5.9 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 37.0/159.8 MB 5.8 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 37.2/159.8 MB 5.8 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 37.4/159.8 MB 5.7 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 37.7/159.8 MB 5.6 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 37.9/159.8 MB 5.6 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 38.2/159.8 MB 5.5 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 38.5/159.8 MB 5.5 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 38.7/159.8 MB 5.5 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 38.9/159.8 MB 5.5 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 39.2/159.8 MB 5.6 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 39.5/159.8 MB 5.6 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 39.7/159.8 MB 5.6 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 40.0/159.8 MB 5.6 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 40.3/159.8 MB 5.6 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 40.5/159.8 MB 5.6 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 40.9/159.8 MB 5.6 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 41.3/159.8 MB 5.8 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 41.6/159.8 MB 6.0 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 42.0/159.8 MB 6.1 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 42.4/159.8 MB 6.3 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 42.7/159.8 MB 6.4 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 43.0/159.8 MB 6.3 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 43.1/159.8 MB 6.3 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 43.3/159.8 MB 6.2 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 43.4/159.8 MB 6.1 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 43.6/159.8 MB 6.2 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 43.7/159.8 MB 6.1 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 43.9/159.8 MB 6.0 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 44.1/159.8 MB 6.0 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 44.3/159.8 MB 5.9 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 44.6/159.8 MB 5.8 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 44.8/159.8 MB 5.8 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 45.1/159.8 MB 5.8 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 45.3/159.8 MB 5.7 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 45.6/159.8 MB 5.7 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 45.9/159.8 MB 5.7 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 46.2/159.8 MB 5.7 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 46.4/159.8 MB 5.6 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 46.8/159.8 MB 5.7 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 47.2/159.8 MB 5.8 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 47.5/159.8 MB 6.0 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 47.8/159.8 MB 6.0 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 48.1/159.8 MB 6.1 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 48.3/159.8 MB 6.0 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 48.5/159.8 MB 6.0 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 48.7/159.8 MB 6.0 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 49.0/159.8 MB 6.0 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 49.2/159.8 MB 5.9 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 49.5/159.8 MB 5.9 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 49.7/159.8 MB 5.9 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 50.0/159.8 MB 5.9 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 50.3/159.8 MB 5.8 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 50.5/159.8 MB 5.8 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 50.8/159.8 MB 5.9 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 51.1/159.8 MB 5.9 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 51.4/159.8 MB 5.9 MB/s eta 0:00:19\n",
      "   ------------ --------------------------- 51.7/159.8 MB 5.8 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 52.0/159.8 MB 5.8 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 52.3/159.8 MB 5.8 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 52.4/159.8 MB 5.7 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 52.6/159.8 MB 5.6 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 52.7/159.8 MB 5.6 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 53.0/159.8 MB 5.5 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 53.2/159.8 MB 5.5 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 53.4/159.8 MB 5.5 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 53.6/159.8 MB 5.6 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 53.9/159.8 MB 5.7 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 54.2/159.8 MB 5.8 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 54.4/159.8 MB 5.8 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 54.8/159.8 MB 5.9 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 55.0/159.8 MB 6.0 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 55.2/159.8 MB 6.0 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 55.4/159.8 MB 5.9 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 55.5/159.8 MB 5.8 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 55.6/159.8 MB 5.7 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 55.7/159.8 MB 5.6 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 55.8/159.8 MB 5.5 MB/s eta 0:00:19\n",
      "   -------------- ------------------------- 56.0/159.8 MB 5.5 MB/s eta 0:00:19\n",
      "   -------------- ------------------------- 56.2/159.8 MB 5.5 MB/s eta 0:00:19\n",
      "   -------------- ------------------------- 56.3/159.8 MB 5.4 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 56.5/159.8 MB 5.3 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 56.6/159.8 MB 5.2 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 56.7/159.8 MB 5.2 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 56.8/159.8 MB 5.1 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 56.8/159.8 MB 5.0 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 56.9/159.8 MB 4.9 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 56.9/159.8 MB 4.9 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 57.0/159.8 MB 4.8 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 57.1/159.8 MB 4.7 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 57.1/159.8 MB 4.6 MB/s eta 0:00:23\n",
      "   -------------- ------------------------- 57.1/159.8 MB 4.5 MB/s eta 0:00:23\n",
      "   -------------- ------------------------- 57.1/159.8 MB 4.4 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 57.2/159.8 MB 4.3 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 57.2/159.8 MB 4.2 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 57.2/159.8 MB 4.1 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 57.2/159.8 MB 4.1 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 57.3/159.8 MB 4.0 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 57.3/159.8 MB 3.9 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 57.3/159.8 MB 3.9 MB/s eta 0:00:27\n",
      "   -------------- ------------------------- 57.3/159.8 MB 3.8 MB/s eta 0:00:27\n",
      "   -------------- ------------------------- 57.4/159.8 MB 3.7 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 57.4/159.8 MB 3.7 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 57.5/159.8 MB 3.7 MB/s eta 0:00:28\n",
      "   -------------- ------------------------- 57.5/159.8 MB 3.6 MB/s eta 0:00:29\n",
      "   -------------- ------------------------- 57.6/159.8 MB 3.6 MB/s eta 0:00:29\n",
      "   -------------- ------------------------- 57.7/159.8 MB 3.5 MB/s eta 0:00:30\n",
      "   -------------- ------------------------- 57.8/159.8 MB 3.5 MB/s eta 0:00:30\n",
      "   -------------- ------------------------- 57.9/159.8 MB 3.4 MB/s eta 0:00:30\n",
      "   -------------- ------------------------- 58.1/159.8 MB 3.4 MB/s eta 0:00:30\n",
      "   -------------- ------------------------- 58.1/159.8 MB 3.4 MB/s eta 0:00:30\n",
      "   -------------- ------------------------- 58.3/159.8 MB 3.4 MB/s eta 0:00:31\n",
      "   -------------- ------------------------- 58.4/159.8 MB 3.4 MB/s eta 0:00:31\n",
      "   -------------- ------------------------- 58.6/159.8 MB 3.3 MB/s eta 0:00:31\n",
      "   -------------- ------------------------- 58.8/159.8 MB 3.3 MB/s eta 0:00:31\n",
      "   -------------- ------------------------- 58.9/159.8 MB 3.3 MB/s eta 0:00:31\n",
      "   -------------- ------------------------- 59.0/159.8 MB 3.3 MB/s eta 0:00:31\n",
      "   -------------- ------------------------- 59.2/159.8 MB 3.3 MB/s eta 0:00:31\n",
      "   -------------- ------------------------- 59.3/159.8 MB 3.3 MB/s eta 0:00:31\n",
      "   -------------- ------------------------- 59.4/159.8 MB 3.3 MB/s eta 0:00:31\n",
      "   -------------- ------------------------- 59.5/159.8 MB 3.2 MB/s eta 0:00:32\n",
      "   -------------- ------------------------- 59.6/159.8 MB 3.2 MB/s eta 0:00:32\n",
      "   -------------- ------------------------- 59.7/159.8 MB 3.2 MB/s eta 0:00:32\n",
      "   -------------- ------------------------- 59.7/159.8 MB 3.1 MB/s eta 0:00:32\n",
      "   -------------- ------------------------- 59.8/159.8 MB 3.1 MB/s eta 0:00:33\n",
      "   -------------- ------------------------- 59.8/159.8 MB 3.1 MB/s eta 0:00:33\n",
      "   -------------- ------------------------- 59.8/159.8 MB 3.0 MB/s eta 0:00:33\n",
      "   -------------- ------------------------- 59.8/159.8 MB 3.0 MB/s eta 0:00:33\n",
      "   -------------- ------------------------- 59.9/159.8 MB 2.9 MB/s eta 0:00:34\n",
      "   -------------- ------------------------- 59.9/159.8 MB 2.9 MB/s eta 0:00:35\n",
      "   -------------- ------------------------- 59.9/159.8 MB 2.9 MB/s eta 0:00:35\n",
      "   --------------- ------------------------ 60.0/159.8 MB 2.8 MB/s eta 0:00:36\n",
      "   --------------- ------------------------ 60.0/159.8 MB 2.8 MB/s eta 0:00:36\n",
      "   --------------- ------------------------ 60.1/159.8 MB 2.8 MB/s eta 0:00:36\n",
      "   --------------- ------------------------ 60.2/159.8 MB 2.8 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 60.3/159.8 MB 2.8 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 60.5/159.8 MB 2.7 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 60.7/159.8 MB 2.7 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 60.9/159.8 MB 2.7 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 61.0/159.8 MB 2.7 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 61.0/159.8 MB 2.7 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 61.0/159.8 MB 2.7 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 61.0/159.8 MB 2.7 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 61.0/159.8 MB 2.7 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 61.0/159.8 MB 2.7 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 61.1/159.8 MB 2.5 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 61.2/159.8 MB 2.5 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 61.4/159.8 MB 2.5 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 61.6/159.8 MB 2.5 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 61.7/159.8 MB 2.5 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 61.7/159.8 MB 2.4 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 61.8/159.8 MB 2.4 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 61.9/159.8 MB 2.4 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 62.0/159.8 MB 2.4 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 62.1/159.8 MB 2.4 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 62.2/159.8 MB 2.4 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 62.3/159.8 MB 2.4 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 62.3/159.8 MB 2.3 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 62.4/159.8 MB 2.3 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 62.4/159.8 MB 2.3 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 62.4/159.8 MB 2.3 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 62.4/159.8 MB 2.3 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 62.4/159.8 MB 2.3 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 62.4/159.8 MB 2.3 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 62.4/159.8 MB 2.2 MB/s eta 0:00:45\n",
      "   --------------- ------------------------ 62.4/159.8 MB 2.2 MB/s eta 0:00:45\n",
      "   --------------- ------------------------ 62.5/159.8 MB 2.1 MB/s eta 0:00:46\n",
      "   --------------- ------------------------ 62.5/159.8 MB 2.1 MB/s eta 0:00:46\n",
      "   --------------- ------------------------ 62.6/159.8 MB 2.1 MB/s eta 0:00:47\n",
      "   --------------- ------------------------ 62.7/159.8 MB 2.1 MB/s eta 0:00:47\n",
      "   --------------- ------------------------ 62.8/159.8 MB 2.1 MB/s eta 0:00:47\n",
      "   --------------- ------------------------ 62.9/159.8 MB 2.1 MB/s eta 0:00:47\n",
      "   --------------- ------------------------ 63.1/159.8 MB 2.1 MB/s eta 0:00:47\n",
      "   --------------- ------------------------ 63.2/159.8 MB 2.1 MB/s eta 0:00:47\n",
      "   --------------- ------------------------ 63.2/159.8 MB 2.1 MB/s eta 0:00:47\n",
      "   --------------- ------------------------ 63.3/159.8 MB 2.1 MB/s eta 0:00:48\n",
      "   --------------- ------------------------ 63.3/159.8 MB 2.0 MB/s eta 0:00:48\n",
      "   --------------- ------------------------ 63.4/159.8 MB 2.0 MB/s eta 0:00:48\n",
      "   --------------- ------------------------ 63.5/159.8 MB 2.0 MB/s eta 0:00:48\n",
      "   --------------- ------------------------ 63.5/159.8 MB 2.0 MB/s eta 0:00:48\n",
      "   --------------- ------------------------ 63.5/159.8 MB 2.0 MB/s eta 0:00:48\n",
      "   --------------- ------------------------ 63.5/159.8 MB 2.0 MB/s eta 0:00:48\n",
      "   --------------- ------------------------ 63.5/159.8 MB 2.0 MB/s eta 0:00:48\n",
      "   --------------- ------------------------ 63.5/159.8 MB 1.9 MB/s eta 0:00:51\n",
      "   --------------- ------------------------ 63.6/159.8 MB 1.9 MB/s eta 0:00:51\n",
      "   --------------- ------------------------ 63.7/159.8 MB 1.9 MB/s eta 0:00:51\n",
      "   --------------- ------------------------ 63.8/159.8 MB 1.9 MB/s eta 0:00:51\n",
      "   --------------- ------------------------ 63.9/159.8 MB 1.9 MB/s eta 0:00:51\n",
      "   ---------------- ----------------------- 64.1/159.8 MB 1.9 MB/s eta 0:00:51\n",
      "   ---------------- ----------------------- 64.3/159.8 MB 1.9 MB/s eta 0:00:51\n",
      "   ---------------- ----------------------- 64.5/159.8 MB 1.9 MB/s eta 0:00:51\n",
      "   ---------------- ----------------------- 64.6/159.8 MB 1.9 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 64.7/159.8 MB 1.9 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 64.7/159.8 MB 1.9 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 64.7/159.8 MB 1.9 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 64.7/159.8 MB 1.9 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 64.7/159.8 MB 1.9 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 64.7/159.8 MB 1.9 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 64.8/159.8 MB 1.8 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 64.9/159.8 MB 1.8 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 65.0/159.8 MB 1.8 MB/s eta 0:00:55\n",
      "   ---------------- ----------------------- 65.0/159.8 MB 1.7 MB/s eta 0:00:55\n",
      "   ---------------- ----------------------- 65.1/159.8 MB 1.7 MB/s eta 0:00:55\n",
      "   ---------------- ----------------------- 65.2/159.8 MB 1.7 MB/s eta 0:00:56\n",
      "   ---------------- ----------------------- 65.3/159.8 MB 1.7 MB/s eta 0:00:56\n",
      "   ---------------- ----------------------- 65.4/159.8 MB 1.7 MB/s eta 0:00:56\n",
      "   ---------------- ----------------------- 65.5/159.8 MB 1.7 MB/s eta 0:00:56\n",
      "   ---------------- ----------------------- 65.6/159.8 MB 1.7 MB/s eta 0:00:56\n",
      "   ---------------- ----------------------- 65.8/159.8 MB 1.7 MB/s eta 0:00:56\n",
      "   ---------------- ----------------------- 65.9/159.8 MB 1.7 MB/s eta 0:00:55\n",
      "   ---------------- ----------------------- 66.1/159.8 MB 1.7 MB/s eta 0:00:55\n",
      "   ---------------- ----------------------- 66.1/159.8 MB 1.7 MB/s eta 0:00:55\n",
      "   ---------------- ----------------------- 66.2/159.8 MB 1.7 MB/s eta 0:00:56\n",
      "   ---------------- ----------------------- 66.2/159.8 MB 1.7 MB/s eta 0:00:56\n",
      "   ---------------- ----------------------- 66.2/159.8 MB 1.7 MB/s eta 0:00:56\n",
      "   ---------------- ----------------------- 66.2/159.8 MB 1.7 MB/s eta 0:00:56\n",
      "   ---------------- ----------------------- 66.2/159.8 MB 1.7 MB/s eta 0:00:56\n",
      "   ---------------- ----------------------- 66.2/159.8 MB 1.7 MB/s eta 0:00:56\n",
      "   ---------------- ----------------------- 66.2/159.8 MB 1.6 MB/s eta 0:00:58\n",
      "   ---------------- ----------------------- 66.3/159.8 MB 1.6 MB/s eta 0:00:58\n",
      "   ---------------- ----------------------- 66.3/159.8 MB 1.6 MB/s eta 0:00:58\n",
      "   ---------------- ----------------------- 66.4/159.8 MB 1.6 MB/s eta 0:00:59\n",
      "   ---------------- ----------------------- 66.5/159.8 MB 1.6 MB/s eta 0:00:59\n",
      "   ---------------- ----------------------- 66.6/159.8 MB 1.6 MB/s eta 0:00:59\n",
      "   ---------------- ----------------------- 66.8/159.8 MB 1.6 MB/s eta 0:00:58\n",
      "   ---------------- ----------------------- 67.0/159.8 MB 1.6 MB/s eta 0:00:58\n",
      "   ---------------- ----------------------- 67.2/159.8 MB 1.6 MB/s eta 0:00:57\n",
      "   ---------------- ----------------------- 67.4/159.8 MB 1.7 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 67.8/159.8 MB 1.8 MB/s eta 0:00:50\n",
      "   ----------------- ---------------------- 68.2/159.8 MB 1.9 MB/s eta 0:00:49\n",
      "   ----------------- ---------------------- 68.8/159.8 MB 1.9 MB/s eta 0:00:47\n",
      "   ----------------- ---------------------- 68.9/159.8 MB 1.9 MB/s eta 0:00:47\n",
      "   ----------------- ---------------------- 69.2/159.8 MB 2.0 MB/s eta 0:00:47\n",
      "   ----------------- ---------------------- 69.3/159.8 MB 2.0 MB/s eta 0:00:47\n",
      "   ----------------- ---------------------- 69.5/159.8 MB 2.0 MB/s eta 0:00:47\n",
      "   ----------------- ---------------------- 69.6/159.8 MB 2.0 MB/s eta 0:00:47\n",
      "   ----------------- ---------------------- 69.7/159.8 MB 2.0 MB/s eta 0:00:46\n",
      "   ----------------- ---------------------- 69.9/159.8 MB 2.0 MB/s eta 0:00:46\n",
      "   ----------------- ---------------------- 70.0/159.8 MB 2.0 MB/s eta 0:00:46\n",
      "   ----------------- ---------------------- 70.1/159.8 MB 2.0 MB/s eta 0:00:45\n",
      "   ----------------- ---------------------- 70.2/159.8 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 70.3/159.8 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 70.5/159.8 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 70.6/159.8 MB 2.1 MB/s eta 0:00:42\n",
      "   ----------------- ---------------------- 70.7/159.8 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 70.8/159.8 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 70.9/159.8 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 71.0/159.8 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 71.1/159.8 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 71.1/159.8 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 71.1/159.8 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 71.1/159.8 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 71.1/159.8 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 71.1/159.8 MB 2.0 MB/s eta 0:00:45\n",
      "   ----------------- ---------------------- 71.2/159.8 MB 2.0 MB/s eta 0:00:45\n",
      "   ----------------- ---------------------- 71.3/159.8 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 71.4/159.8 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 71.5/159.8 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 71.7/159.8 MB 2.1 MB/s eta 0:00:43\n",
      "   ------------------ --------------------- 72.0/159.8 MB 2.1 MB/s eta 0:00:43\n",
      "   ------------------ --------------------- 72.3/159.8 MB 2.1 MB/s eta 0:00:42\n",
      "   ------------------ --------------------- 72.6/159.8 MB 2.3 MB/s eta 0:00:38\n",
      "   ------------------ --------------------- 73.0/159.8 MB 2.4 MB/s eta 0:00:36\n",
      "   ------------------ --------------------- 73.3/159.8 MB 2.5 MB/s eta 0:00:36\n",
      "   ------------------ --------------------- 73.3/159.8 MB 2.5 MB/s eta 0:00:36\n",
      "   ------------------ --------------------- 73.3/159.8 MB 2.5 MB/s eta 0:00:36\n",
      "   ------------------ --------------------- 73.3/159.8 MB 2.5 MB/s eta 0:00:36\n",
      "   ------------------ --------------------- 73.3/159.8 MB 2.5 MB/s eta 0:00:36\n",
      "   ------------------ --------------------- 73.3/159.8 MB 2.5 MB/s eta 0:00:36\n",
      "   ------------------ --------------------- 73.4/159.8 MB 2.3 MB/s eta 0:00:38\n",
      "   ------------------ --------------------- 73.5/159.8 MB 2.4 MB/s eta 0:00:37\n",
      "   ------------------ --------------------- 73.7/159.8 MB 2.5 MB/s eta 0:00:34\n",
      "   ------------------ --------------------- 73.8/159.8 MB 2.5 MB/s eta 0:00:35\n",
      "   ------------------ --------------------- 73.9/159.8 MB 2.5 MB/s eta 0:00:35\n",
      "   ------------------ --------------------- 74.0/159.8 MB 2.5 MB/s eta 0:00:34\n",
      "   ------------------ --------------------- 74.2/159.8 MB 2.5 MB/s eta 0:00:34\n",
      "   ------------------ --------------------- 74.3/159.8 MB 2.5 MB/s eta 0:00:34\n",
      "   ------------------ --------------------- 74.5/159.8 MB 2.5 MB/s eta 0:00:34\n",
      "   ------------------ --------------------- 74.7/159.8 MB 2.5 MB/s eta 0:00:34\n",
      "   ------------------ --------------------- 74.7/159.8 MB 2.5 MB/s eta 0:00:35\n",
      "   ------------------ --------------------- 74.8/159.8 MB 2.5 MB/s eta 0:00:35\n",
      "   ------------------ --------------------- 74.8/159.8 MB 2.5 MB/s eta 0:00:35\n",
      "   ------------------ --------------------- 74.8/159.8 MB 2.5 MB/s eta 0:00:35\n",
      "   ------------------ --------------------- 74.8/159.8 MB 2.5 MB/s eta 0:00:35\n",
      "   ------------------ --------------------- 74.8/159.8 MB 2.5 MB/s eta 0:00:35\n",
      "   ------------------ --------------------- 74.8/159.8 MB 2.5 MB/s eta 0:00:35\n",
      "   ------------------ --------------------- 74.8/159.8 MB 2.3 MB/s eta 0:00:37\n",
      "   ------------------ --------------------- 74.9/159.8 MB 2.3 MB/s eta 0:00:37\n",
      "   ------------------ --------------------- 75.0/159.8 MB 2.5 MB/s eta 0:00:35\n",
      "   ------------------ --------------------- 75.2/159.8 MB 2.5 MB/s eta 0:00:35\n",
      "   ------------------ --------------------- 75.3/159.8 MB 2.5 MB/s eta 0:00:34\n",
      "   ------------------ --------------------- 75.6/159.8 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 75.9/159.8 MB 2.6 MB/s eta 0:00:33\n",
      "   ------------------- -------------------- 76.3/159.8 MB 2.6 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 76.4/159.8 MB 2.9 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 76.7/159.8 MB 3.0 MB/s eta 0:00:28\n",
      "   ------------------- -------------------- 76.7/159.8 MB 3.0 MB/s eta 0:00:28\n",
      "   ------------------- -------------------- 76.8/159.8 MB 2.9 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 76.8/159.8 MB 2.9 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 76.8/159.8 MB 2.9 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 76.8/159.8 MB 2.9 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 76.8/159.8 MB 2.9 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 76.8/159.8 MB 2.9 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 76.8/159.8 MB 2.9 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 76.9/159.8 MB 2.7 MB/s eta 0:00:31\n",
      "   ------------------- -------------------- 76.9/159.8 MB 2.7 MB/s eta 0:00:31\n",
      "   ------------------- -------------------- 76.9/159.8 MB 2.7 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 77.0/159.8 MB 2.7 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 77.1/159.8 MB 2.6 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 77.3/159.8 MB 2.6 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 77.4/159.8 MB 2.6 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 77.6/159.8 MB 2.6 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 77.8/159.8 MB 2.6 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 78.1/159.8 MB 2.6 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 78.4/159.8 MB 2.6 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 78.8/159.8 MB 2.6 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 79.2/159.8 MB 2.6 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 79.7/159.8 MB 2.7 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 80.3/159.8 MB 2.8 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 80.6/159.8 MB 2.8 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 80.7/159.8 MB 2.8 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 80.7/159.8 MB 2.8 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 80.7/159.8 MB 2.8 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 80.7/159.8 MB 2.8 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 80.7/159.8 MB 2.8 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 80.7/159.8 MB 2.8 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 80.8/159.8 MB 2.6 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 80.9/159.8 MB 2.6 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 80.9/159.8 MB 2.6 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 80.9/159.8 MB 2.6 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 81.1/159.8 MB 2.6 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 81.1/159.8 MB 2.6 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 81.1/159.8 MB 2.6 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 81.1/159.8 MB 2.6 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 81.1/159.8 MB 2.6 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 81.1/159.8 MB 2.6 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 81.2/159.8 MB 2.4 MB/s eta 0:00:33\n",
      "   -------------------- ------------------- 81.2/159.8 MB 2.4 MB/s eta 0:00:33\n",
      "   -------------------- ------------------- 81.3/159.8 MB 2.4 MB/s eta 0:00:33\n",
      "   -------------------- ------------------- 81.3/159.8 MB 2.4 MB/s eta 0:00:33\n",
      "   -------------------- ------------------- 81.4/159.8 MB 2.5 MB/s eta 0:00:32\n",
      "   -------------------- ------------------- 81.4/159.8 MB 2.5 MB/s eta 0:00:32\n",
      "   -------------------- ------------------- 81.4/159.8 MB 2.5 MB/s eta 0:00:32\n",
      "   -------------------- ------------------- 81.4/159.8 MB 2.5 MB/s eta 0:00:32\n",
      "   -------------------- ------------------- 81.4/159.8 MB 2.5 MB/s eta 0:00:32\n",
      "   -------------------- ------------------- 81.4/159.8 MB 2.5 MB/s eta 0:00:32\n",
      "   -------------------- ------------------- 81.4/159.8 MB 2.5 MB/s eta 0:00:32\n",
      "   -------------------- ------------------- 81.4/159.8 MB 2.4 MB/s eta 0:00:34\n",
      "   -------------------- ------------------- 81.4/159.8 MB 2.4 MB/s eta 0:00:34\n",
      "   -------------------- ------------------- 81.5/159.8 MB 2.3 MB/s eta 0:00:34\n",
      "   -------------------- ------------------- 81.5/159.8 MB 2.3 MB/s eta 0:00:34\n",
      "   -------------------- ------------------- 81.6/159.8 MB 2.3 MB/s eta 0:00:34\n",
      "   -------------------- ------------------- 81.6/159.8 MB 2.3 MB/s eta 0:00:34\n",
      "   -------------------- ------------------- 81.7/159.8 MB 2.3 MB/s eta 0:00:34\n",
      "   -------------------- ------------------- 81.8/159.8 MB 2.3 MB/s eta 0:00:34\n",
      "   -------------------- ------------------- 81.9/159.8 MB 2.3 MB/s eta 0:00:35\n",
      "   -------------------- ------------------- 82.0/159.8 MB 2.3 MB/s eta 0:00:34\n",
      "   -------------------- ------------------- 82.1/159.8 MB 2.3 MB/s eta 0:00:35\n",
      "   -------------------- ------------------- 82.1/159.8 MB 2.2 MB/s eta 0:00:35\n",
      "   -------------------- ------------------- 82.1/159.8 MB 2.2 MB/s eta 0:00:35\n",
      "   -------------------- ------------------- 82.2/159.8 MB 2.2 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 82.3/159.8 MB 2.2 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 82.4/159.8 MB 2.2 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 82.4/159.8 MB 2.2 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 82.6/159.8 MB 2.2 MB/s eta 0:00:36\n",
      "   -------------------- ------------------- 82.7/159.8 MB 2.1 MB/s eta 0:00:37\n",
      "   -------------------- ------------------- 82.9/159.8 MB 2.1 MB/s eta 0:00:37\n",
      "   -------------------- ------------------- 83.0/159.8 MB 2.1 MB/s eta 0:00:37\n",
      "   -------------------- ------------------- 83.2/159.8 MB 2.1 MB/s eta 0:00:37\n",
      "   -------------------- ------------------- 83.4/159.8 MB 2.1 MB/s eta 0:00:37\n",
      "   -------------------- ------------------- 83.7/159.8 MB 2.2 MB/s eta 0:00:35\n",
      "   -------------------- ------------------- 83.9/159.8 MB 2.2 MB/s eta 0:00:35\n",
      "   --------------------- ------------------ 84.1/159.8 MB 2.3 MB/s eta 0:00:34\n",
      "   --------------------- ------------------ 84.2/159.8 MB 2.3 MB/s eta 0:00:34\n",
      "   --------------------- ------------------ 84.5/159.8 MB 2.3 MB/s eta 0:00:34\n",
      "   --------------------- ------------------ 84.7/159.8 MB 2.3 MB/s eta 0:00:33\n",
      "   --------------------- ------------------ 85.0/159.8 MB 2.4 MB/s eta 0:00:32\n",
      "   --------------------- ------------------ 85.3/159.8 MB 2.6 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 85.6/159.8 MB 2.6 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 85.9/159.8 MB 2.6 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 86.2/159.8 MB 2.6 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 86.5/159.8 MB 2.6 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 86.8/159.8 MB 2.6 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 87.2/159.8 MB 2.9 MB/s eta 0:00:25\n",
      "   --------------------- ------------------ 87.5/159.8 MB 3.0 MB/s eta 0:00:24\n",
      "   ---------------------- ----------------- 87.9/159.8 MB 3.1 MB/s eta 0:00:24\n",
      "   ---------------------- ----------------- 88.2/159.8 MB 3.1 MB/s eta 0:00:24\n",
      "   ---------------------- ----------------- 88.7/159.8 MB 3.1 MB/s eta 0:00:24\n",
      "   ---------------------- ----------------- 89.0/159.8 MB 3.1 MB/s eta 0:00:23\n",
      "   ---------------------- ----------------- 89.3/159.8 MB 3.1 MB/s eta 0:00:23\n",
      "   ---------------------- ----------------- 89.7/159.8 MB 3.1 MB/s eta 0:00:23\n",
      "   ---------------------- ----------------- 90.2/159.8 MB 3.1 MB/s eta 0:00:23\n",
      "   ---------------------- ----------------- 90.5/159.8 MB 3.1 MB/s eta 0:00:23\n",
      "   ---------------------- ----------------- 90.8/159.8 MB 3.1 MB/s eta 0:00:23\n",
      "   ---------------------- ----------------- 91.0/159.8 MB 3.3 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 91.1/159.8 MB 3.4 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 91.3/159.8 MB 3.4 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 91.4/159.8 MB 3.7 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 91.5/159.8 MB 3.7 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 91.7/159.8 MB 4.4 MB/s eta 0:00:16\n",
      "   ---------------------- ----------------- 91.8/159.8 MB 4.5 MB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 92.0/159.8 MB 4.6 MB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 92.3/159.8 MB 4.8 MB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 92.5/159.8 MB 5.1 MB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 92.7/159.8 MB 5.4 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 92.9/159.8 MB 5.5 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 93.2/159.8 MB 5.6 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 93.4/159.8 MB 5.6 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 93.6/159.8 MB 5.6 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 93.9/159.8 MB 5.7 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 94.2/159.8 MB 5.6 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 94.4/159.8 MB 5.7 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 94.7/159.8 MB 5.8 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 95.0/159.8 MB 5.8 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 95.2/159.8 MB 5.7 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 95.5/159.8 MB 5.8 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 95.7/159.8 MB 5.8 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 96.1/159.8 MB 5.8 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 96.3/159.8 MB 5.8 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 96.6/159.8 MB 5.8 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 96.9/159.8 MB 5.8 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 97.2/159.8 MB 5.8 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 97.6/159.8 MB 5.8 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 97.9/159.8 MB 5.8 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 98.4/159.8 MB 5.9 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 98.9/159.8 MB 5.9 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 99.3/159.8 MB 6.0 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 99.8/159.8 MB 6.0 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 100.2/159.8 MB 6.0 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 100.5/159.8 MB 5.9 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 100.6/159.8 MB 5.8 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 100.7/159.8 MB 5.7 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 100.9/159.8 MB 5.7 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 101.0/159.8 MB 5.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 101.0/159.8 MB 5.5 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 101.1/159.8 MB 5.4 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 101.1/159.8 MB 5.4 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 101.1/159.8 MB 5.2 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 101.2/159.8 MB 5.1 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 101.3/159.8 MB 5.1 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 101.5/159.8 MB 5.1 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 101.6/159.8 MB 5.1 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 101.7/159.8 MB 5.1 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 101.9/159.8 MB 5.2 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 102.0/159.8 MB 5.2 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 102.2/159.8 MB 5.1 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 102.5/159.8 MB 5.1 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 102.7/159.8 MB 5.1 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 102.9/159.8 MB 5.0 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 103.2/159.8 MB 5.1 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 103.5/159.8 MB 5.1 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 103.7/159.8 MB 5.2 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 104.0/159.8 MB 5.1 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 104.2/159.8 MB 5.1 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 104.5/159.8 MB 5.1 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 104.8/159.8 MB 5.1 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 105.1/159.8 MB 5.1 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 105.4/159.8 MB 5.2 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 105.7/159.8 MB 5.1 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 106.0/159.8 MB 5.1 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 106.3/159.8 MB 5.1 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 106.6/159.8 MB 5.1 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 106.9/159.8 MB 5.2 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 107.3/159.8 MB 5.1 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 107.6/159.8 MB 5.1 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 107.9/159.8 MB 5.1 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 108.3/159.8 MB 5.2 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 108.7/159.8 MB 5.1 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 109.1/159.8 MB 5.1 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 109.4/159.8 MB 5.1 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 109.7/159.8 MB 5.0 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 109.9/159.8 MB 5.0 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 110.1/159.8 MB 4.9 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 110.2/159.8 MB 4.9 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 110.4/159.8 MB 4.8 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 110.6/159.8 MB 4.8 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 110.8/159.8 MB 4.8 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 110.9/159.8 MB 4.8 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 111.1/159.8 MB 4.8 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 111.3/159.8 MB 5.1 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 111.6/159.8 MB 5.5 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 111.8/159.8 MB 5.6 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 112.1/159.8 MB 5.7 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 112.4/159.8 MB 5.8 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 112.7/159.8 MB 5.8 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 113.0/159.8 MB 6.0 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 113.2/159.8 MB 6.0 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 113.5/159.8 MB 6.0 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 113.8/159.8 MB 6.0 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 114.0/159.8 MB 6.0 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 114.3/159.8 MB 6.0 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 114.6/159.8 MB 6.0 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 114.8/159.8 MB 6.0 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 115.1/159.8 MB 6.0 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 115.4/159.8 MB 6.0 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 115.6/159.8 MB 6.0 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 116.0/159.8 MB 6.1 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 116.3/159.8 MB 6.1 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 116.7/159.8 MB 6.1 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 117.1/159.8 MB 6.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 117.4/159.8 MB 6.2 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 117.8/159.8 MB 6.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 118.1/159.8 MB 6.2 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 118.5/159.8 MB 6.2 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 118.8/159.8 MB 6.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 119.0/159.8 MB 6.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 119.3/159.8 MB 6.0 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 119.6/159.8 MB 6.0 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 120.0/159.8 MB 6.0 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 120.1/159.8 MB 6.0 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 120.3/159.8 MB 6.0 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 120.4/159.8 MB 6.0 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 120.6/159.8 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 120.8/159.8 MB 5.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 121.0/159.8 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 121.1/159.8 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 121.3/159.8 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 121.6/159.8 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 121.8/159.8 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 121.9/159.8 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 122.2/159.8 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 122.4/159.8 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 122.7/159.8 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 123.0/159.8 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 123.2/159.8 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 123.5/159.8 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 123.8/159.8 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 124.1/159.8 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 124.4/159.8 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 124.7/159.8 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 125.0/159.8 MB 5.8 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 125.4/159.8 MB 5.8 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 125.7/159.8 MB 5.8 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 126.0/159.8 MB 5.8 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 126.4/159.8 MB 5.8 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 126.8/159.8 MB 5.8 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 127.2/159.8 MB 5.8 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 127.6/159.8 MB 5.9 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 127.9/159.8 MB 5.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 128.3/159.8 MB 5.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 128.6/159.8 MB 5.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 129.0/159.8 MB 5.8 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 129.3/159.8 MB 5.9 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 129.6/159.8 MB 5.9 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 129.9/159.8 MB 6.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 130.1/159.8 MB 5.9 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 130.3/159.8 MB 5.9 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 130.5/159.8 MB 6.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 130.8/159.8 MB 6.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 131.0/159.8 MB 6.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 131.2/159.8 MB 6.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 131.3/159.8 MB 6.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 131.5/159.8 MB 6.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 131.6/159.8 MB 6.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 131.8/159.8 MB 6.0 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 132.0/159.8 MB 6.0 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 132.2/159.8 MB 6.0 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 132.3/159.8 MB 6.0 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 132.5/159.8 MB 5.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 132.7/159.8 MB 5.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 132.9/159.8 MB 5.7 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 133.1/159.8 MB 5.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 133.4/159.8 MB 5.7 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 133.7/159.8 MB 5.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 133.9/159.8 MB 5.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 134.3/159.8 MB 5.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 134.5/159.8 MB 5.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 134.9/159.8 MB 5.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 135.2/159.8 MB 5.9 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 135.5/159.8 MB 5.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 135.8/159.8 MB 5.9 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 136.2/159.8 MB 5.9 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 136.5/159.8 MB 5.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 136.8/159.8 MB 5.8 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 137.1/159.8 MB 5.8 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 137.3/159.8 MB 5.7 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 137.7/159.8 MB 5.7 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 138.0/159.8 MB 5.7 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 138.4/159.8 MB 5.8 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 138.7/159.8 MB 5.7 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 139.1/159.8 MB 5.7 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 139.5/159.8 MB 5.8 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 139.8/159.8 MB 5.8 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 140.1/159.8 MB 5.8 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 140.3/159.8 MB 5.8 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 140.4/159.8 MB 5.7 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 140.5/159.8 MB 5.6 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 140.6/159.8 MB 5.5 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 140.7/159.8 MB 5.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 140.9/159.8 MB 5.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 141.0/159.8 MB 5.3 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 141.1/159.8 MB 5.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 141.3/159.8 MB 5.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 141.4/159.8 MB 5.3 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 141.7/159.8 MB 5.3 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 141.9/159.8 MB 5.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 142.1/159.8 MB 5.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 142.3/159.8 MB 5.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 142.6/159.8 MB 5.5 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 142.8/159.8 MB 5.5 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 143.0/159.8 MB 5.5 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 143.3/159.8 MB 5.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 143.6/159.8 MB 5.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 143.8/159.8 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 144.1/159.8 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 144.3/159.8 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 144.5/159.8 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 144.8/159.8 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 145.1/159.8 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 145.4/159.8 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 145.7/159.8 MB 5.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 146.1/159.8 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 146.4/159.8 MB 5.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 146.7/159.8 MB 5.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 147.1/159.8 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 147.5/159.8 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 147.8/159.8 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 148.1/159.8 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 148.4/159.8 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 148.7/159.8 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 149.1/159.8 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 149.5/159.8 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 149.7/159.8 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 150.0/159.8 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 150.2/159.8 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 150.5/159.8 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 150.8/159.8 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 151.1/159.8 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 151.4/159.8 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 151.7/159.8 MB 6.3 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 151.9/159.8 MB 6.3 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 152.1/159.8 MB 6.3 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 152.3/159.8 MB 6.3 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 152.5/159.8 MB 6.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 152.6/159.8 MB 6.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 152.8/159.8 MB 6.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 153.0/159.8 MB 6.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 153.2/159.8 MB 6.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 153.4/159.8 MB 6.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 153.6/159.8 MB 6.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 153.9/159.8 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 154.1/159.8 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 154.3/159.8 MB 5.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 154.6/159.8 MB 5.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 154.9/159.8 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 155.2/159.8 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 155.4/159.8 MB 5.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 155.7/159.8 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  156.0/159.8 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  156.4/159.8 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  156.8/159.8 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  157.2/159.8 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  157.6/159.8 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  157.9/159.8 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  158.3/159.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  158.7/159.8 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  158.9/159.8 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  159.2/159.8 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  159.5/159.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  159.7/159.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  159.8/159.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  159.8/159.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  159.8/159.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  159.8/159.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  159.8/159.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  159.8/159.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  159.8/159.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  159.8/159.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  159.8/159.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  159.8/159.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  159.8/159.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  159.8/159.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  159.8/159.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 159.8/159.8 MB 4.3 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.18.0-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.1/1.2 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.3/1.2 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.6/1.2 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 0.8/1.2 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.0/1.2 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.1/1.2 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.3.0-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.2/2.4 MB 6.9 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.5/2.4 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.8/2.4 MB 7.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 6.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.4/2.4 MB 6.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.7/2.4 MB 6.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 6.0 MB/s eta 0:00:00\n",
      "Downloading mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "   ---------------------------------------- 0.0/228.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.4/228.5 MB 13.9 MB/s eta 0:00:17\n",
      "   ---------------------------------------- 0.8/228.5 MB 9.8 MB/s eta 0:00:24\n",
      "   ---------------------------------------- 1.2/228.5 MB 8.6 MB/s eta 0:00:27\n",
      "   ---------------------------------------- 1.5/228.5 MB 9.8 MB/s eta 0:00:24\n",
      "   ---------------------------------------- 1.9/228.5 MB 9.4 MB/s eta 0:00:25\n",
      "   ---------------------------------------- 2.3/228.5 MB 8.7 MB/s eta 0:00:26\n",
      "   ---------------------------------------- 2.7/228.5 MB 9.1 MB/s eta 0:00:25\n",
      "    --------------------------------------- 3.2/228.5 MB 9.2 MB/s eta 0:00:25\n",
      "    --------------------------------------- 3.5/228.5 MB 8.3 MB/s eta 0:00:28\n",
      "    --------------------------------------- 3.8/228.5 MB 8.3 MB/s eta 0:00:28\n",
      "    --------------------------------------- 3.9/228.5 MB 7.8 MB/s eta 0:00:29\n",
      "    --------------------------------------- 4.1/228.5 MB 7.5 MB/s eta 0:00:31\n",
      "    --------------------------------------- 4.2/228.5 MB 7.1 MB/s eta 0:00:32\n",
      "    --------------------------------------- 4.4/228.5 MB 6.8 MB/s eta 0:00:33\n",
      "    --------------------------------------- 4.6/228.5 MB 6.8 MB/s eta 0:00:34\n",
      "    --------------------------------------- 4.8/228.5 MB 6.6 MB/s eta 0:00:34\n",
      "    --------------------------------------- 5.0/228.5 MB 6.3 MB/s eta 0:00:36\n",
      "    --------------------------------------- 5.2/228.5 MB 6.3 MB/s eta 0:00:36\n",
      "    --------------------------------------- 5.4/228.5 MB 6.3 MB/s eta 0:00:36\n",
      "    --------------------------------------- 5.6/228.5 MB 6.2 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 5.9/228.5 MB 6.1 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 6.2/228.5 MB 6.0 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 6.3/228.5 MB 6.0 MB/s eta 0:00:38\n",
      "   - -------------------------------------- 6.6/228.5 MB 6.0 MB/s eta 0:00:38\n",
      "   - -------------------------------------- 6.9/228.5 MB 6.0 MB/s eta 0:00:38\n",
      "   - -------------------------------------- 7.1/228.5 MB 6.0 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 7.4/228.5 MB 6.0 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 7.8/228.5 MB 6.1 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 8.0/228.5 MB 6.0 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 8.4/228.5 MB 6.1 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 8.7/228.5 MB 6.1 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 9.1/228.5 MB 6.2 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 9.5/228.5 MB 6.2 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 9.9/228.5 MB 6.3 MB/s eta 0:00:35\n",
      "   - -------------------------------------- 10.3/228.5 MB 6.4 MB/s eta 0:00:35\n",
      "   - -------------------------------------- 10.7/228.5 MB 6.2 MB/s eta 0:00:35\n",
      "   - -------------------------------------- 11.0/228.5 MB 6.3 MB/s eta 0:00:35\n",
      "   - -------------------------------------- 11.2/228.5 MB 6.3 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 11.6/228.5 MB 6.2 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 11.9/228.5 MB 6.2 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 12.2/228.5 MB 6.1 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 12.4/228.5 MB 6.1 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 12.6/228.5 MB 6.1 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 12.7/228.5 MB 5.9 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 12.9/228.5 MB 5.8 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 13.1/228.5 MB 5.6 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 13.3/228.5 MB 5.6 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 13.4/228.5 MB 5.5 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 13.7/228.5 MB 5.5 MB/s eta 0:00:40\n",
      "   -- ------------------------------------- 13.9/228.5 MB 5.5 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 14.2/228.5 MB 5.6 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 14.4/228.5 MB 5.5 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 14.6/228.5 MB 5.6 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 14.9/228.5 MB 5.7 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 15.2/228.5 MB 5.7 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 15.4/228.5 MB 5.8 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 15.8/228.5 MB 5.8 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 16.1/228.5 MB 5.9 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 16.4/228.5 MB 6.0 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 16.7/228.5 MB 6.1 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 17.1/228.5 MB 6.1 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 17.5/228.5 MB 6.1 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 17.8/228.5 MB 6.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 18.2/228.5 MB 6.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 18.6/228.5 MB 6.2 MB/s eta 0:00:34\n",
      "   --- ------------------------------------ 19.0/228.5 MB 6.2 MB/s eta 0:00:34\n",
      "   --- ------------------------------------ 19.4/228.5 MB 6.2 MB/s eta 0:00:34\n",
      "   --- ------------------------------------ 19.8/228.5 MB 6.3 MB/s eta 0:00:34\n",
      "   --- ------------------------------------ 20.2/228.5 MB 6.2 MB/s eta 0:00:34\n",
      "   --- ------------------------------------ 20.4/228.5 MB 6.2 MB/s eta 0:00:34\n",
      "   --- ------------------------------------ 20.6/228.5 MB 6.1 MB/s eta 0:00:34\n",
      "   --- ------------------------------------ 20.7/228.5 MB 6.0 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 20.8/228.5 MB 5.9 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 21.0/228.5 MB 5.8 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 21.2/228.5 MB 5.8 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 21.3/228.5 MB 5.7 MB/s eta 0:00:37\n",
      "   --- ------------------------------------ 21.6/228.5 MB 5.6 MB/s eta 0:00:37\n",
      "   --- ------------------------------------ 21.8/228.5 MB 5.6 MB/s eta 0:00:37\n",
      "   --- ------------------------------------ 22.0/228.5 MB 5.5 MB/s eta 0:00:38\n",
      "   --- ------------------------------------ 22.2/228.5 MB 5.5 MB/s eta 0:00:38\n",
      "   --- ------------------------------------ 22.5/228.5 MB 5.5 MB/s eta 0:00:38\n",
      "   --- ------------------------------------ 22.8/228.5 MB 5.5 MB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 23.0/228.5 MB 5.6 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 23.3/228.5 MB 5.7 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 23.6/228.5 MB 5.8 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 23.8/228.5 MB 5.9 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 24.1/228.5 MB 5.9 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 24.4/228.5 MB 5.9 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 24.7/228.5 MB 6.1 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 25.1/228.5 MB 6.1 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 25.4/228.5 MB 6.1 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 25.8/228.5 MB 6.2 MB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 26.1/228.5 MB 6.2 MB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 26.5/228.5 MB 6.2 MB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 26.8/228.5 MB 6.3 MB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 27.2/228.5 MB 6.4 MB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 27.7/228.5 MB 6.3 MB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 28.0/228.5 MB 6.4 MB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 28.4/228.5 MB 6.4 MB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 28.6/228.5 MB 6.2 MB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 28.7/228.5 MB 6.1 MB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 28.8/228.5 MB 6.0 MB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 28.9/228.5 MB 5.8 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 29.0/228.5 MB 5.7 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 29.1/228.5 MB 5.6 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 29.2/228.5 MB 5.6 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 29.4/228.5 MB 5.5 MB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 29.5/228.5 MB 5.4 MB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 29.7/228.5 MB 5.3 MB/s eta 0:00:38\n",
      "   ----- ---------------------------------- 29.9/228.5 MB 5.3 MB/s eta 0:00:38\n",
      "   ----- ---------------------------------- 30.1/228.5 MB 5.2 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 30.3/228.5 MB 5.2 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 30.5/228.5 MB 5.1 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 30.7/228.5 MB 5.1 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 31.0/228.5 MB 5.2 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 31.2/228.5 MB 5.3 MB/s eta 0:00:38\n",
      "   ----- ---------------------------------- 31.4/228.5 MB 5.3 MB/s eta 0:00:38\n",
      "   ----- ---------------------------------- 31.6/228.5 MB 5.3 MB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 31.9/228.5 MB 5.4 MB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 32.2/228.5 MB 5.4 MB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 32.5/228.5 MB 5.4 MB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 32.8/228.5 MB 5.5 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 33.1/228.5 MB 5.6 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 33.5/228.5 MB 5.6 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 33.8/228.5 MB 5.6 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 34.2/228.5 MB 5.7 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 34.6/228.5 MB 5.7 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 34.9/228.5 MB 5.7 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 35.3/228.5 MB 5.8 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 35.7/228.5 MB 5.8 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 36.0/228.5 MB 5.7 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 36.3/228.5 MB 5.7 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 36.6/228.5 MB 5.7 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 36.9/228.5 MB 5.6 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 37.1/228.5 MB 5.6 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 37.3/228.5 MB 5.5 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 37.5/228.5 MB 5.5 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 37.6/228.5 MB 5.4 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 37.8/228.5 MB 5.3 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 38.1/228.5 MB 5.2 MB/s eta 0:00:37\n",
      "   ------ --------------------------------- 38.2/228.5 MB 5.1 MB/s eta 0:00:38\n",
      "   ------ --------------------------------- 38.4/228.5 MB 5.1 MB/s eta 0:00:38\n",
      "   ------ --------------------------------- 38.7/228.5 MB 5.1 MB/s eta 0:00:38\n",
      "   ------ --------------------------------- 38.9/228.5 MB 5.3 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 39.2/228.5 MB 5.5 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 39.5/228.5 MB 5.6 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 39.8/228.5 MB 5.8 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 40.1/228.5 MB 5.8 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 40.4/228.5 MB 6.0 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 40.7/228.5 MB 6.0 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 41.1/228.5 MB 6.2 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 41.4/228.5 MB 6.2 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 41.7/228.5 MB 6.3 MB/s eta 0:00:30\n",
      "   ------- -------------------------------- 42.1/228.5 MB 6.4 MB/s eta 0:00:30\n",
      "   ------- -------------------------------- 42.4/228.5 MB 6.4 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 42.9/228.5 MB 6.4 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 43.3/228.5 MB 6.5 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 43.6/228.5 MB 6.4 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 43.8/228.5 MB 6.4 MB/s eta 0:00:30\n",
      "   ------- -------------------------------- 44.1/228.5 MB 6.4 MB/s eta 0:00:30\n",
      "   ------- -------------------------------- 44.2/228.5 MB 6.2 MB/s eta 0:00:30\n",
      "   ------- -------------------------------- 44.3/228.5 MB 6.1 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 44.5/228.5 MB 6.0 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 44.7/228.5 MB 5.8 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 44.8/228.5 MB 5.8 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 45.0/228.5 MB 5.7 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 45.2/228.5 MB 5.7 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 45.4/228.5 MB 5.6 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 45.6/228.5 MB 5.6 MB/s eta 0:00:33\n",
      "   -------- ------------------------------- 45.9/228.5 MB 5.5 MB/s eta 0:00:34\n",
      "   -------- ------------------------------- 46.1/228.5 MB 5.4 MB/s eta 0:00:34\n",
      "   -------- ------------------------------- 46.4/228.5 MB 5.4 MB/s eta 0:00:34\n",
      "   -------- ------------------------------- 46.6/228.5 MB 5.4 MB/s eta 0:00:34\n",
      "   -------- ------------------------------- 46.9/228.5 MB 5.4 MB/s eta 0:00:34\n",
      "   -------- ------------------------------- 47.2/228.5 MB 5.5 MB/s eta 0:00:34\n",
      "   -------- ------------------------------- 47.5/228.5 MB 5.5 MB/s eta 0:00:33\n",
      "   -------- ------------------------------- 47.8/228.5 MB 5.6 MB/s eta 0:00:33\n",
      "   -------- ------------------------------- 48.1/228.5 MB 5.7 MB/s eta 0:00:32\n",
      "   -------- ------------------------------- 48.5/228.5 MB 5.8 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 48.7/228.5 MB 5.8 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 49.0/228.5 MB 5.8 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 49.3/228.5 MB 5.9 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 49.7/228.5 MB 5.9 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 50.1/228.5 MB 5.9 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 50.4/228.5 MB 5.9 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 50.8/228.5 MB 6.0 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 51.2/228.5 MB 6.0 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 51.6/228.5 MB 6.1 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 51.9/228.5 MB 6.1 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 52.3/228.5 MB 6.2 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 52.7/228.5 MB 6.1 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 53.0/228.5 MB 6.1 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 53.3/228.5 MB 6.1 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 53.5/228.5 MB 6.1 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 53.8/228.5 MB 6.0 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 54.0/228.5 MB 5.8 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 54.1/228.5 MB 5.8 MB/s eta 0:00:31\n",
      "   --------- ------------------------------ 54.3/228.5 MB 5.8 MB/s eta 0:00:31\n",
      "   --------- ------------------------------ 54.5/228.5 MB 5.9 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 54.7/228.5 MB 6.0 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 54.9/228.5 MB 6.0 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 55.1/228.5 MB 6.0 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 55.3/228.5 MB 6.0 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 55.5/228.5 MB 6.1 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 55.7/228.5 MB 6.1 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 56.0/228.5 MB 6.1 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 56.3/228.5 MB 6.1 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 56.6/228.5 MB 6.1 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 56.9/228.5 MB 6.1 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 57.2/228.5 MB 6.2 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 57.5/228.5 MB 6.2 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 57.8/228.5 MB 6.2 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 58.2/228.5 MB 6.2 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 58.5/228.5 MB 6.2 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 58.9/228.5 MB 6.2 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 59.3/228.5 MB 6.3 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 59.7/228.5 MB 6.3 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 60.0/228.5 MB 6.2 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 60.4/228.5 MB 6.4 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 60.5/228.5 MB 6.2 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 60.5/228.5 MB 6.2 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 60.6/228.5 MB 5.9 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 60.7/228.5 MB 5.8 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 60.9/228.5 MB 5.7 MB/s eta 0:00:30\n",
      "   ---------- ----------------------------- 61.2/228.5 MB 5.7 MB/s eta 0:00:30\n",
      "   ---------- ----------------------------- 61.5/228.5 MB 5.6 MB/s eta 0:00:30\n",
      "   ---------- ----------------------------- 61.9/228.5 MB 5.6 MB/s eta 0:00:30\n",
      "   ---------- ----------------------------- 62.2/228.5 MB 5.5 MB/s eta 0:00:30\n",
      "   ---------- ----------------------------- 62.5/228.5 MB 5.5 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 62.9/228.5 MB 5.6 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 63.2/228.5 MB 5.5 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 63.6/228.5 MB 5.5 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 64.0/228.5 MB 5.6 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 64.4/228.5 MB 5.9 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 64.7/228.5 MB 6.1 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 65.0/228.5 MB 6.2 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 65.5/228.5 MB 6.4 MB/s eta 0:00:26\n",
      "   ----------- ---------------------------- 65.8/228.5 MB 6.4 MB/s eta 0:00:26\n",
      "   ----------- ---------------------------- 66.0/228.5 MB 6.4 MB/s eta 0:00:26\n",
      "   ----------- ---------------------------- 66.2/228.5 MB 6.3 MB/s eta 0:00:26\n",
      "   ----------- ---------------------------- 66.5/228.5 MB 6.4 MB/s eta 0:00:26\n",
      "   ----------- ---------------------------- 66.8/228.5 MB 6.4 MB/s eta 0:00:26\n",
      "   ----------- ---------------------------- 67.1/228.5 MB 6.4 MB/s eta 0:00:26\n",
      "   ----------- ---------------------------- 67.3/228.5 MB 6.4 MB/s eta 0:00:26\n",
      "   ----------- ---------------------------- 67.6/228.5 MB 6.3 MB/s eta 0:00:26\n",
      "   ----------- ---------------------------- 67.8/228.5 MB 6.3 MB/s eta 0:00:26\n",
      "   ----------- ---------------------------- 68.0/228.5 MB 6.2 MB/s eta 0:00:26\n",
      "   ----------- ---------------------------- 68.2/228.5 MB 6.2 MB/s eta 0:00:26\n",
      "   ----------- ---------------------------- 68.4/228.5 MB 6.1 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 68.7/228.5 MB 6.0 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 68.9/228.5 MB 6.0 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 69.2/228.5 MB 5.9 MB/s eta 0:00:28\n",
      "   ------------ --------------------------- 69.4/228.5 MB 5.8 MB/s eta 0:00:28\n",
      "   ------------ --------------------------- 69.7/228.5 MB 5.8 MB/s eta 0:00:28\n",
      "   ------------ --------------------------- 70.1/228.5 MB 5.9 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 70.3/228.5 MB 5.8 MB/s eta 0:00:28\n",
      "   ------------ --------------------------- 70.6/228.5 MB 5.8 MB/s eta 0:00:28\n",
      "   ------------ --------------------------- 70.9/228.5 MB 6.4 MB/s eta 0:00:25\n",
      "   ------------ --------------------------- 71.3/228.5 MB 6.4 MB/s eta 0:00:25\n",
      "   ------------ --------------------------- 71.6/228.5 MB 6.4 MB/s eta 0:00:25\n",
      "   ------------ --------------------------- 72.0/228.5 MB 6.5 MB/s eta 0:00:25\n",
      "   ------------ --------------------------- 72.4/228.5 MB 6.4 MB/s eta 0:00:25\n",
      "   ------------ --------------------------- 72.8/228.5 MB 6.5 MB/s eta 0:00:24\n",
      "   ------------ --------------------------- 73.2/228.5 MB 6.5 MB/s eta 0:00:24\n",
      "   ------------ --------------------------- 73.5/228.5 MB 6.5 MB/s eta 0:00:24\n",
      "   ------------ --------------------------- 73.7/228.5 MB 6.5 MB/s eta 0:00:24\n",
      "   ------------ --------------------------- 73.9/228.5 MB 6.4 MB/s eta 0:00:25\n",
      "   ------------ --------------------------- 74.1/228.5 MB 6.3 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 74.3/228.5 MB 6.2 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 74.6/228.5 MB 6.2 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 74.9/228.5 MB 6.0 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 75.2/228.5 MB 6.0 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 75.5/228.5 MB 6.0 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 75.8/228.5 MB 6.0 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 76.1/228.5 MB 6.0 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 76.4/228.5 MB 6.1 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 76.7/228.5 MB 6.1 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 76.9/228.5 MB 6.2 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 77.2/228.5 MB 6.2 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 77.4/228.5 MB 6.1 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 77.8/228.5 MB 6.1 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 78.0/228.5 MB 6.2 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 78.4/228.5 MB 6.2 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 78.7/228.5 MB 6.2 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 79.0/228.5 MB 6.3 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 79.3/228.5 MB 6.4 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 79.6/228.5 MB 6.4 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 79.8/228.5 MB 6.4 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 80.0/228.5 MB 6.4 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 80.1/228.5 MB 6.2 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 80.2/228.5 MB 6.1 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 80.4/228.5 MB 6.1 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 80.7/228.5 MB 6.1 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 81.0/228.5 MB 6.1 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 81.3/228.5 MB 6.1 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 81.7/228.5 MB 6.1 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 82.0/228.5 MB 6.0 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 82.4/228.5 MB 6.1 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 82.7/228.5 MB 6.0 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 83.0/228.5 MB 6.0 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 83.4/228.5 MB 6.0 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 83.7/228.5 MB 5.9 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 84.1/228.5 MB 6.1 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 84.5/228.5 MB 6.3 MB/s eta 0:00:23\n",
      "   -------------- ------------------------- 84.8/228.5 MB 6.2 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 85.1/228.5 MB 6.3 MB/s eta 0:00:23\n",
      "   -------------- ------------------------- 85.2/228.5 MB 6.2 MB/s eta 0:00:23\n",
      "   -------------- ------------------------- 85.4/228.5 MB 6.1 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 85.5/228.5 MB 6.1 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 85.7/228.5 MB 6.0 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 85.8/228.5 MB 5.8 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 86.0/228.5 MB 5.8 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 86.2/228.5 MB 5.7 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 86.4/228.5 MB 5.7 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 86.6/228.5 MB 5.7 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 86.8/228.5 MB 5.6 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 87.1/228.5 MB 5.6 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 87.3/228.5 MB 5.6 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 87.6/228.5 MB 5.6 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 87.8/228.5 MB 5.6 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 88.1/228.5 MB 5.6 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 88.4/228.5 MB 5.6 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 88.7/228.5 MB 5.6 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 89.1/228.5 MB 5.6 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 89.4/228.5 MB 5.6 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 89.6/228.5 MB 5.6 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 89.9/228.5 MB 5.6 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 90.3/228.5 MB 5.7 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 90.7/228.5 MB 6.0 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 91.1/228.5 MB 6.0 MB/s eta 0:00:23\n",
      "   --------------- ------------------------ 91.4/228.5 MB 6.0 MB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 91.6/228.5 MB 6.0 MB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 91.9/228.5 MB 6.0 MB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 92.2/228.5 MB 6.0 MB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 92.6/228.5 MB 5.9 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 92.9/228.5 MB 6.0 MB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 93.1/228.5 MB 5.9 MB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 93.3/228.5 MB 5.9 MB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 93.5/228.5 MB 5.8 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 93.7/228.5 MB 5.7 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 93.8/228.5 MB 5.6 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 93.9/228.5 MB 5.6 MB/s eta 0:00:25\n",
      "   ---------------- ----------------------- 94.0/228.5 MB 5.5 MB/s eta 0:00:25\n",
      "   ---------------- ----------------------- 94.1/228.5 MB 5.4 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 94.2/228.5 MB 5.3 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 94.4/228.5 MB 5.2 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 94.6/228.5 MB 5.1 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 94.7/228.5 MB 5.0 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 94.9/228.5 MB 5.0 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 95.1/228.5 MB 5.0 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 95.3/228.5 MB 4.9 MB/s eta 0:00:28\n",
      "   ---------------- ----------------------- 95.5/228.5 MB 5.0 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 95.8/228.5 MB 5.1 MB/s eta 0:00:27\n",
      "   ---------------- ----------------------- 96.1/228.5 MB 5.2 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 96.3/228.5 MB 5.2 MB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 96.6/228.5 MB 5.3 MB/s eta 0:00:25\n",
      "   ---------------- ----------------------- 96.9/228.5 MB 5.3 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 97.2/228.5 MB 5.3 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 97.5/228.5 MB 5.4 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 97.7/228.5 MB 5.4 MB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 98.1/228.5 MB 5.5 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 98.5/228.5 MB 5.5 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 98.8/228.5 MB 5.5 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 99.2/228.5 MB 5.5 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 99.6/228.5 MB 5.6 MB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 100.0/228.5 MB 5.6 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 100.4/228.5 MB 5.7 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 100.8/228.5 MB 5.7 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 101.1/228.5 MB 5.7 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 101.4/228.5 MB 5.7 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 101.8/228.5 MB 5.7 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 102.1/228.5 MB 5.7 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 102.2/228.5 MB 5.6 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 102.5/228.5 MB 5.6 MB/s eta 0:00:23\n",
      "   ----------------- ---------------------- 102.7/228.5 MB 5.5 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 102.8/228.5 MB 5.5 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 103.0/228.5 MB 5.4 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 103.2/228.5 MB 5.4 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 103.4/228.5 MB 5.3 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 103.6/228.5 MB 5.3 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 103.8/228.5 MB 5.3 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 104.0/228.5 MB 5.3 MB/s eta 0:00:24\n",
      "   ------------------ --------------------- 104.2/228.5 MB 5.5 MB/s eta 0:00:23\n",
      "   ------------------ --------------------- 104.5/228.5 MB 5.7 MB/s eta 0:00:22\n",
      "   ------------------ --------------------- 104.7/228.5 MB 5.8 MB/s eta 0:00:22\n",
      "   ------------------ --------------------- 104.9/228.5 MB 5.8 MB/s eta 0:00:22\n",
      "   ------------------ --------------------- 105.2/228.5 MB 5.9 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 105.5/228.5 MB 5.9 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 105.8/228.5 MB 6.0 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 106.1/228.5 MB 6.1 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 106.4/228.5 MB 6.1 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 106.8/228.5 MB 6.2 MB/s eta 0:00:20\n",
      "   ------------------ --------------------- 107.2/228.5 MB 6.2 MB/s eta 0:00:20\n",
      "   ------------------ --------------------- 107.6/228.5 MB 6.2 MB/s eta 0:00:20\n",
      "   ------------------ --------------------- 108.0/228.5 MB 6.3 MB/s eta 0:00:20\n",
      "   ------------------ --------------------- 108.4/228.5 MB 6.4 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 108.7/228.5 MB 6.4 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 109.1/228.5 MB 6.4 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 109.5/228.5 MB 6.4 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 109.7/228.5 MB 6.3 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 109.9/228.5 MB 6.2 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 110.1/228.5 MB 6.1 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 110.2/228.5 MB 6.0 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 110.4/228.5 MB 5.9 MB/s eta 0:00:21\n",
      "   ------------------- -------------------- 110.6/228.5 MB 5.8 MB/s eta 0:00:21\n",
      "   ------------------- -------------------- 110.8/228.5 MB 5.7 MB/s eta 0:00:21\n",
      "   ------------------- -------------------- 111.0/228.5 MB 5.6 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 111.3/228.5 MB 5.6 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 111.5/228.5 MB 5.6 MB/s eta 0:00:21\n",
      "   ------------------- -------------------- 111.8/228.5 MB 5.5 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 112.0/228.5 MB 5.5 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 112.2/228.5 MB 5.4 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 112.5/228.5 MB 5.4 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 112.7/228.5 MB 5.5 MB/s eta 0:00:22\n",
      "   ------------------- -------------------- 113.0/228.5 MB 5.6 MB/s eta 0:00:21\n",
      "   ------------------- -------------------- 113.4/228.5 MB 5.7 MB/s eta 0:00:21\n",
      "   ------------------- -------------------- 113.7/228.5 MB 5.9 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 114.1/228.5 MB 6.0 MB/s eta 0:00:20\n",
      "   -------------------- ------------------- 114.5/228.5 MB 6.1 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 114.9/228.5 MB 6.2 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 115.3/228.5 MB 6.3 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 115.6/228.5 MB 6.4 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 116.0/228.5 MB 6.4 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 116.5/228.5 MB 6.5 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 117.0/228.5 MB 6.5 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 117.3/228.5 MB 6.5 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 117.6/228.5 MB 6.4 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 117.7/228.5 MB 6.3 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 117.9/228.5 MB 6.2 MB/s eta 0:00:18\n",
      "   -------------------- ------------------- 118.0/228.5 MB 6.0 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 118.1/228.5 MB 5.9 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 118.2/228.5 MB 5.8 MB/s eta 0:00:20\n",
      "   -------------------- ------------------- 118.3/228.5 MB 5.7 MB/s eta 0:00:20\n",
      "   -------------------- ------------------- 118.5/228.5 MB 5.6 MB/s eta 0:00:20\n",
      "   -------------------- ------------------- 118.6/228.5 MB 5.5 MB/s eta 0:00:20\n",
      "   -------------------- ------------------- 118.8/228.5 MB 5.4 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 119.0/228.5 MB 5.4 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 119.1/228.5 MB 5.3 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 119.4/228.5 MB 5.2 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 119.6/228.5 MB 5.2 MB/s eta 0:00:21\n",
      "   -------------------- ------------------- 119.9/228.5 MB 5.3 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 120.1/228.5 MB 5.3 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 120.4/228.5 MB 5.4 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 120.7/228.5 MB 5.5 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 121.0/228.5 MB 5.6 MB/s eta 0:00:20\n",
      "   --------------------- ------------------ 121.4/228.5 MB 5.6 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 121.7/228.5 MB 5.7 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 122.1/228.5 MB 5.8 MB/s eta 0:00:19\n",
      "   --------------------- ------------------ 122.5/228.5 MB 5.9 MB/s eta 0:00:18\n",
      "   --------------------- ------------------ 122.9/228.5 MB 6.0 MB/s eta 0:00:18\n",
      "   --------------------- ------------------ 123.2/228.5 MB 6.0 MB/s eta 0:00:18\n",
      "   --------------------- ------------------ 123.6/228.5 MB 6.1 MB/s eta 0:00:18\n",
      "   --------------------- ------------------ 124.0/228.5 MB 6.1 MB/s eta 0:00:18\n",
      "   --------------------- ------------------ 124.5/228.5 MB 6.1 MB/s eta 0:00:17\n",
      "   --------------------- ------------------ 125.0/228.5 MB 6.1 MB/s eta 0:00:18\n",
      "   --------------------- ------------------ 125.2/228.5 MB 6.1 MB/s eta 0:00:18\n",
      "   --------------------- ------------------ 125.5/228.5 MB 6.0 MB/s eta 0:00:18\n",
      "   --------------------- ------------------ 125.6/228.5 MB 6.0 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 125.7/228.5 MB 5.8 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 125.8/228.5 MB 5.7 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 125.9/228.5 MB 5.6 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 126.0/228.5 MB 5.5 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 126.2/228.5 MB 5.5 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 126.3/228.5 MB 5.4 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 126.4/228.5 MB 5.3 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 126.6/228.5 MB 5.2 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 126.8/228.5 MB 5.2 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 127.0/228.5 MB 5.1 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 127.3/228.5 MB 5.0 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 127.5/228.5 MB 4.9 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 127.8/228.5 MB 5.0 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 128.0/228.5 MB 5.0 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 128.3/228.5 MB 5.3 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 128.7/228.5 MB 5.5 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 129.0/228.5 MB 5.6 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 129.3/228.5 MB 5.7 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 129.7/228.5 MB 5.8 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 130.1/228.5 MB 5.9 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 130.4/228.5 MB 6.0 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 130.9/228.5 MB 6.1 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 131.3/228.5 MB 6.1 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 131.7/228.5 MB 6.2 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 132.2/228.5 MB 6.3 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 132.6/228.5 MB 6.3 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 132.8/228.5 MB 6.1 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 132.9/228.5 MB 6.1 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 133.1/228.5 MB 6.0 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 133.2/228.5 MB 5.8 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 133.3/228.5 MB 5.7 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 133.4/228.5 MB 5.6 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 133.5/228.5 MB 5.5 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 133.6/228.5 MB 5.5 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 133.8/228.5 MB 5.4 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 134.0/228.5 MB 5.3 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 134.2/228.5 MB 5.2 MB/s eta 0:00:19\n",
      "   ----------------------- ---------------- 134.4/228.5 MB 5.1 MB/s eta 0:00:19\n",
      "   ----------------------- ---------------- 134.6/228.5 MB 5.1 MB/s eta 0:00:19\n",
      "   ----------------------- ---------------- 134.9/228.5 MB 5.0 MB/s eta 0:00:19\n",
      "   ----------------------- ---------------- 135.1/228.5 MB 5.0 MB/s eta 0:00:19\n",
      "   ----------------------- ---------------- 135.4/228.5 MB 5.0 MB/s eta 0:00:19\n",
      "   ----------------------- ---------------- 135.7/228.5 MB 5.1 MB/s eta 0:00:19\n",
      "   ----------------------- ---------------- 136.0/228.5 MB 5.2 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 136.3/228.5 MB 5.4 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 136.7/228.5 MB 5.6 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 137.0/228.5 MB 5.8 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 137.5/228.5 MB 6.0 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 137.8/228.5 MB 6.1 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 138.2/228.5 MB 6.1 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 138.6/228.5 MB 6.2 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 139.0/228.5 MB 6.2 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 139.3/228.5 MB 6.2 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 139.6/228.5 MB 6.1 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 139.8/228.5 MB 6.1 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 140.0/228.5 MB 6.0 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 140.2/228.5 MB 6.0 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 140.3/228.5 MB 5.8 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 140.5/228.5 MB 5.7 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 140.7/228.5 MB 5.7 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 141.0/228.5 MB 5.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 141.1/228.5 MB 5.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 141.4/228.5 MB 5.5 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 141.6/228.5 MB 5.3 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 141.8/228.5 MB 5.3 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 142.0/228.5 MB 5.2 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 142.3/228.5 MB 5.2 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 142.6/228.5 MB 5.1 MB/s eta 0:00:17\n",
      "   ------------------------- -------------- 142.9/228.5 MB 5.1 MB/s eta 0:00:17\n",
      "   ------------------------- -------------- 143.1/228.5 MB 5.2 MB/s eta 0:00:17\n",
      "   ------------------------- -------------- 143.4/228.5 MB 5.3 MB/s eta 0:00:17\n",
      "   ------------------------- -------------- 143.7/228.5 MB 5.5 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 144.0/228.5 MB 5.7 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 144.3/228.5 MB 5.8 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 144.7/228.5 MB 5.9 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 144.8/228.5 MB 6.0 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 144.8/228.5 MB 6.0 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 144.8/228.5 MB 5.6 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 145.0/228.5 MB 5.5 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 145.3/228.5 MB 5.6 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 145.7/228.5 MB 5.6 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 146.1/228.5 MB 5.7 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 146.5/228.5 MB 5.7 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 146.9/228.5 MB 5.7 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 147.3/228.5 MB 5.7 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 147.5/228.5 MB 5.7 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 147.8/228.5 MB 5.7 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 148.3/228.5 MB 5.7 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 148.7/228.5 MB 5.7 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 149.2/228.5 MB 5.7 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 149.5/228.5 MB 5.7 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 149.8/228.5 MB 5.8 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 150.0/228.5 MB 5.8 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 150.2/228.5 MB 5.8 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 150.4/228.5 MB 5.8 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 150.7/228.5 MB 6.0 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 151.0/228.5 MB 6.0 MB/s eta 0:00:13\n",
      "   -------------------------- ------------- 151.3/228.5 MB 6.1 MB/s eta 0:00:13\n",
      "   -------------------------- ------------- 151.5/228.5 MB 6.1 MB/s eta 0:00:13\n",
      "   -------------------------- ------------- 151.6/228.5 MB 6.1 MB/s eta 0:00:13\n",
      "   -------------------------- ------------- 151.8/228.5 MB 6.1 MB/s eta 0:00:13\n",
      "   -------------------------- ------------- 152.0/228.5 MB 6.0 MB/s eta 0:00:13\n",
      "   -------------------------- ------------- 152.1/228.5 MB 6.0 MB/s eta 0:00:13\n",
      "   -------------------------- ------------- 152.2/228.5 MB 5.8 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 152.5/228.5 MB 5.8 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 152.7/228.5 MB 5.7 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 152.8/228.5 MB 5.7 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 153.0/228.5 MB 5.7 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 153.3/228.5 MB 5.6 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 153.6/228.5 MB 5.7 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 153.8/228.5 MB 5.6 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 154.1/228.5 MB 5.6 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 154.4/228.5 MB 5.6 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 154.7/228.5 MB 5.6 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 155.0/228.5 MB 5.6 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 155.3/228.5 MB 6.0 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 155.7/228.5 MB 6.1 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 156.0/228.5 MB 6.1 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 156.4/228.5 MB 6.0 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 156.8/228.5 MB 6.0 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 157.2/228.5 MB 6.1 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 157.6/228.5 MB 6.1 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 157.9/228.5 MB 6.1 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 158.1/228.5 MB 6.1 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 158.3/228.5 MB 6.0 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 158.5/228.5 MB 5.8 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 158.7/228.5 MB 5.7 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 159.0/228.5 MB 5.7 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 159.2/228.5 MB 5.6 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 159.4/228.5 MB 5.6 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 159.7/228.5 MB 5.6 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 159.9/228.5 MB 5.5 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 160.1/228.5 MB 5.4 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 160.4/228.5 MB 5.5 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 160.6/228.5 MB 5.5 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 160.9/228.5 MB 5.5 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 161.2/228.5 MB 5.5 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 161.4/228.5 MB 5.5 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 161.7/228.5 MB 5.5 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 162.1/228.5 MB 5.7 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 162.4/228.5 MB 5.8 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 162.8/228.5 MB 6.1 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 163.0/228.5 MB 6.1 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 163.4/228.5 MB 6.2 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 163.8/228.5 MB 6.4 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 164.3/228.5 MB 6.5 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 164.8/228.5 MB 6.6 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 165.2/228.5 MB 6.7 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 165.7/228.5 MB 6.7 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 166.0/228.5 MB 6.7 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 166.2/228.5 MB 6.7 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 166.3/228.5 MB 6.5 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 166.5/228.5 MB 6.5 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 166.6/228.5 MB 6.4 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 166.7/228.5 MB 6.2 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 166.9/228.5 MB 6.1 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 167.1/228.5 MB 6.0 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 167.2/228.5 MB 5.9 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 167.4/228.5 MB 5.7 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 167.6/228.5 MB 5.7 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 167.8/228.5 MB 5.6 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 168.0/228.5 MB 5.6 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 168.2/228.5 MB 5.6 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 168.4/228.5 MB 5.5 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 168.7/228.5 MB 5.7 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 168.9/228.5 MB 5.7 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 169.3/228.5 MB 5.7 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 169.6/228.5 MB 5.9 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 169.9/228.5 MB 5.9 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 170.3/228.5 MB 6.1 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 170.7/228.5 MB 6.1 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 171.0/228.5 MB 6.1 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 171.5/228.5 MB 6.3 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 171.9/228.5 MB 6.4 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 172.2/228.5 MB 6.4 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 172.6/228.5 MB 6.4 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 172.9/228.5 MB 6.3 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 173.2/228.5 MB 6.4 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 173.4/228.5 MB 6.2 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 173.5/228.5 MB 6.2 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 173.7/228.5 MB 6.1 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 173.8/228.5 MB 6.0 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 174.0/228.5 MB 5.8 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 174.1/228.5 MB 5.7 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 174.3/228.5 MB 5.7 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 174.5/228.5 MB 5.5 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 174.7/228.5 MB 5.5 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 175.0/228.5 MB 5.4 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 175.2/228.5 MB 5.4 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 175.5/228.5 MB 5.3 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 175.7/228.5 MB 5.3 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 176.0/228.5 MB 5.3 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 176.4/228.5 MB 5.2 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 176.7/228.5 MB 5.4 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 177.0/228.5 MB 5.6 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 177.4/228.5 MB 5.7 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 177.7/228.5 MB 6.0 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 178.1/228.5 MB 6.0 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 178.4/228.5 MB 6.1 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 178.8/228.5 MB 6.2 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 179.2/228.5 MB 6.2 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 179.6/228.5 MB 6.4 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 180.1/228.5 MB 6.4 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 180.5/228.5 MB 6.4 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 180.9/228.5 MB 6.5 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 181.0/228.5 MB 6.4 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 181.2/228.5 MB 6.3 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 181.3/228.5 MB 6.2 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 181.5/228.5 MB 6.1 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 181.6/228.5 MB 6.0 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 181.8/228.5 MB 5.8 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 182.0/228.5 MB 5.7 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 182.2/228.5 MB 5.7 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 182.4/228.5 MB 5.6 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 182.7/228.5 MB 5.6 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 182.9/228.5 MB 5.5 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 183.2/228.5 MB 5.5 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 183.4/228.5 MB 5.5 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 183.7/228.5 MB 5.6 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 184.0/228.5 MB 5.8 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 184.3/228.5 MB 6.0 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 184.7/228.5 MB 6.1 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 185.1/228.5 MB 6.2 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 185.4/228.5 MB 6.3 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 185.8/228.5 MB 6.3 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 186.1/228.5 MB 6.4 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 186.5/228.5 MB 6.5 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 186.9/228.5 MB 6.5 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 187.3/228.5 MB 6.5 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 187.7/228.5 MB 6.5 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 187.9/228.5 MB 6.4 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 188.1/228.5 MB 6.4 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 188.2/228.5 MB 6.2 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 188.4/228.5 MB 6.2 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 188.5/228.5 MB 6.1 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 188.7/228.5 MB 6.0 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 188.9/228.5 MB 5.9 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 189.1/228.5 MB 5.8 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 189.4/228.5 MB 5.7 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 189.6/228.5 MB 5.7 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 189.8/228.5 MB 5.6 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 190.1/228.5 MB 5.6 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 190.4/228.5 MB 5.5 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 190.6/228.5 MB 5.5 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 190.9/228.5 MB 5.5 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 191.2/228.5 MB 5.5 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 191.5/228.5 MB 5.6 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 191.8/228.5 MB 5.8 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 192.2/228.5 MB 6.0 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 192.6/228.5 MB 6.1 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 193.0/228.5 MB 6.2 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 193.4/228.5 MB 6.2 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 193.8/228.5 MB 6.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 194.2/228.5 MB 6.4 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 194.4/228.5 MB 6.4 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 194.6/228.5 MB 6.3 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 194.8/228.5 MB 6.3 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 195.0/228.5 MB 6.2 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 195.2/228.5 MB 6.2 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 195.5/228.5 MB 6.1 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 195.7/228.5 MB 6.1 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 196.0/228.5 MB 6.1 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 196.4/228.5 MB 6.0 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 196.6/228.5 MB 5.9 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 196.9/228.5 MB 5.9 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 197.2/228.5 MB 5.9 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 197.5/228.5 MB 5.8 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 197.8/228.5 MB 5.8 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 198.2/228.5 MB 6.0 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 198.5/228.5 MB 6.2 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 198.9/228.5 MB 6.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 199.3/228.5 MB 6.6 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 199.7/228.5 MB 6.7 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 200.0/228.5 MB 6.7 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 200.2/228.5 MB 6.7 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 200.4/228.5 MB 6.7 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 200.6/228.5 MB 6.6 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 200.7/228.5 MB 6.5 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 200.9/228.5 MB 6.4 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 201.0/228.5 MB 6.4 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 201.2/228.5 MB 6.2 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 201.4/228.5 MB 6.2 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 201.6/228.5 MB 6.1 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 201.8/228.5 MB 6.1 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 202.0/228.5 MB 6.0 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 202.3/228.5 MB 6.0 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 202.5/228.5 MB 5.9 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 202.8/228.5 MB 5.8 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 203.0/228.5 MB 5.8 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 203.3/228.5 MB 5.7 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 203.6/228.5 MB 5.7 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 203.9/228.5 MB 5.6 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 204.2/228.5 MB 5.7 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 204.5/228.5 MB 5.6 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 204.8/228.5 MB 5.6 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 205.1/228.5 MB 5.8 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 205.5/228.5 MB 5.8 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 205.8/228.5 MB 5.9 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 206.2/228.5 MB 6.0 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 206.6/228.5 MB 6.1 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 207.0/228.5 MB 6.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 207.4/228.5 MB 6.1 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 207.9/228.5 MB 6.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 208.4/228.5 MB 6.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 208.7/228.5 MB 6.3 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 208.9/228.5 MB 6.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 209.0/228.5 MB 6.1 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 209.0/228.5 MB 5.8 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 209.1/228.5 MB 5.7 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 209.1/228.5 MB 5.6 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 209.2/228.5 MB 5.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 209.3/228.5 MB 5.4 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 209.4/228.5 MB 5.3 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 209.5/228.5 MB 5.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 209.6/228.5 MB 5.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 209.7/228.5 MB 5.1 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 209.9/228.5 MB 5.0 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 210.1/228.5 MB 4.9 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 210.2/228.5 MB 4.9 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 210.4/228.5 MB 4.9 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 210.6/228.5 MB 4.9 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 210.8/228.5 MB 4.9 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 211.0/228.5 MB 5.0 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 211.2/228.5 MB 5.0 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 211.4/228.5 MB 5.0 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 211.7/228.5 MB 5.1 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 212.0/228.5 MB 5.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 212.3/228.5 MB 5.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 212.4/228.5 MB 5.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 212.4/228.5 MB 5.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 212.4/228.5 MB 4.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 212.6/228.5 MB 4.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 213.0/228.5 MB 4.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 213.4/228.5 MB 4.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 213.7/228.5 MB 4.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 214.0/228.5 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 214.4/228.5 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 214.8/228.5 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 215.2/228.5 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 215.5/228.5 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 215.9/228.5 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 216.4/228.5 MB 5.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 216.7/228.5 MB 5.1 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 217.1/228.5 MB 5.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 217.4/228.5 MB 5.1 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 217.7/228.5 MB 5.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 217.9/228.5 MB 4.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 218.2/228.5 MB 4.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 218.3/228.5 MB 4.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 218.5/228.5 MB 4.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 218.6/228.5 MB 4.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 218.8/228.5 MB 4.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 218.9/228.5 MB 4.6 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 219.0/228.5 MB 4.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 219.2/228.5 MB 4.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 219.4/228.5 MB 4.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 219.5/228.5 MB 5.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 219.7/228.5 MB 5.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 220.0/228.5 MB 5.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 220.2/228.5 MB 5.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 220.4/228.5 MB 5.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 220.7/228.5 MB 5.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 221.0/228.5 MB 5.3 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 221.3/228.5 MB 5.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 221.6/228.5 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 221.9/228.5 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 222.2/228.5 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 222.6/228.5 MB 5.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  222.9/228.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  223.3/228.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  223.7/228.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  224.1/228.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  224.4/228.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  224.9/228.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  225.2/228.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  225.5/228.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  225.9/228.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  226.2/228.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  226.6/228.5 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  226.9/228.5 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  227.2/228.5 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  227.4/228.5 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  227.7/228.5 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  227.8/228.5 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.0/228.5 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.1/228.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.3/228.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.5/228.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.5/228.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.5/228.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.5/228.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.5/228.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.5/228.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.5/228.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.5/228.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.5/228.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.5/228.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.5/228.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.5/228.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.5/228.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.5/228.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.5/228.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.5/228.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.5/228.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  228.5/228.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 228.5/228.5 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.2/3.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.4/3.5 MB 4.5 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.6/3.5 MB 4.6 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.8/3.5 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.1/3.5 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.3/3.5 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.6/3.5 MB 5.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.9/3.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.2/3.5 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.5/3.5 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.8/3.5 MB 5.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.1/3.5 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.5/3.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 5.6 MB/s eta 0:00:00\n",
      "Downloading tbb-2021.12.0-py3-none-win_amd64.whl (286 kB)\n",
      "   ---------------------------------------- 0.0/286.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 286.4/286.4 kB 8.9 MB/s eta 0:00:00\n",
      "Downloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "   ---------------------------------------- 0.0/316.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 316.1/316.1 kB 9.9 MB/s eta 0:00:00\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.4/1.7 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.8/1.7 MB 8.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.7 MB 10.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 7.7 MB/s eta 0:00:00\n",
      "Downloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
      "   ---------------------------------------- 0.0/5.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.4/5.7 MB 12.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.8/5.7 MB 10.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.2/5.7 MB 9.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.6/5.7 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.9/5.7 MB 8.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.1/5.7 MB 8.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.5/5.7 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.8/5.7 MB 7.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.1/5.7 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.3/5.7 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.7/5.7 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.1/5.7 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.4/5.7 MB 7.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.7/5.7 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.9/5.7 MB 7.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.1/5.7 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.3/5.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.6/5.7 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.7/5.7 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.7/5.7 MB 6.3 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 225.3/536.2 kB 6.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 501.8/536.2 kB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 536.2/536.2 kB 4.2 MB/s eta 0:00:00\n",
      "Installing collected packages: tbb, mpmath, intel-openmp, sympy, networkx, mkl, fsspec, filelock, torch, torchvision, torchaudio\n",
      "Successfully installed filelock-3.14.0 fsspec-2024.5.0 intel-openmp-2021.4.0 mkl-2021.4.0 mpmath-1.3.0 networkx-3.3 sympy-1.12.1 tbb-2021.12.0 torch-2.3.0 torchaudio-2.3.0 torchvision-0.18.0\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa998e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.12.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.24.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e40c6f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformersNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.8/43.8 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.14.0)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.28.2)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp310-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/9.1 MB 5.9 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.4/9.1 MB 5.0 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.6/9.1 MB 4.8 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.8/9.1 MB 4.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.0/9.1 MB 4.6 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.2/9.1 MB 4.4 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.4/9.1 MB 4.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.7/9.1 MB 4.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.8/9.1 MB 4.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.1/9.1 MB 4.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.2/9.1 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.4/9.1 MB 4.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.7/9.1 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.8/9.1 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.1/9.1 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.3/9.1 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.5/9.1 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.7/9.1 MB 4.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.9/9.1 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.1/9.1 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.3/9.1 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.5/9.1 MB 4.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.8/9.1 MB 4.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.9/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.2/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.3/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.5/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.7/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.9/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.1/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.3/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.5/9.1 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.7/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.0/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.1/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.4/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.6/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.8/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.0/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.2/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.4/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.6/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.9/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.1/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.1/9.1 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.1/9.1 MB 4.3 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
      "   ---------------------------------------- 0.0/401.7 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 204.8/401.7 kB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 378.9/401.7 kB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 401.7/401.7 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.3-cp310-none-win_amd64.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.4 kB ? eta -:--:--\n",
      "   --------------------- ------------------ 153.6/287.4 kB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  286.7/287.4 kB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 287.4/287.4 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp310-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB 7.9 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.5/2.2 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/2.2 MB 5.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.2 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.2/2.2 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.2 MB 5.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.9/2.2 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.23.2 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.41.2\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0d717eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f284538f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c7ef5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d616e65",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/hsahn/Downloads/job_details.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Merge role_description and description columns to form job_description\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_description\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole_description\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Convert skills to binary vector\u001b[39;00m\n\u001b[0;32m     19\u001b[0m mlb \u001b[38;5;241m=\u001b[39m MultiLabelBinarizer()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn as nn\n",
    "from transformers import AdamW\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from sklearn.metrics import accuracy_score, recall_score, ndcg_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Merge role_description and description columns to form job_description\n",
    "df['job_description'] = df['role_description'].fillna('') + ' ' + df['description'].fillna('')\n",
    "\n",
    "# Convert skills to binary vector\n",
    "mlb = MultiLabelBinarizer()\n",
    "skills_encoded = mlb.fit_transform(df['skills'])\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(df['job_description'], skills_encoded, test_size=0.2, random_state=42)\n",
    "val_texts, test_texts, val_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define a custom dataset class\n",
    "class JobDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.max_len = 512\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels[idx]\n",
    "        inputs = self.tokenizer(text, return_tensors='pt', max_length=self.max_len, truncation=True, padding='max_length')\n",
    "        input_ids = inputs['input_ids'].squeeze()\n",
    "        attention_mask = inputs['attention_mask'].squeeze()\n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': torch.tensor(label, dtype=torch.float)}\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_dataset = JobDataset(train_texts, train_labels)\n",
    "val_dataset = JobDataset(val_texts, val_labels)\n",
    "test_dataset = JobDataset(test_texts, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "class BERTXMLC(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(BERTXMLC, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.bottleneck = nn.Linear(768, 256)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.classifier = nn.Linear(256, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        x = self.dropout(cls_output)\n",
    "        x = self.tanh(self.bottleneck(x))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "num_labels = skills_encoded.shape[1]\n",
    "model = BERTXMLC(num_labels)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "criterion = BCEWithLogitsLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}, Training Loss: {avg_train_loss}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f'Epoch {epoch + 1}, Validation Loss: {avg_val_loss}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(outputs.cpu().numpy())\n",
    "\n",
    "# Convert predictions to binary\n",
    "threshold = 0.5\n",
    "binary_preds = (all_preds > threshold).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_labels, binary_preds)\n",
    "recall_at_5 = recall_score(all_labels, binary_preds, average='samples', k=5)\n",
    "ndcg_at_5 = ndcg_score(all_labels, binary_preds, k=5)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Recall@5: {recall_at_5}')\n",
    "print(f'nDCG@5: {ndcg_at_5}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89118fdd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'skills'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'skills'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Here, assuming 'skills' column exists and is a list of skills. You might need to adjust this depending on your actual dataset format.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Convert skills to binary vector\u001b[39;00m\n\u001b[0;32m     20\u001b[0m mlb \u001b[38;5;241m=\u001b[39m MultiLabelBinarizer()\n\u001b[1;32m---> 21\u001b[0m skills_encoded \u001b[38;5;241m=\u001b[39m mlb\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mskills\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)))  \u001b[38;5;66;03m# Adjust the split method based on actual data format\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Split the data into training, validation, and test sets\u001b[39;00m\n\u001b[0;32m     24\u001b[0m train_texts, temp_texts, train_labels, temp_labels \u001b[38;5;241m=\u001b[39m train_test_split(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_description\u001b[39m\u001b[38;5;124m'\u001b[39m], skills_encoded, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'skills'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn as nn\n",
    "from transformers import AdamW\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from sklearn.metrics import accuracy_score, recall_score, ndcg_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/hsahn/Downloads/job_details.csv')\n",
    "\n",
    "# Merge role_description and description columns to form job_description\n",
    "data['job_description'] = data['role_description'].fillna('') + ' ' + data['description'].fillna('')\n",
    "\n",
    "# Here, assuming 'skills' column exists and is a list of skills. You might need to adjust this depending on your actual dataset format.\n",
    "# Convert skills to binary vector\n",
    "mlb = MultiLabelBinarizer()\n",
    "skills_encoded = mlb.fit_transform(data['skills'].apply(lambda x: x.split(',')))  # Adjust the split method based on actual data format\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(data['job_description'], skills_encoded, test_size=0.2, random_state=42)\n",
    "val_texts, test_texts, val_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define a custom dataset class\n",
    "class JobDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.max_len = 512\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels[idx]\n",
    "        inputs = self.tokenizer(text, return_tensors='pt', max_length=self.max_len, truncation=True, padding='max_length')\n",
    "        input_ids = inputs['input_ids'].squeeze()\n",
    "        attention_mask = inputs['attention_mask'].squeeze()\n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': torch.tensor(label, dtype=torch.float)}\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_dataset = JobDataset(train_texts, train_labels)\n",
    "val_dataset = JobDataset(val_texts, val_labels)\n",
    "test_dataset = JobDataset(test_texts, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "class BERTXMLC(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(BERTXMLC, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.bottleneck = nn.Linear(768, 256)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.classifier = nn.Linear(256, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        x = self.dropout(cls_output)\n",
    "        x = self.tanh(self.bottleneck(x))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "num_labels = skills_encoded.shape[1]\n",
    "model = BERTXMLC(num_labels)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "criterion = BCEWithLogitsLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}, Training Loss: {avg_train_loss}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f'Epoch {epoch + 1}, Validation Loss: {avg_val_loss}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(outputs.cpu().numpy())\n",
    "\n",
    "# Convert predictions to binary\n",
    "threshold = 0.5\n",
    "binary_preds = (all_preds > threshold).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_labels, binary_preds)\n",
    "recall_at_5 = recall_score(all_labels, binary_preds, average='samples')\n",
    "ndcg_at_5 = ndcg_score(all_labels, binary_preds, k=5)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Recall@5: {recall_at_5}')\n",
    "print(f'nDCG@5: {ndcg_at_5}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49a225ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'your_skills_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Convert skills to binary vector\u001b[39;00m\n\u001b[0;32m     36\u001b[0m mlb \u001b[38;5;241m=\u001b[39m MultiLabelBinarizer(classes\u001b[38;5;241m=\u001b[39mskills_list)\n\u001b[1;32m---> 37\u001b[0m skills_encoded \u001b[38;5;241m=\u001b[39m mlb\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43myour_skills_data\u001b[49m)  \u001b[38;5;66;03m# Replace your_skills_data with your actual skills data\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Split the data into training, validation, and test sets\u001b[39;00m\n\u001b[0;32m     40\u001b[0m train_texts, temp_texts, train_labels, temp_labels \u001b[38;5;241m=\u001b[39m train_test_split(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_description\u001b[39m\u001b[38;5;124m'\u001b[39m], skills_encoded, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'your_skills_data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn as nn\n",
    "from transformers import AdamW\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from sklearn.metrics import accuracy_score, recall_score, ndcg_score\n",
    "\n",
    "# Vectorized skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/hsahn/Downloads/job_details.csv')\n",
    "\n",
    "# Merge role_description and description columns to form job_description\n",
    "data['job_description'] = data['role_description'].fillna('') + ' ' + data['description'].fillna('')\n",
    "\n",
    "# Convert skills to binary vector\n",
    "mlb = MultiLabelBinarizer(classes=skills_list)\n",
    "skills_encoded = mlb.fit_transform(your_skills_data)  # Replace your_skills_data with your actual skills data\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(data['job_description'], skills_encoded, test_size=0.2, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define a custom dataset class\n",
    "class JobDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.max_len = 512\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels[idx]\n",
    "        inputs = self.tokenizer(text, return_tensors='pt', max_length=self.max_len, truncation=True, padding='max_length')\n",
    "        input_ids = inputs['input_ids'].squeeze()\n",
    "        attention_mask = inputs['attention_mask'].squeeze()\n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': torch.tensor(label, dtype=torch.float)}\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_dataset = JobDataset(train_texts, train_labels)\n",
    "val_dataset = JobDataset(val_texts, val_labels)\n",
    "test_dataset = JobDataset(test_texts, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "class BERTXMLC(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(BERTXMLC, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.bottleneck = nn.Linear(768, 256)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.classifier = nn.Linear(256, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        x = self.dropout(cls_output)\n",
    "        x = self.tanh(self.bottleneck(x))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "num_labels = len(skills_list)\n",
    "model = BERTXMLC(num_labels)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "criterion = BCEWithLogitsLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}, Training Loss: {avg_train_loss}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f'Epoch {epoch + 1}, Validation Loss: {avg_val_loss}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(outputs.cpu().numpy())\n",
    "\n",
    "# Convert predictions to binary\n",
    "threshold = 0.5\n",
    "binary_preds = (torch.sigmoid(torch.tensor(all_preds)) > threshold).int().cpu().numpy()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_labels, binary_preds)\n",
    "recall_at_5 = recall_score(all_labels, binary_preds, average='samples')\n",
    "ndcg_at_5 = ndcg_score(all_labels, binary_preds, k=5)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Recall@5: {recall_at_5}')\n",
    "print(f'nDCG@5: {ndcg_at_5}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ea32eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes (Filtered): ['hr' 'ai' 'r' 'recruitment' 'marketing' 'social media' 'content creation'\n",
      " 'excel' 'sales' 'product management' 'research' 'collaboration'\n",
      " 'market research' 'proto' 'operations' 'product marketing'\n",
      " 'project management' 'business development' 'lead generation' 'seo'\n",
      " 'communication' 'aws' 'logistics' 'sql' 'rest' 'problem solving'\n",
      " 'data visualization' 'python' 'react' 'tableau' 'power bi' 'java'\n",
      " 'javascript' 'b2b' 'machine learning' 'agile' 'content strategy'\n",
      " 'organizational skills']\n",
      "Counts per Class (Filtered):\n",
      "r                        147\n",
      "ai                       110\n",
      "research                  44\n",
      "marketing                 42\n",
      "sales                     31\n",
      "excel                     27\n",
      "communication             27\n",
      "operations                23\n",
      "hr                        19\n",
      "market research           19\n",
      "social media              17\n",
      "collaboration             16\n",
      "rest                      15\n",
      "sql                       14\n",
      "business development      10\n",
      "aws                        8\n",
      "project management         8\n",
      "python                     7\n",
      "recruitment                6\n",
      "content creation           6\n",
      "lead generation            5\n",
      "proto                      5\n",
      "product management         5\n",
      "react                      5\n",
      "machine learning           4\n",
      "javascript                 4\n",
      "problem solving            4\n",
      "java                       4\n",
      "agile                      3\n",
      "product marketing          3\n",
      "content strategy           3\n",
      "data visualization         3\n",
      "logistics                  3\n",
      "b2b                        3\n",
      "seo                        2\n",
      "power bi                   2\n",
      "tableau                    2\n",
      "organizational skills      2\n",
      "Name: skills, dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 108\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier on filtered data\u001b[39;00m\n\u001b[0;32m    107\u001b[0m model_filtered \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m--> 108\u001b[0m \u001b[43mmodel_filtered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m    111\u001b[0m y_pred_filtered \u001b[38;5;241m=\u001b[39m model_filtered\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "data['cleaned_text'] = data['role_description'].apply(preprocess_text)\n",
    "\n",
    "# Skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Count the number of samples per class\n",
    "class_counts = data['skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data[data['skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Remove samples belonging to classes with only one sample\n",
    "data_filtered = data_filtered[data_filtered['skills'].apply(lambda x: len(x) > 1)]\n",
    "\n",
    "# Filter out outliers and delete them\n",
    "outlier_classes = class_counts[class_counts < 2].index\n",
    "data_filtered['skills'] = data_filtered['skills'].apply(lambda x: [skill for skill in x if skill not in outlier_classes])\n",
    "\n",
    "# Reset index after deleting rows\n",
    "data_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert filtered data to features and labels\n",
    "X_filtered = data_filtered['cleaned_text']\n",
    "y_filtered = data_filtered.drop(columns=['cleaned_text'])\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering again\n",
    "unique_classes_filtered = data_filtered['skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    print(\"There are not enough unique classes present in the filtered data after removing classes with fewer than two samples.\")\n",
    "else:\n",
    "    # Print unique classes and their counts\n",
    "    print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "    print(\"Counts per Class (Filtered):\")\n",
    "    print(data_filtered['skills'].explode().value_counts())\n",
    "\n",
    "    # Transform skills into binary labels\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    labels = mlb.fit_transform(data_filtered['skills'])\n",
    "\n",
    "    # TF-IDF Vectorization\n",
    "    vectorizer = TfidfVectorizer(max_features=1000, lowercase=False)\n",
    "    X = vectorizer.fit_transform(data_filtered['cleaned_text'])\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a multi-label classifier on filtered data\n",
    "    model_filtered = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "    model_filtered.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_filtered = model_filtered.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    f1 = f1_score(y_test, y_pred_filtered, average='micro')\n",
    "    hamming = hamming_loss(y_test, y_pred_filtered)\n",
    "    accuracy = accuracy_score(y_test, y_pred_filtered)\n",
    "\n",
    "    print(\"F1 Score (Micro):\", f1)\n",
    "    print(\"Hamming Loss:\", hamming)\n",
    "    print(\"Accuracy Score:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9243b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes (Filtered): ['hr' 'ai' 'r' 'recruitment' 'marketing' 'social media' 'content creation'\n",
      " 'excel' 'sales' 'product management' 'research' 'collaboration'\n",
      " 'market research' 'proto' 'operations' 'product marketing'\n",
      " 'project management' 'business development' 'lead generation' 'seo'\n",
      " 'communication' 'aws' 'logistics' 'sql' 'rest' 'problem solving'\n",
      " 'data visualization' 'python' 'react' 'tableau' 'power bi' 'java'\n",
      " 'javascript' 'b2b' 'machine learning' 'agile' 'content strategy'\n",
      " 'organizational skills']\n",
      "Counts per Class (Filtered):\n",
      "r                        147\n",
      "ai                       110\n",
      "research                  44\n",
      "marketing                 42\n",
      "sales                     31\n",
      "excel                     27\n",
      "communication             27\n",
      "operations                23\n",
      "hr                        19\n",
      "market research           19\n",
      "social media              17\n",
      "collaboration             16\n",
      "rest                      15\n",
      "sql                       14\n",
      "business development      10\n",
      "aws                        8\n",
      "project management         8\n",
      "python                     7\n",
      "recruitment                6\n",
      "content creation           6\n",
      "lead generation            5\n",
      "proto                      5\n",
      "product management         5\n",
      "react                      5\n",
      "machine learning           4\n",
      "javascript                 4\n",
      "problem solving            4\n",
      "java                       4\n",
      "agile                      3\n",
      "product marketing          3\n",
      "content strategy           3\n",
      "data visualization         3\n",
      "logistics                  3\n",
      "b2b                        3\n",
      "seo                        2\n",
      "power bi                   2\n",
      "tableau                    2\n",
      "organizational skills      2\n",
      "Name: skills, dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 108\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Train a multi-label classifier on filtered data\u001b[39;00m\n\u001b[0;32m    107\u001b[0m model_filtered \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m--> 108\u001b[0m \u001b[43mmodel_filtered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m    111\u001b[0m y_pred_filtered \u001b[38;5;241m=\u001b[39m model_filtered\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings in the relevant column\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove all non-word characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple whitespace with single space\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]  # Remove stopwords\n",
    "    return ' '.join(tokens)  # Join tokens back into a single string\n",
    "\n",
    "# Apply preprocessing to the role_description column\n",
    "data['cleaned_text'] = data['role_description'].apply(preprocess_text)\n",
    "\n",
    "# Define the skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction to the cleaned_text column\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Count the number of samples per class (skill)\n",
    "class_counts = data['skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data[data['skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Remove samples belonging to classes with only one sample\n",
    "data_filtered = data_filtered[data_filtered['skills'].apply(lambda x: len(x) > 1)]\n",
    "\n",
    "# Filter out outliers and delete them\n",
    "outlier_classes = class_counts[class_counts < 2].index\n",
    "data_filtered['skills'] = data_filtered['skills'].apply(lambda x: [skill for skill in x if skill not in outlier_classes])\n",
    "\n",
    "# Reset index after deleting rows\n",
    "data_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert filtered data to features and labels\n",
    "X_filtered = data_filtered['cleaned_text']\n",
    "y_filtered = data_filtered.drop(columns=['cleaned_text'])\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering again\n",
    "unique_classes_filtered = data_filtered['skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    print(\"There are not enough unique classes present in the filtered data after removing classes with fewer than two samples.\")\n",
    "else:\n",
    "    # Print unique classes and their counts\n",
    "    print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "    print(\"Counts per Class (Filtered):\")\n",
    "    print(data_filtered['skills'].explode().value_counts())\n",
    "\n",
    "    # Transform skills into binary labels\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    labels = mlb.fit_transform(data_filtered['skills'])\n",
    "\n",
    "    # TF-IDF Vectorization with bigrams\n",
    "    vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 2), lowercase=False)\n",
    "    X = vectorizer.fit_transform(data_filtered['cleaned_text'])\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a multi-label classifier on filtered data\n",
    "    model_filtered = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "    model_filtered.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_filtered = model_filtered.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    f1 = f1_score(y_test, y_pred_filtered, average='micro')\n",
    "    hamming = hamming_loss(y_test, y_pred_filtered)\n",
    "    accuracy = accuracy_score(y_test, y_pred_filtered)\n",
    "\n",
    "    print(\"F1 Score (Micro):\", f1)\n",
    "    print(\"Hamming Loss:\", hamming)\n",
    "    print(\"Accuracy Score:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68ad6db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes (Filtered): ['hr' 'ai' 'r' 'recruitment' 'marketing' 'social media' 'content creation'\n",
      " 'excel' 'sales' 'product management' 'research' 'collaboration'\n",
      " 'market research' 'proto' 'operations' 'product marketing'\n",
      " 'project management' 'business development' 'lead generation' 'seo'\n",
      " 'communication' 'aws' 'logistics' 'sql' 'rest' 'problem solving'\n",
      " 'data visualization' 'python' 'react' 'tableau' 'power bi' 'java'\n",
      " 'javascript' 'b2b' 'machine learning' 'agile' 'content strategy'\n",
      " 'organizational skills']\n",
      "Counts per Class (Filtered):\n",
      "r                        147\n",
      "ai                       110\n",
      "research                  44\n",
      "marketing                 42\n",
      "sales                     31\n",
      "excel                     27\n",
      "communication             27\n",
      "operations                23\n",
      "hr                        19\n",
      "market research           19\n",
      "social media              17\n",
      "collaboration             16\n",
      "rest                      15\n",
      "sql                       14\n",
      "business development      10\n",
      "aws                        8\n",
      "project management         8\n",
      "python                     7\n",
      "recruitment                6\n",
      "content creation           6\n",
      "lead generation            5\n",
      "proto                      5\n",
      "product management         5\n",
      "react                      5\n",
      "machine learning           4\n",
      "javascript                 4\n",
      "problem solving            4\n",
      "java                       4\n",
      "agile                      3\n",
      "product marketing          3\n",
      "content strategy           3\n",
      "data visualization         3\n",
      "logistics                  3\n",
      "b2b                        3\n",
      "seo                        2\n",
      "power bi                   2\n",
      "tableau                    2\n",
      "organizational skills      2\n",
      "Name: skills, dtype: int64\n",
      "F1 Score (Micro): 0.6944444444444445\n",
      "Hamming Loss: 0.05789473684210526\n",
      "Accuracy Score: 0.13333333333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings in the relevant column\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "\n",
    "# Function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove all non-word characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple whitespace with single space\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]  # Remove stopwords\n",
    "    return ' '.join(tokens)  # Join tokens back into a single string\n",
    "\n",
    "# Apply preprocessing to the role_description column\n",
    "data['cleaned_text'] = data['role_description'].apply(preprocess_text)\n",
    "\n",
    "# Define the skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction to the cleaned_text column\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Count the number of samples per class (skill)\n",
    "class_counts = data['skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data[data['skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Remove samples belonging to classes with only one sample\n",
    "data_filtered = data_filtered[data_filtered['skills'].apply(lambda x: len(x) > 1)]\n",
    "\n",
    "# Filter out outliers and delete them\n",
    "outlier_classes = class_counts[class_counts < 2].index\n",
    "data_filtered['skills'] = data_filtered['skills'].apply(lambda x: [skill for skill in x if skill not in outlier_classes])\n",
    "\n",
    "# Reset index after deleting rows\n",
    "data_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert filtered data to features and labels\n",
    "X_filtered = data_filtered['cleaned_text']\n",
    "y_filtered = data_filtered.drop(columns=['cleaned_text'])\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering again\n",
    "unique_classes_filtered = data_filtered['skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    print(\"There are not enough unique classes present in the filtered data after removing classes with fewer than two samples.\")\n",
    "else:\n",
    "    # Print unique classes and their counts\n",
    "    print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "    print(\"Counts per Class (Filtered):\")\n",
    "    print(data_filtered['skills'].explode().value_counts())\n",
    "\n",
    "    # Transform skills into binary labels\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    labels = mlb.fit_transform(data_filtered['skills'])\n",
    "\n",
    "    # TF-IDF Vectorization with bigrams\n",
    "    vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 2), lowercase=False)\n",
    "    X = vectorizer.fit_transform(data_filtered['cleaned_text'])\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a multi-label classifier on filtered data using RandomForestClassifier\n",
    "    model_filtered = MultiOutputClassifier(RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    model_filtered.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_filtered = model_filtered.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    f1 = f1_score(y_test, y_pred_filtered, average='micro')\n",
    "    hamming = hamming_loss(y_test, y_pred_filtered)\n",
    "    accuracy = accuracy_score(y_test, y_pred_filtered)\n",
    "\n",
    "    print(\"F1 Score (Micro):\", f1)\n",
    "    print(\"Hamming Loss:\", hamming)\n",
    "    print(\"Accuracy Score:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06a233c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes (Filtered): ['hr' 'ai' 'r' 'recruitment' 'marketing' 'content creation' 'excel'\n",
      " 'product management' 'research' 'collaboration' 'market research' 'proto'\n",
      " 'product marketing' 'project management' 'business development'\n",
      " 'lead generation' 'seo' 'communication' 'aws' 'logistics' 'sql' 'rest'\n",
      " 'problem solving' 'data visualization' 'python' 'react' 'tableau'\n",
      " 'power bi' 'java' 'javascript' 'b2b' 'machine learning' 'agile'\n",
      " 'content strategy']\n",
      "Counts per Class (Filtered):\n",
      "r                       146\n",
      "ai                      110\n",
      "research                 44\n",
      "marketing                42\n",
      "communication            27\n",
      "excel                    27\n",
      "market research          19\n",
      "hr                       19\n",
      "collaboration            16\n",
      "rest                     15\n",
      "sql                      14\n",
      "business development     10\n",
      "aws                       8\n",
      "project management        8\n",
      "python                    7\n",
      "content creation          6\n",
      "recruitment               6\n",
      "react                     5\n",
      "product management        5\n",
      "lead generation           5\n",
      "proto                     5\n",
      "problem solving           4\n",
      "java                      4\n",
      "javascript                4\n",
      "machine learning          4\n",
      "logistics                 3\n",
      "data visualization        3\n",
      "product marketing         3\n",
      "b2b                       3\n",
      "agile                     3\n",
      "content strategy          3\n",
      "seo                       2\n",
      "tableau                   2\n",
      "power bi                  2\n",
      "Name: skills, dtype: int64\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "F1 Score (Micro): 0.6804123711340205\n",
      "Hamming Loss: 0.060784313725490195\n",
      "Accuracy Score: 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings in the relevant column\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "\n",
    "# Function for text cleaning with lemmatization\n",
    "def preprocess_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove all non-word characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple whitespace with single space\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stopwords.words('english')]  # Lemmatize and remove stopwords\n",
    "    return ' '.join(tokens)  # Join tokens back into a single string\n",
    "\n",
    "# Apply preprocessing to the role_description column\n",
    "data['cleaned_text'] = data['role_description'].apply(preprocess_text)\n",
    "\n",
    "# Define the skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction to the cleaned_text column\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Count the number of samples per class (skill)\n",
    "class_counts = data['skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data[data['skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Remove samples belonging to classes with only one sample\n",
    "data_filtered = data_filtered[data_filtered['skills'].apply(lambda x: len(x) > 1)]\n",
    "\n",
    "# Filter out outliers and delete them\n",
    "outlier_classes = class_counts[class_counts < 2].index\n",
    "data_filtered['skills'] = data_filtered['skills'].apply(lambda x: [skill for skill in x if skill not in outlier_classes])\n",
    "\n",
    "# Reset index after deleting rows\n",
    "data_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert filtered data to features and labels\n",
    "X_filtered = data_filtered['cleaned_text']\n",
    "y_filtered = data_filtered.drop(columns=['cleaned_text'])\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering again\n",
    "unique_classes_filtered = data_filtered['skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    print(\"There are not enough unique classes present in the filtered data after removing classes with fewer than two samples.\")\n",
    "else:\n",
    "    # Print unique classes and their counts\n",
    "    print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "    print(\"Counts per Class (Filtered):\")\n",
    "    print(data_filtered['skills'].explode().value_counts())\n",
    "\n",
    "    # Transform skills into binary labels\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    labels = mlb.fit_transform(data_filtered['skills'])\n",
    "\n",
    "    # TF-IDF Vectorization with trigrams\n",
    "    vectorizer = TfidfVectorizer(max_features=2000, ngram_range=(1, 3), lowercase=False)\n",
    "    X = vectorizer.fit_transform(data_filtered['cleaned_text'])\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the model with RandomForestClassifier\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    # Define the parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best model\n",
    "    best_rf = grid_search.best_estimator_\n",
    "\n",
    "    # Train a multi-label classifier on filtered data using the best RandomForestClassifier\n",
    "    model_filtered = MultiOutputClassifier(best_rf)\n",
    "    model_filtered.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_filtered = model_filtered.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    f1 = f1_score(y_test, y_pred_filtered, average='micro')\n",
    "    hamming = hamming_loss(y_test, y_pred_filtered)\n",
    "    accuracy = accuracy_score(y_test, y_pred_filtered)\n",
    "\n",
    "    print(\"F1 Score (Micro):\", f1)\n",
    "    print(\"Hamming Loss:\", hamming)\n",
    "    print(\"Accuracy Score:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed5cb219",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultioutput\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiOutputClassifier\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier, GradientBoostingClassifier\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score, hamming_loss, accuracy_score\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertModel\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings in the relevant column\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "\n",
    "# Function for text cleaning with stemming and lemmatization\n",
    "def preprocess_text(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove all non-word characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple whitespace with single space\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    tokens = [lemmatizer.lemmatize(stemmer.stem(word)) for word in tokens if word not in stopwords.words('english')]  # Stem and lemmatize, remove stopwords\n",
    "    return ' '.join(tokens)  # Join tokens back into a single string\n",
    "\n",
    "# Apply preprocessing to the role_description column\n",
    "data['cleaned_text'] = data['role_description'].apply(preprocess_text)\n",
    "\n",
    "# Define the skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction to the cleaned_text column\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Count the number of samples per class (skill)\n",
    "class_counts = data['skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data[data['skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Remove samples belonging to classes with only one sample\n",
    "data_filtered = data_filtered[data_filtered['skills'].apply(lambda x: len(x) > 1)]\n",
    "\n",
    "# Filter out outliers and delete them\n",
    "outlier_classes = class_counts[class_counts < 2].index\n",
    "data_filtered['skills'] = data_filtered['skills'].apply(lambda x: [skill for skill in x if skill not in outlier_classes])\n",
    "\n",
    "# Reset index after deleting rows\n",
    "data_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert filtered data to features and labels\n",
    "X_filtered = data_filtered['cleaned_text']\n",
    "y_filtered = data_filtered.drop(columns=['cleaned_text'])\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering again\n",
    "unique_classes_filtered = data_filtered['skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    print(\"There are not enough unique classes present in the filtered data after removing classes with fewer than two samples.\")\n",
    "else:\n",
    "    # Print unique classes and their counts\n",
    "    print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "    print(\"Counts per Class (Filtered):\")\n",
    "    print(data_filtered['skills'].explode().value_counts())\n",
    "\n",
    "    # Transform skills into binary labels\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    labels = mlb.fit_transform(data_filtered['skills'])\n",
    "\n",
    "    # TF-IDF Vectorization with trigrams\n",
    "    vectorizer = TfidfVectorizer(max_features=3000, ngram_range=(1, 3), lowercase=False)\n",
    "    X_tfidf = vectorizer.fit_transform(data_filtered['cleaned_text'])\n",
    "\n",
    "    # Load BERT model and tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Function to extract BERT embeddings\n",
    "    def get_bert_embeddings(text):\n",
    "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        outputs = bert_model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "        return embeddings\n",
    "\n",
    "    # Apply BERT embeddings to the cleaned_text column\n",
    "    X_bert = np.array([get_bert_embeddings(text) for text in data_filtered['cleaned_text']])\n",
    "    X_bert = np.squeeze(X_bert)\n",
    "\n",
    "    # Combine TF-IDF and BERT embeddings\n",
    "    X_combined = np.hstack((X_tfidf.toarray(), X_bert))\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_combined, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the model with RandomForestClassifier\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    # Define the parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best model\n",
    "    best_rf = grid_search.best_estimator_\n",
    "\n",
    "    # Train a multi-label classifier on filtered data using the best RandomForestClassifier\n",
    "    model_rf = MultiOutputClassifier(best_rf)\n",
    "    model_rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set using RandomForestClassifier\n",
    "    y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "    # Evaluate the RandomForestClassifier model\n",
    "    f1_rf = f1_score(y_test, y_pred_rf, average='micro')\n",
    "    hamming_rf = hamming_loss(y_test, y_pred_rf)\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "    print(\"RandomForestClassifier\")\n",
    "    print(\"F1 Score (Micro):\", f1_rf)\n",
    "    print(\"Hamming Loss:\", hamming_rf)\n",
    "    print(\"Accuracy Score:\", accuracy_rf)\n",
    "\n",
    "    # Train a multi-label classifier on filtered data using XGBoost\n",
    "    xgb = XGBClassifier(objective='multi:softprob', eval_metric='mlogloss')\n",
    "    model_xgb = MultiOutputClassifier(xgb)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set using XGBoost\n",
    "    y_pred_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "    # Evaluate the XGBoost model\n",
    "    f1_xgb = f1_score(y_test, y_pred_xgb, average='micro')\n",
    "    hamming_xgb = hamming_loss(y_test, y_pred_xgb)\n",
    "    accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "\n",
    "    print(\"XGBoost\")\n",
    "    print(\"F1 Score (Micro):\", f1_xgb)\n",
    "    print(\"Hamming Loss:\", hamming_xgb)\n",
    "    print(\"Accuracy Score:\", accuracy_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4ed8977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.24.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\hsahn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.10.1)\n",
      "Downloading xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n",
      "   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/99.8 MB 991.0 kB/s eta 0:01:41\n",
      "   ---------------------------------------- 0.1/99.8 MB 787.7 kB/s eta 0:02:07\n",
      "   ---------------------------------------- 0.1/99.8 MB 939.4 kB/s eta 0:01:47\n",
      "   ---------------------------------------- 0.2/99.8 MB 706.2 kB/s eta 0:02:22\n",
      "   ---------------------------------------- 0.2/99.8 MB 737.3 kB/s eta 0:02:16\n",
      "   ---------------------------------------- 0.2/99.8 MB 737.3 kB/s eta 0:02:16\n",
      "   ---------------------------------------- 0.3/99.8 MB 787.7 kB/s eta 0:02:07\n",
      "   ---------------------------------------- 0.3/99.8 MB 776.2 kB/s eta 0:02:09\n",
      "   ---------------------------------------- 0.3/99.8 MB 708.9 kB/s eta 0:02:21\n",
      "   ---------------------------------------- 0.3/99.8 MB 749.8 kB/s eta 0:02:13\n",
      "   ---------------------------------------- 0.3/99.8 MB 749.8 kB/s eta 0:02:13\n",
      "   ---------------------------------------- 0.3/99.8 MB 749.8 kB/s eta 0:02:13\n",
      "   ---------------------------------------- 0.4/99.8 MB 620.1 kB/s eta 0:02:41\n",
      "   ---------------------------------------- 0.4/99.8 MB 606.2 kB/s eta 0:02:44\n",
      "   ---------------------------------------- 0.4/99.8 MB 622.6 kB/s eta 0:02:40\n",
      "   ---------------------------------------- 0.4/99.8 MB 622.6 kB/s eta 0:02:40\n",
      "   ---------------------------------------- 0.4/99.8 MB 546.1 kB/s eta 0:03:02\n",
      "   ---------------------------------------- 0.4/99.8 MB 546.1 kB/s eta 0:03:02\n",
      "   ---------------------------------------- 0.4/99.8 MB 529.7 kB/s eta 0:03:08\n",
      "   ---------------------------------------- 0.4/99.8 MB 529.7 kB/s eta 0:03:08\n",
      "   ---------------------------------------- 0.4/99.8 MB 529.7 kB/s eta 0:03:08\n",
      "   ---------------------------------------- 0.5/99.8 MB 476.0 kB/s eta 0:03:29\n",
      "   ---------------------------------------- 0.5/99.8 MB 476.0 kB/s eta 0:03:29\n",
      "   ---------------------------------------- 0.5/99.8 MB 456.9 kB/s eta 0:03:38\n",
      "   ---------------------------------------- 0.5/99.8 MB 482.1 kB/s eta 0:03:26\n",
      "   ---------------------------------------- 0.5/99.8 MB 458.1 kB/s eta 0:03:37\n",
      "   ---------------------------------------- 0.6/99.8 MB 478.3 kB/s eta 0:03:28\n",
      "   ---------------------------------------- 0.6/99.8 MB 476.7 kB/s eta 0:03:29\n",
      "   ---------------------------------------- 0.6/99.8 MB 477.6 kB/s eta 0:03:28\n",
      "   ---------------------------------------- 0.6/99.8 MB 483.9 kB/s eta 0:03:25\n",
      "   ---------------------------------------- 0.7/99.8 MB 549.0 kB/s eta 0:03:01\n",
      "   ---------------------------------------- 0.8/99.8 MB 589.4 kB/s eta 0:02:48\n",
      "   ---------------------------------------- 0.8/99.8 MB 597.2 kB/s eta 0:02:46\n",
      "   ---------------------------------------- 1.0/99.8 MB 648.7 kB/s eta 0:02:33\n",
      "   ---------------------------------------- 1.0/99.8 MB 641.7 kB/s eta 0:02:34\n",
      "   ---------------------------------------- 1.0/99.8 MB 635.9 kB/s eta 0:02:36\n",
      "   ---------------------------------------- 1.0/99.8 MB 642.8 kB/s eta 0:02:34\n",
      "   ---------------------------------------- 1.1/99.8 MB 649.4 kB/s eta 0:02:32\n",
      "   ---------------------------------------- 1.1/99.8 MB 667.4 kB/s eta 0:02:28\n",
      "   ---------------------------------------- 1.2/99.8 MB 673.2 kB/s eta 0:02:27\n",
      "   ---------------------------------------- 1.2/99.8 MB 678.5 kB/s eta 0:02:26\n",
      "    --------------------------------------- 1.3/99.8 MB 677.9 kB/s eta 0:02:26\n",
      "    --------------------------------------- 1.3/99.8 MB 688.1 kB/s eta 0:02:24\n",
      "    --------------------------------------- 1.3/99.8 MB 688.1 kB/s eta 0:02:24\n",
      "    --------------------------------------- 1.3/99.8 MB 676.4 kB/s eta 0:02:26\n",
      "    --------------------------------------- 1.4/99.8 MB 681.3 kB/s eta 0:02:25\n",
      "    --------------------------------------- 1.4/99.8 MB 675.4 kB/s eta 0:02:26\n",
      "    --------------------------------------- 1.4/99.8 MB 675.4 kB/s eta 0:02:26\n",
      "    --------------------------------------- 1.4/99.8 MB 675.4 kB/s eta 0:02:26\n",
      "    --------------------------------------- 1.5/99.8 MB 674.2 kB/s eta 0:02:26\n",
      "    --------------------------------------- 1.5/99.8 MB 674.2 kB/s eta 0:02:26\n",
      "    --------------------------------------- 1.5/99.8 MB 655.6 kB/s eta 0:02:30\n",
      "    --------------------------------------- 1.6/99.8 MB 659.9 kB/s eta 0:02:29\n",
      "    --------------------------------------- 1.6/99.8 MB 664.3 kB/s eta 0:02:28\n",
      "    --------------------------------------- 1.6/99.8 MB 651.4 kB/s eta 0:02:31\n",
      "    --------------------------------------- 1.6/99.8 MB 667.9 kB/s eta 0:02:27\n",
      "    --------------------------------------- 1.7/99.8 MB 671.9 kB/s eta 0:02:26\n",
      "    --------------------------------------- 1.8/99.8 MB 687.8 kB/s eta 0:02:23\n",
      "    --------------------------------------- 1.8/99.8 MB 691.1 kB/s eta 0:02:22\n",
      "    --------------------------------------- 1.8/99.8 MB 690.1 kB/s eta 0:02:22\n",
      "    --------------------------------------- 1.9/99.8 MB 697.1 kB/s eta 0:02:21\n",
      "    --------------------------------------- 1.9/99.8 MB 688.8 kB/s eta 0:02:23\n",
      "    --------------------------------------- 2.0/99.8 MB 699.5 kB/s eta 0:02:20\n",
      "    --------------------------------------- 2.0/99.8 MB 698.8 kB/s eta 0:02:20\n",
      "    --------------------------------------- 2.0/99.8 MB 690.9 kB/s eta 0:02:22\n",
      "    --------------------------------------- 2.0/99.8 MB 686.9 kB/s eta 0:02:23\n",
      "    --------------------------------------- 2.1/99.8 MB 703.5 kB/s eta 0:02:19\n",
      "    --------------------------------------- 2.1/99.8 MB 706.6 kB/s eta 0:02:19\n",
      "    --------------------------------------- 2.2/99.8 MB 705.6 kB/s eta 0:02:19\n",
      "    --------------------------------------- 2.2/99.8 MB 705.6 kB/s eta 0:02:19\n",
      "    --------------------------------------- 2.3/99.8 MB 707.2 kB/s eta 0:02:18\n",
      "    --------------------------------------- 2.3/99.8 MB 716.5 kB/s eta 0:02:17\n",
      "    --------------------------------------- 2.3/99.8 MB 712.1 kB/s eta 0:02:17\n",
      "    --------------------------------------- 2.3/99.8 MB 705.2 kB/s eta 0:02:19\n",
      "    --------------------------------------- 2.3/99.8 MB 704.9 kB/s eta 0:02:19\n",
      "    --------------------------------------- 2.4/99.8 MB 701.2 kB/s eta 0:02:19\n",
      "    --------------------------------------- 2.4/99.8 MB 694.5 kB/s eta 0:02:21\n",
      "    --------------------------------------- 2.4/99.8 MB 694.5 kB/s eta 0:02:21\n",
      "    --------------------------------------- 2.5/99.8 MB 696.3 kB/s eta 0:02:20\n",
      "   - -------------------------------------- 2.5/99.8 MB 698.6 kB/s eta 0:02:20\n",
      "   - -------------------------------------- 2.5/99.8 MB 700.8 kB/s eta 0:02:19\n",
      "   - -------------------------------------- 2.6/99.8 MB 703.4 kB/s eta 0:02:19\n",
      "   - -------------------------------------- 2.6/99.8 MB 703.0 kB/s eta 0:02:19\n",
      "   - -------------------------------------- 2.6/99.8 MB 704.8 kB/s eta 0:02:18\n",
      "   - -------------------------------------- 2.7/99.8 MB 709.6 kB/s eta 0:02:17\n",
      "   - -------------------------------------- 2.7/99.8 MB 708.9 kB/s eta 0:02:17\n",
      "   - -------------------------------------- 2.7/99.8 MB 708.5 kB/s eta 0:02:17\n",
      "   - -------------------------------------- 2.8/99.8 MB 702.6 kB/s eta 0:02:19\n",
      "   - -------------------------------------- 2.8/99.8 MB 699.4 kB/s eta 0:02:19\n",
      "   - -------------------------------------- 2.8/99.8 MB 699.4 kB/s eta 0:02:19\n",
      "   - -------------------------------------- 2.8/99.8 MB 693.5 kB/s eta 0:02:20\n",
      "   - -------------------------------------- 2.8/99.8 MB 690.5 kB/s eta 0:02:21\n",
      "   - -------------------------------------- 2.8/99.8 MB 690.5 kB/s eta 0:02:21\n",
      "   - -------------------------------------- 2.8/99.8 MB 682.7 kB/s eta 0:02:22\n",
      "   - -------------------------------------- 2.8/99.8 MB 682.7 kB/s eta 0:02:22\n",
      "   - -------------------------------------- 2.8/99.8 MB 682.7 kB/s eta 0:02:22\n",
      "   - -------------------------------------- 2.9/99.8 MB 669.8 kB/s eta 0:02:25\n",
      "   - -------------------------------------- 2.9/99.8 MB 669.6 kB/s eta 0:02:25\n",
      "   - -------------------------------------- 2.9/99.8 MB 662.5 kB/s eta 0:02:27\n",
      "   - -------------------------------------- 2.9/99.8 MB 660.0 kB/s eta 0:02:27\n",
      "   - -------------------------------------- 2.9/99.8 MB 655.4 kB/s eta 0:02:28\n",
      "   - -------------------------------------- 3.0/99.8 MB 655.5 kB/s eta 0:02:28\n",
      "   - -------------------------------------- 3.0/99.8 MB 655.5 kB/s eta 0:02:28\n",
      "   - -------------------------------------- 3.0/99.8 MB 648.7 kB/s eta 0:02:30\n",
      "   - -------------------------------------- 3.0/99.8 MB 653.1 kB/s eta 0:02:29\n",
      "   - -------------------------------------- 3.1/99.8 MB 653.2 kB/s eta 0:02:28\n",
      "   - -------------------------------------- 3.1/99.8 MB 655.5 kB/s eta 0:02:28\n",
      "   - -------------------------------------- 3.1/99.8 MB 653.2 kB/s eta 0:02:28\n",
      "   - -------------------------------------- 3.2/99.8 MB 653.3 kB/s eta 0:02:28\n",
      "   - -------------------------------------- 3.2/99.8 MB 653.3 kB/s eta 0:02:28\n",
      "   - -------------------------------------- 3.2/99.8 MB 649.1 kB/s eta 0:02:29\n",
      "   - -------------------------------------- 3.2/99.8 MB 651.3 kB/s eta 0:02:29\n",
      "   - -------------------------------------- 3.2/99.8 MB 651.2 kB/s eta 0:02:29\n",
      "   - -------------------------------------- 3.3/99.8 MB 649.3 kB/s eta 0:02:29\n",
      "   - -------------------------------------- 3.3/99.8 MB 649.3 kB/s eta 0:02:29\n",
      "   - -------------------------------------- 3.3/99.8 MB 647.4 kB/s eta 0:02:29\n",
      "   - -------------------------------------- 3.4/99.8 MB 649.4 kB/s eta 0:02:29\n",
      "   - -------------------------------------- 3.5/99.8 MB 665.3 kB/s eta 0:02:25\n",
      "   - -------------------------------------- 3.6/99.8 MB 672.9 kB/s eta 0:02:23\n",
      "   - -------------------------------------- 3.6/99.8 MB 676.6 kB/s eta 0:02:23\n",
      "   - -------------------------------------- 3.7/99.8 MB 691.9 kB/s eta 0:02:19\n",
      "   - -------------------------------------- 3.7/99.8 MB 689.6 kB/s eta 0:02:20\n",
      "   - -------------------------------------- 3.8/99.8 MB 697.0 kB/s eta 0:02:18\n",
      "   - -------------------------------------- 3.8/99.8 MB 700.4 kB/s eta 0:02:17\n",
      "   - -------------------------------------- 3.9/99.8 MB 703.5 kB/s eta 0:02:17\n",
      "   - -------------------------------------- 3.9/99.8 MB 707.2 kB/s eta 0:02:16\n",
      "   - -------------------------------------- 4.0/99.8 MB 711.8 kB/s eta 0:02:15\n",
      "   - -------------------------------------- 4.1/99.8 MB 716.9 kB/s eta 0:02:14\n",
      "   - -------------------------------------- 4.1/99.8 MB 718.1 kB/s eta 0:02:14\n",
      "   - -------------------------------------- 4.1/99.8 MB 718.1 kB/s eta 0:02:14\n",
      "   - -------------------------------------- 4.2/99.8 MB 717.1 kB/s eta 0:02:14\n",
      "   - -------------------------------------- 4.2/99.8 MB 720.1 kB/s eta 0:02:13\n",
      "   - -------------------------------------- 4.2/99.8 MB 721.6 kB/s eta 0:02:13\n",
      "   - -------------------------------------- 4.3/99.8 MB 726.4 kB/s eta 0:02:12\n",
      "   - -------------------------------------- 4.4/99.8 MB 729.2 kB/s eta 0:02:11\n",
      "   - -------------------------------------- 4.4/99.8 MB 729.2 kB/s eta 0:02:11\n",
      "   - -------------------------------------- 4.4/99.8 MB 729.2 kB/s eta 0:02:11\n",
      "   - -------------------------------------- 4.4/99.8 MB 724.3 kB/s eta 0:02:12\n",
      "   - -------------------------------------- 4.5/99.8 MB 723.8 kB/s eta 0:02:12\n",
      "   - -------------------------------------- 4.5/99.8 MB 725.2 kB/s eta 0:02:12\n",
      "   - -------------------------------------- 4.5/99.8 MB 725.2 kB/s eta 0:02:12\n",
      "   - -------------------------------------- 4.5/99.8 MB 717.5 kB/s eta 0:02:13\n",
      "   - -------------------------------------- 4.5/99.8 MB 717.5 kB/s eta 0:02:13\n",
      "   - -------------------------------------- 4.5/99.8 MB 710.0 kB/s eta 0:02:15\n",
      "   - -------------------------------------- 4.6/99.8 MB 711.5 kB/s eta 0:02:14\n",
      "   - -------------------------------------- 4.6/99.8 MB 714.1 kB/s eta 0:02:14\n",
      "   - -------------------------------------- 4.6/99.8 MB 714.1 kB/s eta 0:02:14\n",
      "   - -------------------------------------- 4.6/99.8 MB 714.1 kB/s eta 0:02:14\n",
      "   - -------------------------------------- 4.7/99.8 MB 706.7 kB/s eta 0:02:15\n",
      "   - -------------------------------------- 4.7/99.8 MB 712.5 kB/s eta 0:02:14\n",
      "   - -------------------------------------- 4.8/99.8 MB 716.5 kB/s eta 0:02:13\n",
      "   - -------------------------------------- 4.9/99.8 MB 720.8 kB/s eta 0:02:12\n",
      "   - -------------------------------------- 4.9/99.8 MB 725.1 kB/s eta 0:02:11\n",
      "   - -------------------------------------- 5.0/99.8 MB 725.9 kB/s eta 0:02:11\n",
      "   -- ------------------------------------- 5.0/99.8 MB 729.8 kB/s eta 0:02:10\n",
      "   -- ------------------------------------- 5.1/99.8 MB 730.9 kB/s eta 0:02:10\n",
      "   -- ------------------------------------- 5.1/99.8 MB 733.4 kB/s eta 0:02:10\n",
      "   -- ------------------------------------- 5.1/99.8 MB 733.1 kB/s eta 0:02:10\n",
      "   -- ------------------------------------- 5.2/99.8 MB 736.6 kB/s eta 0:02:09\n",
      "   -- ------------------------------------- 5.3/99.8 MB 737.5 kB/s eta 0:02:09\n",
      "   -- ------------------------------------- 5.3/99.8 MB 738.6 kB/s eta 0:02:08\n",
      "   -- ------------------------------------- 5.4/99.8 MB 745.2 kB/s eta 0:02:07\n",
      "   -- ------------------------------------- 5.4/99.8 MB 743.2 kB/s eta 0:02:07\n",
      "   -- ------------------------------------- 5.4/99.8 MB 748.4 kB/s eta 0:02:06\n",
      "   -- ------------------------------------- 5.5/99.8 MB 750.9 kB/s eta 0:02:06\n",
      "   -- ------------------------------------- 5.5/99.8 MB 750.0 kB/s eta 0:02:06\n",
      "   -- ------------------------------------- 5.6/99.8 MB 750.8 kB/s eta 0:02:06\n",
      "   -- ------------------------------------- 5.6/99.8 MB 751.5 kB/s eta 0:02:06\n",
      "   -- ------------------------------------- 5.7/99.8 MB 755.3 kB/s eta 0:02:05\n",
      "   -- ------------------------------------- 5.7/99.8 MB 759.9 kB/s eta 0:02:04\n",
      "   -- ------------------------------------- 5.8/99.8 MB 762.0 kB/s eta 0:02:04\n",
      "   -- ------------------------------------- 5.8/99.8 MB 765.5 kB/s eta 0:02:03\n",
      "   -- ------------------------------------- 5.9/99.8 MB 764.9 kB/s eta 0:02:03\n",
      "   -- ------------------------------------- 5.9/99.8 MB 763.7 kB/s eta 0:02:03\n",
      "   -- ------------------------------------- 6.0/99.8 MB 766.2 kB/s eta 0:02:03\n",
      "   -- ------------------------------------- 6.0/99.8 MB 764.8 kB/s eta 0:02:03\n",
      "   -- ------------------------------------- 6.1/99.8 MB 768.5 kB/s eta 0:02:02\n",
      "   -- ------------------------------------- 6.1/99.8 MB 771.3 kB/s eta 0:02:02\n",
      "   -- ------------------------------------- 6.2/99.8 MB 770.8 kB/s eta 0:02:02\n",
      "   -- ------------------------------------- 6.2/99.8 MB 775.2 kB/s eta 0:02:01\n",
      "   -- ------------------------------------- 6.3/99.8 MB 777.1 kB/s eta 0:02:01\n",
      "   -- ------------------------------------- 6.3/99.8 MB 781.7 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 6.4/99.8 MB 782.2 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 6.4/99.8 MB 780.0 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 6.5/99.8 MB 777.8 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 6.5/99.8 MB 777.8 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 6.5/99.8 MB 774.2 kB/s eta 0:02:01\n",
      "   -- ------------------------------------- 6.5/99.8 MB 773.5 kB/s eta 0:02:01\n",
      "   -- ------------------------------------- 6.5/99.8 MB 774.6 kB/s eta 0:02:01\n",
      "   -- ------------------------------------- 6.6/99.8 MB 771.3 kB/s eta 0:02:01\n",
      "   -- ------------------------------------- 6.6/99.8 MB 771.8 kB/s eta 0:02:01\n",
      "   -- ------------------------------------- 6.6/99.8 MB 773.5 kB/s eta 0:02:01\n",
      "   -- ------------------------------------- 6.7/99.8 MB 776.7 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 6.7/99.8 MB 777.5 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 6.8/99.8 MB 776.8 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 6.8/99.8 MB 777.1 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 6.9/99.8 MB 778.8 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 6.9/99.8 MB 779.5 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 6.9/99.8 MB 777.7 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 6.9/99.8 MB 777.5 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 7.0/99.8 MB 776.9 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 7.0/99.8 MB 777.1 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 7.0/99.8 MB 776.7 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 7.0/99.8 MB 772.5 kB/s eta 0:02:01\n",
      "   -- ------------------------------------- 7.1/99.8 MB 775.0 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 7.2/99.8 MB 776.5 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 7.2/99.8 MB 775.9 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 7.2/99.8 MB 775.3 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 7.2/99.8 MB 774.9 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 7.3/99.8 MB 772.1 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 7.3/99.8 MB 771.7 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 7.3/99.8 MB 766.4 kB/s eta 0:02:01\n",
      "   -- ------------------------------------- 7.3/99.8 MB 764.8 kB/s eta 0:02:01\n",
      "   -- ------------------------------------- 7.3/99.8 MB 763.2 kB/s eta 0:02:02\n",
      "   -- ------------------------------------- 7.4/99.8 MB 763.9 kB/s eta 0:02:01\n",
      "   -- ------------------------------------- 7.4/99.8 MB 762.5 kB/s eta 0:02:02\n",
      "   -- ------------------------------------- 7.4/99.8 MB 759.7 kB/s eta 0:02:02\n",
      "   -- ------------------------------------- 7.4/99.8 MB 759.7 kB/s eta 0:02:02\n",
      "   -- ------------------------------------- 7.4/99.8 MB 759.7 kB/s eta 0:02:02\n",
      "   -- ------------------------------------- 7.4/99.8 MB 754.1 kB/s eta 0:02:03\n",
      "   -- ------------------------------------- 7.4/99.8 MB 754.1 kB/s eta 0:02:03\n",
      "   --- ------------------------------------ 7.5/99.8 MB 754.6 kB/s eta 0:02:03\n",
      "   --- ------------------------------------ 7.5/99.8 MB 753.1 kB/s eta 0:02:03\n",
      "   --- ------------------------------------ 7.6/99.8 MB 754.7 kB/s eta 0:02:03\n",
      "   --- ------------------------------------ 7.6/99.8 MB 754.7 kB/s eta 0:02:03\n",
      "   --- ------------------------------------ 7.6/99.8 MB 754.7 kB/s eta 0:02:03\n",
      "   --- ------------------------------------ 7.6/99.8 MB 744.1 kB/s eta 0:02:04\n",
      "   --- ------------------------------------ 7.6/99.8 MB 744.1 kB/s eta 0:02:04\n",
      "   --- ------------------------------------ 7.6/99.8 MB 741.3 kB/s eta 0:02:05\n",
      "   --- ------------------------------------ 7.6/99.8 MB 741.3 kB/s eta 0:02:05\n",
      "   --- ------------------------------------ 7.6/99.8 MB 738.6 kB/s eta 0:02:05\n",
      "   --- ------------------------------------ 7.6/99.8 MB 738.6 kB/s eta 0:02:05\n",
      "   --- ------------------------------------ 7.7/99.8 MB 736.0 kB/s eta 0:02:06\n",
      "   --- ------------------------------------ 7.7/99.8 MB 737.4 kB/s eta 0:02:05\n",
      "   --- ------------------------------------ 7.8/99.8 MB 738.0 kB/s eta 0:02:05\n",
      "   --- ------------------------------------ 7.8/99.8 MB 738.8 kB/s eta 0:02:05\n",
      "   --- ------------------------------------ 7.9/99.8 MB 742.1 kB/s eta 0:02:04\n",
      "   --- ------------------------------------ 7.9/99.8 MB 742.6 kB/s eta 0:02:04\n",
      "   --- ------------------------------------ 8.0/99.8 MB 744.3 kB/s eta 0:02:04\n",
      "   --- ------------------------------------ 8.0/99.8 MB 745.1 kB/s eta 0:02:04\n",
      "   --- ------------------------------------ 8.0/99.8 MB 745.1 kB/s eta 0:02:04\n",
      "   --- ------------------------------------ 8.0/99.8 MB 740.4 kB/s eta 0:02:04\n",
      "   --- ------------------------------------ 8.1/99.8 MB 740.1 kB/s eta 0:02:04\n",
      "   --- ------------------------------------ 8.1/99.8 MB 737.9 kB/s eta 0:02:05\n",
      "   --- ------------------------------------ 8.1/99.8 MB 737.3 kB/s eta 0:02:05\n",
      "   --- ------------------------------------ 8.2/99.8 MB 737.0 kB/s eta 0:02:05\n",
      "   --- ------------------------------------ 8.2/99.8 MB 737.0 kB/s eta 0:02:05\n",
      "   --- ------------------------------------ 8.2/99.8 MB 734.4 kB/s eta 0:02:05\n",
      "   --- ------------------------------------ 8.2/99.8 MB 734.2 kB/s eta 0:02:05\n",
      "   --- ------------------------------------ 8.2/99.8 MB 733.1 kB/s eta 0:02:05\n",
      "   --- ------------------------------------ 8.2/99.8 MB 729.8 kB/s eta 0:02:06\n",
      "   --- ------------------------------------ 8.3/99.8 MB 732.2 kB/s eta 0:02:05\n",
      "   --- ------------------------------------ 8.4/99.8 MB 736.4 kB/s eta 0:02:05\n",
      "   --- ------------------------------------ 8.4/99.8 MB 739.9 kB/s eta 0:02:04\n",
      "   --- ------------------------------------ 8.5/99.8 MB 743.0 kB/s eta 0:02:03\n",
      "   --- ------------------------------------ 8.6/99.8 MB 744.4 kB/s eta 0:02:03\n",
      "   --- ------------------------------------ 8.7/99.8 MB 748.5 kB/s eta 0:02:02\n",
      "   --- ------------------------------------ 8.7/99.8 MB 748.1 kB/s eta 0:02:02\n",
      "   --- ------------------------------------ 8.8/99.8 MB 754.8 kB/s eta 0:02:01\n",
      "   --- ------------------------------------ 8.8/99.8 MB 756.4 kB/s eta 0:02:01\n",
      "   --- ------------------------------------ 8.9/99.8 MB 757.3 kB/s eta 0:02:00\n",
      "   --- ------------------------------------ 9.0/99.8 MB 764.8 kB/s eta 0:01:59\n",
      "   --- ------------------------------------ 9.0/99.8 MB 764.6 kB/s eta 0:01:59\n",
      "   --- ------------------------------------ 9.2/99.8 MB 770.0 kB/s eta 0:01:58\n",
      "   --- ------------------------------------ 9.2/99.8 MB 769.7 kB/s eta 0:01:58\n",
      "   --- ------------------------------------ 9.3/99.8 MB 773.3 kB/s eta 0:01:57\n",
      "   --- ------------------------------------ 9.3/99.8 MB 775.6 kB/s eta 0:01:57\n",
      "   --- ------------------------------------ 9.4/99.8 MB 781.0 kB/s eta 0:01:56\n",
      "   --- ------------------------------------ 9.5/99.8 MB 783.3 kB/s eta 0:01:56\n",
      "   --- ------------------------------------ 9.6/99.8 MB 791.0 kB/s eta 0:01:54\n",
      "   --- ------------------------------------ 9.8/99.8 MB 797.9 kB/s eta 0:01:53\n",
      "   --- ------------------------------------ 9.9/99.8 MB 802.3 kB/s eta 0:01:53\n",
      "   --- ------------------------------------ 9.9/99.8 MB 806.8 kB/s eta 0:01:52\n",
      "   ---- ----------------------------------- 10.0/99.8 MB 809.0 kB/s eta 0:01:51\n",
      "   ---- ----------------------------------- 10.1/99.8 MB 810.5 kB/s eta 0:01:51\n",
      "   ---- ----------------------------------- 10.1/99.8 MB 814.3 kB/s eta 0:01:51\n",
      "   ---- ----------------------------------- 10.2/99.8 MB 817.8 kB/s eta 0:01:50\n",
      "   ---- ----------------------------------- 10.3/99.8 MB 821.5 kB/s eta 0:01:49\n",
      "   ---- ----------------------------------- 10.4/99.8 MB 824.5 kB/s eta 0:01:49\n",
      "   ---- ----------------------------------- 10.4/99.8 MB 826.6 kB/s eta 0:01:49\n",
      "   ---- ----------------------------------- 10.5/99.8 MB 835.1 kB/s eta 0:01:47\n",
      "   ---- ----------------------------------- 10.6/99.8 MB 847.0 kB/s eta 0:01:46\n",
      "   ---- ----------------------------------- 10.7/99.8 MB 856.9 kB/s eta 0:01:44\n",
      "   ---- ----------------------------------- 10.8/99.8 MB 878.8 kB/s eta 0:01:42\n",
      "   ---- ----------------------------------- 10.9/99.8 MB 888.4 kB/s eta 0:01:41\n",
      "   ---- ----------------------------------- 10.9/99.8 MB 885.9 kB/s eta 0:01:41\n",
      "   ---- ----------------------------------- 11.0/99.8 MB 883.6 kB/s eta 0:01:41\n",
      "   ---- ----------------------------------- 11.0/99.8 MB 883.6 kB/s eta 0:01:41\n",
      "   ---- ----------------------------------- 11.1/99.8 MB 885.9 kB/s eta 0:01:41\n",
      "   ---- ----------------------------------- 11.1/99.8 MB 885.9 kB/s eta 0:01:41\n",
      "   ---- ----------------------------------- 11.1/99.8 MB 885.9 kB/s eta 0:01:41\n",
      "   ---- ----------------------------------- 11.1/99.8 MB 885.9 kB/s eta 0:01:41\n",
      "   ---- ----------------------------------- 11.3/99.8 MB 887.2 kB/s eta 0:01:40\n",
      "   ---- ----------------------------------- 11.3/99.8 MB 884.7 kB/s eta 0:01:40\n",
      "   ---- ----------------------------------- 11.4/99.8 MB 885.9 kB/s eta 0:01:40\n",
      "   ---- ----------------------------------- 11.4/99.8 MB 881.2 kB/s eta 0:01:41\n",
      "   ---- ----------------------------------- 11.4/99.8 MB 880.0 kB/s eta 0:01:41\n",
      "   ---- ----------------------------------- 11.5/99.8 MB 883.6 kB/s eta 0:01:40\n",
      "   ---- ----------------------------------- 11.5/99.8 MB 883.6 kB/s eta 0:01:40\n",
      "   ---- ----------------------------------- 11.6/99.8 MB 887.1 kB/s eta 0:01:40\n",
      "   ---- ----------------------------------- 11.6/99.8 MB 891.9 kB/s eta 0:01:39\n",
      "   ---- ----------------------------------- 11.7/99.8 MB 905.5 kB/s eta 0:01:38\n",
      "   ---- ----------------------------------- 11.8/99.8 MB 906.7 kB/s eta 0:01:38\n",
      "   ---- ----------------------------------- 11.9/99.8 MB 911.8 kB/s eta 0:01:37\n",
      "   ---- ----------------------------------- 12.0/99.8 MB 915.7 kB/s eta 0:01:36\n",
      "   ---- ----------------------------------- 12.0/99.8 MB 916.9 kB/s eta 0:01:36\n",
      "   ---- ----------------------------------- 12.1/99.8 MB 914.4 kB/s eta 0:01:36\n",
      "   ---- ----------------------------------- 12.1/99.8 MB 918.3 kB/s eta 0:01:36\n",
      "   ---- ----------------------------------- 12.2/99.8 MB 924.8 kB/s eta 0:01:35\n",
      "   ---- ----------------------------------- 12.2/99.8 MB 924.7 kB/s eta 0:01:35\n",
      "   ---- ----------------------------------- 12.3/99.8 MB 930.0 kB/s eta 0:01:35\n",
      "   ---- ----------------------------------- 12.4/99.8 MB 939.3 kB/s eta 0:01:33\n",
      "   ----- ---------------------------------- 12.5/99.8 MB 939.3 kB/s eta 0:01:33\n",
      "   ----- ---------------------------------- 12.6/99.8 MB 961.4 kB/s eta 0:01:31\n",
      "   ----- ---------------------------------- 12.7/99.8 MB 960.0 kB/s eta 0:01:31\n",
      "   ----- ---------------------------------- 12.7/99.8 MB 965.6 kB/s eta 0:01:31\n",
      "   ----- ---------------------------------- 12.8/99.8 MB 971.3 kB/s eta 0:01:30\n",
      "   ----- ---------------------------------- 12.9/99.8 MB 974.3 kB/s eta 0:01:30\n",
      "   ----- ---------------------------------- 13.0/99.8 MB 992.0 kB/s eta 0:01:28\n",
      "   ----- ---------------------------------- 13.1/99.8 MB 1.0 MB/s eta 0:01:26\n",
      "   ----- ---------------------------------- 13.2/99.8 MB 1.0 MB/s eta 0:01:25\n",
      "   ----- ---------------------------------- 13.3/99.8 MB 1.0 MB/s eta 0:01:24\n",
      "   ----- ---------------------------------- 13.3/99.8 MB 1.0 MB/s eta 0:01:23\n",
      "   ----- ---------------------------------- 13.4/99.8 MB 1.1 MB/s eta 0:01:22\n",
      "   ----- ---------------------------------- 13.5/99.8 MB 1.1 MB/s eta 0:01:21\n",
      "   ----- ---------------------------------- 13.7/99.8 MB 1.1 MB/s eta 0:01:20\n",
      "   ----- ---------------------------------- 13.7/99.8 MB 1.1 MB/s eta 0:01:20\n",
      "   ----- ---------------------------------- 13.9/99.8 MB 1.1 MB/s eta 0:01:20\n",
      "   ----- ---------------------------------- 14.0/99.8 MB 1.1 MB/s eta 0:01:19\n",
      "   ----- ---------------------------------- 14.1/99.8 MB 1.1 MB/s eta 0:01:18\n",
      "   ----- ---------------------------------- 14.2/99.8 MB 1.1 MB/s eta 0:01:18\n",
      "   ----- ---------------------------------- 14.3/99.8 MB 1.1 MB/s eta 0:01:18\n",
      "   ----- ---------------------------------- 14.4/99.8 MB 1.1 MB/s eta 0:01:17\n",
      "   ----- ---------------------------------- 14.4/99.8 MB 1.1 MB/s eta 0:01:17\n",
      "   ----- ---------------------------------- 14.5/99.8 MB 1.1 MB/s eta 0:01:17\n",
      "   ----- ---------------------------------- 14.6/99.8 MB 1.1 MB/s eta 0:01:17\n",
      "   ----- ---------------------------------- 14.6/99.8 MB 1.1 MB/s eta 0:01:17\n",
      "   ----- ---------------------------------- 14.7/99.8 MB 1.1 MB/s eta 0:01:16\n",
      "   ----- ---------------------------------- 14.7/99.8 MB 1.1 MB/s eta 0:01:15\n",
      "   ----- ---------------------------------- 14.8/99.8 MB 1.1 MB/s eta 0:01:14\n",
      "   ----- ---------------------------------- 14.8/99.8 MB 1.2 MB/s eta 0:01:14\n",
      "   ----- ---------------------------------- 14.9/99.8 MB 1.2 MB/s eta 0:01:14\n",
      "   ------ --------------------------------- 15.0/99.8 MB 1.2 MB/s eta 0:01:13\n",
      "   ------ --------------------------------- 15.0/99.8 MB 1.2 MB/s eta 0:01:13\n",
      "   ------ --------------------------------- 15.1/99.8 MB 1.2 MB/s eta 0:01:13\n",
      "   ------ --------------------------------- 15.2/99.8 MB 1.2 MB/s eta 0:01:13\n",
      "   ------ --------------------------------- 15.3/99.8 MB 1.2 MB/s eta 0:01:13\n",
      "   ------ --------------------------------- 15.4/99.8 MB 1.2 MB/s eta 0:01:12\n",
      "   ------ --------------------------------- 15.5/99.8 MB 1.2 MB/s eta 0:01:12\n",
      "   ------ --------------------------------- 15.5/99.8 MB 1.2 MB/s eta 0:01:11\n",
      "   ------ --------------------------------- 15.7/99.8 MB 1.2 MB/s eta 0:01:10\n",
      "   ------ --------------------------------- 15.8/99.8 MB 1.2 MB/s eta 0:01:10\n",
      "   ------ --------------------------------- 15.8/99.8 MB 1.2 MB/s eta 0:01:10\n",
      "   ------ --------------------------------- 15.9/99.8 MB 1.2 MB/s eta 0:01:10\n",
      "   ------ --------------------------------- 16.0/99.8 MB 1.2 MB/s eta 0:01:10\n",
      "   ------ --------------------------------- 16.0/99.8 MB 1.2 MB/s eta 0:01:10\n",
      "   ------ --------------------------------- 16.1/99.8 MB 1.2 MB/s eta 0:01:10\n",
      "   ------ --------------------------------- 16.1/99.8 MB 1.2 MB/s eta 0:01:10\n",
      "   ------ --------------------------------- 16.2/99.8 MB 1.2 MB/s eta 0:01:09\n",
      "   ------ --------------------------------- 16.2/99.8 MB 1.2 MB/s eta 0:01:09\n",
      "   ------ --------------------------------- 16.3/99.8 MB 1.2 MB/s eta 0:01:09\n",
      "   ------ --------------------------------- 16.3/99.8 MB 1.2 MB/s eta 0:01:09\n",
      "   ------ --------------------------------- 16.3/99.8 MB 1.2 MB/s eta 0:01:09\n",
      "   ------ --------------------------------- 16.4/99.8 MB 1.2 MB/s eta 0:01:09\n",
      "   ------ --------------------------------- 16.5/99.8 MB 1.2 MB/s eta 0:01:09\n",
      "   ------ --------------------------------- 16.5/99.8 MB 1.2 MB/s eta 0:01:09\n",
      "   ------ --------------------------------- 16.5/99.8 MB 1.2 MB/s eta 0:01:09\n",
      "   ------ --------------------------------- 16.6/99.8 MB 1.2 MB/s eta 0:01:09\n",
      "   ------ --------------------------------- 16.6/99.8 MB 1.2 MB/s eta 0:01:09\n",
      "   ------ --------------------------------- 16.7/99.8 MB 1.2 MB/s eta 0:01:08\n",
      "   ------ --------------------------------- 16.8/99.8 MB 1.2 MB/s eta 0:01:07\n",
      "   ------ --------------------------------- 16.9/99.8 MB 1.2 MB/s eta 0:01:07\n",
      "   ------ --------------------------------- 16.9/99.8 MB 1.2 MB/s eta 0:01:07\n",
      "   ------ --------------------------------- 17.0/99.8 MB 1.3 MB/s eta 0:01:06\n",
      "   ------ --------------------------------- 17.1/99.8 MB 1.3 MB/s eta 0:01:06\n",
      "   ------ --------------------------------- 17.2/99.8 MB 1.3 MB/s eta 0:01:05\n",
      "   ------ --------------------------------- 17.3/99.8 MB 1.3 MB/s eta 0:01:05\n",
      "   ------ --------------------------------- 17.3/99.8 MB 1.3 MB/s eta 0:01:04\n",
      "   ------ --------------------------------- 17.4/99.8 MB 1.3 MB/s eta 0:01:04\n",
      "   ------ --------------------------------- 17.4/99.8 MB 1.3 MB/s eta 0:01:03\n",
      "   ------- -------------------------------- 17.5/99.8 MB 1.3 MB/s eta 0:01:04\n",
      "   ------- -------------------------------- 17.5/99.8 MB 1.3 MB/s eta 0:01:03\n",
      "   ------- -------------------------------- 17.6/99.8 MB 1.3 MB/s eta 0:01:02\n",
      "   ------- -------------------------------- 17.6/99.8 MB 1.3 MB/s eta 0:01:02\n",
      "   ------- -------------------------------- 17.6/99.8 MB 1.3 MB/s eta 0:01:02\n",
      "   ------- -------------------------------- 17.6/99.8 MB 1.3 MB/s eta 0:01:02\n",
      "   ------- -------------------------------- 17.7/99.8 MB 1.3 MB/s eta 0:01:01\n",
      "   ------- -------------------------------- 17.7/99.8 MB 1.3 MB/s eta 0:01:02\n",
      "   ------- -------------------------------- 17.8/99.8 MB 1.3 MB/s eta 0:01:01\n",
      "   ------- -------------------------------- 17.8/99.8 MB 1.3 MB/s eta 0:01:02\n",
      "   ------- -------------------------------- 17.8/99.8 MB 1.4 MB/s eta 0:01:00\n",
      "   ------- -------------------------------- 17.8/99.8 MB 1.4 MB/s eta 0:01:00\n",
      "   ------- -------------------------------- 17.9/99.8 MB 1.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 18.0/99.8 MB 1.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 18.0/99.8 MB 1.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 18.0/99.8 MB 1.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 18.1/99.8 MB 1.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 18.1/99.8 MB 1.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 18.2/99.8 MB 1.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 18.2/99.8 MB 1.4 MB/s eta 0:00:58\n",
      "   ------- -------------------------------- 18.3/99.8 MB 1.4 MB/s eta 0:00:58\n",
      "   ------- -------------------------------- 18.4/99.8 MB 1.4 MB/s eta 0:00:58\n",
      "   ------- -------------------------------- 18.4/99.8 MB 1.4 MB/s eta 0:00:57\n",
      "   ------- -------------------------------- 18.5/99.8 MB 1.4 MB/s eta 0:00:57\n",
      "   ------- -------------------------------- 18.5/99.8 MB 1.5 MB/s eta 0:00:56\n",
      "   ------- -------------------------------- 18.5/99.8 MB 1.5 MB/s eta 0:00:56\n",
      "   ------- -------------------------------- 18.6/99.8 MB 1.5 MB/s eta 0:00:56\n",
      "   ------- -------------------------------- 18.6/99.8 MB 1.4 MB/s eta 0:00:57\n",
      "   ------- -------------------------------- 18.6/99.8 MB 1.4 MB/s eta 0:00:57\n",
      "   ------- -------------------------------- 18.7/99.8 MB 1.4 MB/s eta 0:00:57\n",
      "   ------- -------------------------------- 18.7/99.8 MB 1.4 MB/s eta 0:00:57\n",
      "   ------- -------------------------------- 18.7/99.8 MB 1.4 MB/s eta 0:00:57\n",
      "   ------- -------------------------------- 18.8/99.8 MB 1.4 MB/s eta 0:00:57\n",
      "   ------- -------------------------------- 18.8/99.8 MB 1.4 MB/s eta 0:00:57\n",
      "   ------- -------------------------------- 18.9/99.8 MB 1.4 MB/s eta 0:00:57\n",
      "   ------- -------------------------------- 18.9/99.8 MB 1.4 MB/s eta 0:00:57\n",
      "   ------- -------------------------------- 19.0/99.8 MB 1.4 MB/s eta 0:00:57\n",
      "   ------- -------------------------------- 19.0/99.8 MB 1.4 MB/s eta 0:00:58\n",
      "   ------- -------------------------------- 19.1/99.8 MB 1.4 MB/s eta 0:00:58\n",
      "   ------- -------------------------------- 19.1/99.8 MB 1.4 MB/s eta 0:00:57\n",
      "   ------- -------------------------------- 19.1/99.8 MB 1.4 MB/s eta 0:00:58\n",
      "   ------- -------------------------------- 19.1/99.8 MB 1.4 MB/s eta 0:00:58\n",
      "   ------- -------------------------------- 19.2/99.8 MB 1.4 MB/s eta 0:00:58\n",
      "   ------- -------------------------------- 19.2/99.8 MB 1.4 MB/s eta 0:00:58\n",
      "   ------- -------------------------------- 19.3/99.8 MB 1.4 MB/s eta 0:00:58\n",
      "   ------- -------------------------------- 19.3/99.8 MB 1.4 MB/s eta 0:00:58\n",
      "   ------- -------------------------------- 19.3/99.8 MB 1.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 19.4/99.8 MB 1.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 19.4/99.8 MB 1.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 19.4/99.8 MB 1.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 19.5/99.8 MB 1.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 19.5/99.8 MB 1.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 19.5/99.8 MB 1.4 MB/s eta 0:01:00\n",
      "   ------- -------------------------------- 19.6/99.8 MB 1.4 MB/s eta 0:01:00\n",
      "   ------- -------------------------------- 19.6/99.8 MB 1.3 MB/s eta 0:01:00\n",
      "   ------- -------------------------------- 19.6/99.8 MB 1.3 MB/s eta 0:01:00\n",
      "   ------- -------------------------------- 19.7/99.8 MB 1.3 MB/s eta 0:01:01\n",
      "   ------- -------------------------------- 19.7/99.8 MB 1.3 MB/s eta 0:01:01\n",
      "   ------- -------------------------------- 19.7/99.8 MB 1.3 MB/s eta 0:01:01\n",
      "   ------- -------------------------------- 19.8/99.8 MB 1.3 MB/s eta 0:01:01\n",
      "   ------- -------------------------------- 19.8/99.8 MB 1.3 MB/s eta 0:01:01\n",
      "   ------- -------------------------------- 19.9/99.8 MB 1.3 MB/s eta 0:01:01\n",
      "   ------- -------------------------------- 19.9/99.8 MB 1.3 MB/s eta 0:01:01\n",
      "   -------- ------------------------------- 20.0/99.8 MB 1.3 MB/s eta 0:01:02\n",
      "   -------- ------------------------------- 20.0/99.8 MB 1.3 MB/s eta 0:01:02\n",
      "   -------- ------------------------------- 20.1/99.8 MB 1.3 MB/s eta 0:01:02\n",
      "   -------- ------------------------------- 20.1/99.8 MB 1.3 MB/s eta 0:01:02\n",
      "   -------- ------------------------------- 20.1/99.8 MB 1.3 MB/s eta 0:01:02\n",
      "   -------- ------------------------------- 20.2/99.8 MB 1.3 MB/s eta 0:01:03\n",
      "   -------- ------------------------------- 20.2/99.8 MB 1.3 MB/s eta 0:01:03\n",
      "   -------- ------------------------------- 20.2/99.8 MB 1.3 MB/s eta 0:01:03\n",
      "   -------- ------------------------------- 20.3/99.8 MB 1.3 MB/s eta 0:01:03\n",
      "   -------- ------------------------------- 20.3/99.8 MB 1.3 MB/s eta 0:01:03\n",
      "   -------- ------------------------------- 20.3/99.8 MB 1.3 MB/s eta 0:01:04\n",
      "   -------- ------------------------------- 20.3/99.8 MB 1.3 MB/s eta 0:01:04\n",
      "   -------- ------------------------------- 20.3/99.8 MB 1.3 MB/s eta 0:01:04\n",
      "   -------- ------------------------------- 20.3/99.8 MB 1.2 MB/s eta 0:01:04\n",
      "   -------- ------------------------------- 20.4/99.8 MB 1.2 MB/s eta 0:01:05\n",
      "   -------- ------------------------------- 20.4/99.8 MB 1.2 MB/s eta 0:01:05\n",
      "   -------- ------------------------------- 20.4/99.8 MB 1.2 MB/s eta 0:01:05\n",
      "   -------- ------------------------------- 20.4/99.8 MB 1.2 MB/s eta 0:01:06\n",
      "   -------- ------------------------------- 20.4/99.8 MB 1.2 MB/s eta 0:01:06\n",
      "   -------- ------------------------------- 20.5/99.8 MB 1.2 MB/s eta 0:01:06\n",
      "   -------- ------------------------------- 20.5/99.8 MB 1.2 MB/s eta 0:01:06\n",
      "   -------- ------------------------------- 20.5/99.8 MB 1.2 MB/s eta 0:01:06\n",
      "   -------- ------------------------------- 20.6/99.8 MB 1.2 MB/s eta 0:01:06\n",
      "   -------- ------------------------------- 20.6/99.8 MB 1.2 MB/s eta 0:01:07\n",
      "   -------- ------------------------------- 20.6/99.8 MB 1.2 MB/s eta 0:01:07\n",
      "   -------- ------------------------------- 20.7/99.8 MB 1.2 MB/s eta 0:01:07\n",
      "   -------- ------------------------------- 20.7/99.8 MB 1.2 MB/s eta 0:01:07\n",
      "   -------- ------------------------------- 20.8/99.8 MB 1.2 MB/s eta 0:01:07\n",
      "   -------- ------------------------------- 20.8/99.8 MB 1.2 MB/s eta 0:01:07\n",
      "   -------- ------------------------------- 20.8/99.8 MB 1.2 MB/s eta 0:01:08\n",
      "   -------- ------------------------------- 20.9/99.8 MB 1.2 MB/s eta 0:01:08\n",
      "   -------- ------------------------------- 20.9/99.8 MB 1.2 MB/s eta 0:01:08\n",
      "   -------- ------------------------------- 21.0/99.8 MB 1.2 MB/s eta 0:01:08\n",
      "   -------- ------------------------------- 21.1/99.8 MB 1.2 MB/s eta 0:01:08\n",
      "   -------- ------------------------------- 21.1/99.8 MB 1.2 MB/s eta 0:01:08\n",
      "   -------- ------------------------------- 21.1/99.8 MB 1.2 MB/s eta 0:01:08\n",
      "   -------- ------------------------------- 21.1/99.8 MB 1.2 MB/s eta 0:01:08\n",
      "   -------- ------------------------------- 21.2/99.8 MB 1.2 MB/s eta 0:01:09\n",
      "   -------- ------------------------------- 21.2/99.8 MB 1.2 MB/s eta 0:01:09\n",
      "   -------- ------------------------------- 21.2/99.8 MB 1.1 MB/s eta 0:01:09\n",
      "   -------- ------------------------------- 21.2/99.8 MB 1.1 MB/s eta 0:01:09\n",
      "   -------- ------------------------------- 21.2/99.8 MB 1.1 MB/s eta 0:01:10\n",
      "   -------- ------------------------------- 21.2/99.8 MB 1.1 MB/s eta 0:01:10\n",
      "   -------- ------------------------------- 21.2/99.8 MB 1.1 MB/s eta 0:01:10\n",
      "   -------- ------------------------------- 21.3/99.8 MB 1.1 MB/s eta 0:01:10\n",
      "   -------- ------------------------------- 21.3/99.8 MB 1.1 MB/s eta 0:01:10\n",
      "   -------- ------------------------------- 21.3/99.8 MB 1.1 MB/s eta 0:01:10\n",
      "   -------- ------------------------------- 21.3/99.8 MB 1.1 MB/s eta 0:01:10\n",
      "   -------- ------------------------------- 21.3/99.8 MB 1.1 MB/s eta 0:01:11\n",
      "   -------- ------------------------------- 21.3/99.8 MB 1.1 MB/s eta 0:01:11\n",
      "   -------- ------------------------------- 21.3/99.8 MB 1.1 MB/s eta 0:01:12\n",
      "   -------- ------------------------------- 21.4/99.8 MB 1.1 MB/s eta 0:01:12\n",
      "   -------- ------------------------------- 21.4/99.8 MB 1.1 MB/s eta 0:01:12\n",
      "   -------- ------------------------------- 21.4/99.8 MB 1.1 MB/s eta 0:01:12\n",
      "   -------- ------------------------------- 21.4/99.8 MB 1.1 MB/s eta 0:01:12\n",
      "   -------- ------------------------------- 21.5/99.8 MB 1.1 MB/s eta 0:01:13\n",
      "   -------- ------------------------------- 21.5/99.8 MB 1.1 MB/s eta 0:01:13\n",
      "   -------- ------------------------------- 21.5/99.8 MB 1.1 MB/s eta 0:01:13\n",
      "   -------- ------------------------------- 21.6/99.8 MB 1.1 MB/s eta 0:01:13\n",
      "   -------- ------------------------------- 21.6/99.8 MB 1.1 MB/s eta 0:01:13\n",
      "   -------- ------------------------------- 21.6/99.8 MB 1.1 MB/s eta 0:01:13\n",
      "   -------- ------------------------------- 21.6/99.8 MB 1.1 MB/s eta 0:01:13\n",
      "   -------- ------------------------------- 21.6/99.8 MB 1.1 MB/s eta 0:01:13\n",
      "   -------- ------------------------------- 21.6/99.8 MB 1.1 MB/s eta 0:01:13\n",
      "   -------- ------------------------------- 21.6/99.8 MB 1.1 MB/s eta 0:01:14\n",
      "   -------- ------------------------------- 21.7/99.8 MB 1.1 MB/s eta 0:01:14\n",
      "   -------- ------------------------------- 21.7/99.8 MB 1.1 MB/s eta 0:01:14\n",
      "   -------- ------------------------------- 21.7/99.8 MB 1.1 MB/s eta 0:01:14\n",
      "   -------- ------------------------------- 21.7/99.8 MB 1.1 MB/s eta 0:01:15\n",
      "   -------- ------------------------------- 21.8/99.8 MB 1.1 MB/s eta 0:01:15\n",
      "   -------- ------------------------------- 21.8/99.8 MB 1.0 MB/s eta 0:01:15\n",
      "   -------- ------------------------------- 21.8/99.8 MB 1.0 MB/s eta 0:01:15\n",
      "   -------- ------------------------------- 21.9/99.8 MB 1.0 MB/s eta 0:01:15\n",
      "   -------- ------------------------------- 21.9/99.8 MB 1.0 MB/s eta 0:01:16\n",
      "   -------- ------------------------------- 21.9/99.8 MB 1.0 MB/s eta 0:01:16\n",
      "   -------- ------------------------------- 22.0/99.8 MB 1.0 MB/s eta 0:01:16\n",
      "   -------- ------------------------------- 22.0/99.8 MB 1.0 MB/s eta 0:01:16\n",
      "   -------- ------------------------------- 22.0/99.8 MB 1.0 MB/s eta 0:01:16\n",
      "   -------- ------------------------------- 22.0/99.8 MB 1.0 MB/s eta 0:01:16\n",
      "   -------- ------------------------------- 22.0/99.8 MB 1.0 MB/s eta 0:01:16\n",
      "   -------- ------------------------------- 22.0/99.8 MB 1.0 MB/s eta 0:01:17\n",
      "   -------- ------------------------------- 22.1/99.8 MB 1.0 MB/s eta 0:01:17\n",
      "   -------- ------------------------------- 22.1/99.8 MB 1.0 MB/s eta 0:01:18\n",
      "   -------- ------------------------------- 22.1/99.8 MB 1.0 MB/s eta 0:01:18\n",
      "   -------- ------------------------------- 22.1/99.8 MB 998.0 kB/s eta 0:01:18\n",
      "   -------- ------------------------------- 22.2/99.8 MB 996.5 kB/s eta 0:01:18\n",
      "   -------- ------------------------------- 22.2/99.8 MB 996.5 kB/s eta 0:01:18\n",
      "   -------- ------------------------------- 22.2/99.8 MB 993.6 kB/s eta 0:01:19\n",
      "   -------- ------------------------------- 22.2/99.8 MB 993.5 kB/s eta 0:01:19\n",
      "   -------- ------------------------------- 22.3/99.8 MB 987.5 kB/s eta 0:01:19\n",
      "   -------- ------------------------------- 22.3/99.8 MB 987.5 kB/s eta 0:01:19\n",
      "   -------- ------------------------------- 22.3/99.8 MB 987.5 kB/s eta 0:01:19\n",
      "   -------- ------------------------------- 22.3/99.8 MB 987.5 kB/s eta 0:01:19\n",
      "   -------- ------------------------------- 22.3/99.8 MB 971.4 kB/s eta 0:01:20\n",
      "   -------- ------------------------------- 22.4/99.8 MB 971.3 kB/s eta 0:01:20\n",
      "   -------- ------------------------------- 22.4/99.8 MB 971.3 kB/s eta 0:01:20\n",
      "   -------- ------------------------------- 22.4/99.8 MB 971.3 kB/s eta 0:01:20\n",
      "   -------- ------------------------------- 22.4/99.8 MB 961.4 kB/s eta 0:01:21\n",
      "   -------- ------------------------------- 22.4/99.8 MB 954.4 kB/s eta 0:01:22\n",
      "   -------- ------------------------------- 22.4/99.8 MB 954.4 kB/s eta 0:01:22\n",
      "   --------- ------------------------------ 22.5/99.8 MB 953.0 kB/s eta 0:01:22\n",
      "   --------- ------------------------------ 22.5/99.8 MB 951.6 kB/s eta 0:01:22\n",
      "   --------- ------------------------------ 22.6/99.8 MB 950.3 kB/s eta 0:01:22\n",
      "   --------- ------------------------------ 22.6/99.8 MB 947.5 kB/s eta 0:01:22\n",
      "   --------- ------------------------------ 22.7/99.8 MB 944.8 kB/s eta 0:01:22\n",
      "   --------- ------------------------------ 22.7/99.8 MB 943.4 kB/s eta 0:01:22\n",
      "   --------- ------------------------------ 22.7/99.8 MB 942.0 kB/s eta 0:01:22\n",
      "   --------- ------------------------------ 22.8/99.8 MB 940.7 kB/s eta 0:01:22\n",
      "   --------- ------------------------------ 22.8/99.8 MB 939.4 kB/s eta 0:01:22\n",
      "   --------- ------------------------------ 22.8/99.8 MB 939.4 kB/s eta 0:01:22\n",
      "   --------- ------------------------------ 22.8/99.8 MB 930.0 kB/s eta 0:01:23\n",
      "   --------- ------------------------------ 22.9/99.8 MB 927.4 kB/s eta 0:01:23\n",
      "   --------- ------------------------------ 23.0/99.8 MB 927.4 kB/s eta 0:01:23\n",
      "   --------- ------------------------------ 23.0/99.8 MB 928.7 kB/s eta 0:01:23\n",
      "   --------- ------------------------------ 23.0/99.8 MB 924.8 kB/s eta 0:01:23\n",
      "   --------- ------------------------------ 23.1/99.8 MB 922.1 kB/s eta 0:01:24\n",
      "   --------- ------------------------------ 23.2/99.8 MB 920.8 kB/s eta 0:01:24\n",
      "   --------- ------------------------------ 23.2/99.8 MB 919.5 kB/s eta 0:01:24\n",
      "   --------- ------------------------------ 23.3/99.8 MB 918.2 kB/s eta 0:01:24\n",
      "   --------- ------------------------------ 23.3/99.8 MB 917.0 kB/s eta 0:01:24\n",
      "   --------- ------------------------------ 23.4/99.8 MB 915.7 kB/s eta 0:01:24\n",
      "   --------- ------------------------------ 23.4/99.8 MB 914.4 kB/s eta 0:01:24\n",
      "   --------- ------------------------------ 23.5/99.8 MB 914.4 kB/s eta 0:01:24\n",
      "   --------- ------------------------------ 23.6/99.8 MB 914.4 kB/s eta 0:01:24\n",
      "   --------- ------------------------------ 23.6/99.8 MB 913.1 kB/s eta 0:01:24\n",
      "   --------- ------------------------------ 23.6/99.8 MB 913.1 kB/s eta 0:01:24\n",
      "   --------- ------------------------------ 23.7/99.8 MB 905.5 kB/s eta 0:01:25\n",
      "   --------- ------------------------------ 23.7/99.8 MB 903.0 kB/s eta 0:01:25\n",
      "   --------- ------------------------------ 23.8/99.8 MB 901.9 kB/s eta 0:01:25\n",
      "   --------- ------------------------------ 23.9/99.8 MB 900.6 kB/s eta 0:01:25\n",
      "   --------- ------------------------------ 23.9/99.8 MB 900.5 kB/s eta 0:01:25\n",
      "   --------- ------------------------------ 24.0/99.8 MB 898.1 kB/s eta 0:01:25\n",
      "   --------- ------------------------------ 24.1/99.8 MB 895.6 kB/s eta 0:01:25\n",
      "   --------- ------------------------------ 24.2/99.8 MB 894.4 kB/s eta 0:01:25\n",
      "   --------- ------------------------------ 24.2/99.8 MB 893.2 kB/s eta 0:01:25\n",
      "   --------- ------------------------------ 24.3/99.8 MB 892.0 kB/s eta 0:01:25\n",
      "   --------- ------------------------------ 24.4/99.8 MB 889.5 kB/s eta 0:01:25\n",
      "   --------- ------------------------------ 24.4/99.8 MB 888.4 kB/s eta 0:01:25\n",
      "   --------- ------------------------------ 24.5/99.8 MB 888.4 kB/s eta 0:01:25\n",
      "   --------- ------------------------------ 24.5/99.8 MB 887.1 kB/s eta 0:01:25\n",
      "   --------- ------------------------------ 24.5/99.8 MB 887.1 kB/s eta 0:01:25\n",
      "   --------- ------------------------------ 24.6/99.8 MB 883.6 kB/s eta 0:01:26\n",
      "   --------- ------------------------------ 24.7/99.8 MB 881.1 kB/s eta 0:01:26\n",
      "   --------- ------------------------------ 24.7/99.8 MB 878.8 kB/s eta 0:01:26\n",
      "   --------- ------------------------------ 24.8/99.8 MB 877.6 kB/s eta 0:01:26\n",
      "   --------- ------------------------------ 24.8/99.8 MB 878.8 kB/s eta 0:01:26\n",
      "   --------- ------------------------------ 24.9/99.8 MB 880.0 kB/s eta 0:01:26\n",
      "   ---------- ----------------------------- 25.0/99.8 MB 881.2 kB/s eta 0:01:25\n",
      "   ---------- ----------------------------- 25.0/99.8 MB 883.6 kB/s eta 0:01:25\n",
      "   ---------- ----------------------------- 25.1/99.8 MB 885.9 kB/s eta 0:01:25\n",
      "   ---------- ----------------------------- 25.3/99.8 MB 888.4 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 25.4/99.8 MB 889.5 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 25.5/99.8 MB 889.5 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 25.5/99.8 MB 889.5 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 25.6/99.8 MB 887.1 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 25.7/99.8 MB 888.3 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 25.8/99.8 MB 889.5 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 25.8/99.8 MB 883.6 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 25.8/99.8 MB 883.5 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 25.9/99.8 MB 881.2 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 26.0/99.8 MB 880.0 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 26.0/99.8 MB 881.2 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 26.1/99.8 MB 880.0 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 26.2/99.8 MB 880.0 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 26.3/99.8 MB 882.3 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 26.3/99.8 MB 882.3 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 26.4/99.8 MB 883.5 kB/s eta 0:01:24\n",
      "   ---------- ----------------------------- 26.4/99.8 MB 883.6 kB/s eta 0:01:23\n",
      "   ---------- ----------------------------- 26.5/99.8 MB 883.6 kB/s eta 0:01:23\n",
      "   ---------- ----------------------------- 26.5/99.8 MB 884.7 kB/s eta 0:01:23\n",
      "   ---------- ----------------------------- 26.6/99.8 MB 884.8 kB/s eta 0:01:23\n",
      "   ---------- ----------------------------- 26.6/99.8 MB 884.8 kB/s eta 0:01:23\n",
      "   ---------- ----------------------------- 26.7/99.8 MB 889.5 kB/s eta 0:01:23\n",
      "   ---------- ----------------------------- 26.8/99.8 MB 892.0 kB/s eta 0:01:22\n",
      "   ---------- ----------------------------- 26.9/99.8 MB 893.2 kB/s eta 0:01:22\n",
      "   ---------- ----------------------------- 27.0/99.8 MB 890.7 kB/s eta 0:01:22\n",
      "   ---------- ----------------------------- 27.0/99.8 MB 891.9 kB/s eta 0:01:22\n",
      "   ---------- ----------------------------- 27.1/99.8 MB 891.9 kB/s eta 0:01:22\n",
      "   ---------- ----------------------------- 27.1/99.8 MB 888.4 kB/s eta 0:01:22\n",
      "   ---------- ----------------------------- 27.2/99.8 MB 887.2 kB/s eta 0:01:22\n",
      "   ---------- ----------------------------- 27.2/99.8 MB 887.2 kB/s eta 0:01:22\n",
      "   ---------- ----------------------------- 27.3/99.8 MB 885.9 kB/s eta 0:01:22\n",
      "   ---------- ----------------------------- 27.3/99.8 MB 887.2 kB/s eta 0:01:22\n",
      "   ---------- ----------------------------- 27.4/99.8 MB 883.6 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 27.5/99.8 MB 883.6 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 27.5/99.8 MB 883.5 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 27.6/99.8 MB 882.3 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 27.7/99.8 MB 882.3 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 27.8/99.8 MB 889.5 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 27.8/99.8 MB 895.6 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 27.9/99.8 MB 893.2 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 27.9/99.8 MB 893.2 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 27.9/99.8 MB 889.5 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 27.9/99.8 MB 889.5 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 28.0/99.8 MB 893.2 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 28.0/99.8 MB 893.2 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 28.0/99.8 MB 889.5 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 28.0/99.8 MB 888.3 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 28.0/99.8 MB 888.3 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 28.1/99.8 MB 889.5 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 28.2/99.8 MB 888.3 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 28.2/99.8 MB 888.3 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 28.2/99.8 MB 883.6 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 28.2/99.8 MB 882.4 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 28.3/99.8 MB 887.2 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 28.4/99.8 MB 885.9 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 28.4/99.8 MB 884.7 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 28.4/99.8 MB 884.7 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 28.5/99.8 MB 881.2 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 28.5/99.8 MB 880.0 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 28.5/99.8 MB 874.1 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 28.5/99.8 MB 877.6 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 28.6/99.8 MB 872.9 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 28.6/99.8 MB 870.6 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 28.6/99.8 MB 869.5 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 28.7/99.8 MB 870.6 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 28.7/99.8 MB 871.8 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 28.8/99.8 MB 869.4 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 28.8/99.8 MB 871.7 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 28.8/99.8 MB 871.8 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 28.9/99.8 MB 871.7 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 29.0/99.8 MB 871.8 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 29.0/99.8 MB 874.1 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 29.0/99.8 MB 874.1 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 29.1/99.8 MB 872.9 kB/s eta 0:01:21\n",
      "   ----------- ---------------------------- 29.1/99.8 MB 871.8 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 29.1/99.8 MB 870.6 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 29.1/99.8 MB 870.6 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 29.1/99.8 MB 870.6 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 29.1/99.8 MB 870.6 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 29.1/99.8 MB 870.6 kB/s eta 0:01:22\n",
      "   ----------- ---------------------------- 29.2/99.8 MB 855.8 kB/s eta 0:01:23\n",
      "   ----------- ---------------------------- 29.2/99.8 MB 855.8 kB/s eta 0:01:23\n",
      "   ----------- ---------------------------- 29.2/99.8 MB 851.4 kB/s eta 0:01:23\n",
      "   ----------- ---------------------------- 29.2/99.8 MB 851.4 kB/s eta 0:01:23\n",
      "   ----------- ---------------------------- 29.2/99.8 MB 849.2 kB/s eta 0:01:24\n",
      "   ----------- ---------------------------- 29.3/99.8 MB 848.0 kB/s eta 0:01:24\n",
      "   ----------- ---------------------------- 29.3/99.8 MB 844.7 kB/s eta 0:01:24\n",
      "   ----------- ---------------------------- 29.3/99.8 MB 844.8 kB/s eta 0:01:24\n",
      "   ----------- ---------------------------- 29.3/99.8 MB 844.8 kB/s eta 0:01:24\n",
      "   ----------- ---------------------------- 29.4/99.8 MB 842.6 kB/s eta 0:01:24\n",
      "   ----------- ---------------------------- 29.4/99.8 MB 842.6 kB/s eta 0:01:24\n",
      "   ----------- ---------------------------- 29.4/99.8 MB 841.5 kB/s eta 0:01:24\n",
      "   ----------- ---------------------------- 29.4/99.8 MB 841.5 kB/s eta 0:01:24\n",
      "   ----------- ---------------------------- 29.5/99.8 MB 836.2 kB/s eta 0:01:25\n",
      "   ----------- ---------------------------- 29.5/99.8 MB 835.1 kB/s eta 0:01:25\n",
      "   ----------- ---------------------------- 29.5/99.8 MB 832.9 kB/s eta 0:01:25\n",
      "   ----------- ---------------------------- 29.5/99.8 MB 832.9 kB/s eta 0:01:25\n",
      "   ----------- ---------------------------- 29.6/99.8 MB 834.0 kB/s eta 0:01:25\n",
      "   ----------- ---------------------------- 29.6/99.8 MB 834.0 kB/s eta 0:01:25\n",
      "   ----------- ---------------------------- 29.6/99.8 MB 830.9 kB/s eta 0:01:25\n",
      "   ----------- ---------------------------- 29.6/99.8 MB 830.9 kB/s eta 0:01:25\n",
      "   ----------- ---------------------------- 29.6/99.8 MB 825.6 kB/s eta 0:01:25\n",
      "   ----------- ---------------------------- 29.6/99.8 MB 824.6 kB/s eta 0:01:26\n",
      "   ----------- ---------------------------- 29.7/99.8 MB 827.7 kB/s eta 0:01:25\n",
      "   ----------- ---------------------------- 29.7/99.8 MB 823.5 kB/s eta 0:01:26\n",
      "   ----------- ---------------------------- 29.7/99.8 MB 826.6 kB/s eta 0:01:25\n",
      "   ----------- ---------------------------- 29.8/99.8 MB 826.6 kB/s eta 0:01:25\n",
      "   ----------- ---------------------------- 29.8/99.8 MB 825.6 kB/s eta 0:01:25\n",
      "   ----------- ---------------------------- 29.9/99.8 MB 830.9 kB/s eta 0:01:25\n",
      "   ----------- ---------------------------- 29.9/99.8 MB 833.0 kB/s eta 0:01:24\n",
      "   ----------- ---------------------------- 29.9/99.8 MB 833.0 kB/s eta 0:01:24\n",
      "   ----------- ---------------------------- 29.9/99.8 MB 833.0 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 29.9/99.8 MB 823.5 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 30.0/99.8 MB 823.5 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 30.0/99.8 MB 820.4 kB/s eta 0:01:26\n",
      "   ------------ --------------------------- 30.1/99.8 MB 823.5 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 30.1/99.8 MB 821.5 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 30.2/99.8 MB 823.5 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 30.2/99.8 MB 822.5 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 30.2/99.8 MB 822.5 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 30.3/99.8 MB 817.3 kB/s eta 0:01:26\n",
      "   ------------ --------------------------- 30.3/99.8 MB 817.3 kB/s eta 0:01:26\n",
      "   ------------ --------------------------- 30.3/99.8 MB 817.4 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 30.3/99.8 MB 813.2 kB/s eta 0:01:26\n",
      "   ------------ --------------------------- 30.3/99.8 MB 814.3 kB/s eta 0:01:26\n",
      "   ------------ --------------------------- 30.3/99.8 MB 814.3 kB/s eta 0:01:26\n",
      "   ------------ --------------------------- 30.4/99.8 MB 810.3 kB/s eta 0:01:26\n",
      "   ------------ --------------------------- 30.4/99.8 MB 810.3 kB/s eta 0:01:26\n",
      "   ------------ --------------------------- 30.4/99.8 MB 808.3 kB/s eta 0:01:26\n",
      "   ------------ --------------------------- 30.4/99.8 MB 807.3 kB/s eta 0:01:26\n",
      "   ------------ --------------------------- 30.4/99.8 MB 807.3 kB/s eta 0:01:26\n",
      "   ------------ --------------------------- 30.4/99.8 MB 803.3 kB/s eta 0:01:27\n",
      "   ------------ --------------------------- 30.5/99.8 MB 802.3 kB/s eta 0:01:27\n",
      "   ------------ --------------------------- 30.5/99.8 MB 810.3 kB/s eta 0:01:26\n",
      "   ------------ --------------------------- 30.6/99.8 MB 815.3 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 30.6/99.8 MB 817.3 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 30.6/99.8 MB 822.5 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 30.8/99.8 MB 827.7 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 30.8/99.8 MB 825.6 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 30.8/99.8 MB 824.5 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 30.8/99.8 MB 822.5 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 30.8/99.8 MB 822.5 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 30.9/99.8 MB 822.5 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 30.9/99.8 MB 822.5 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 30.9/99.8 MB 823.5 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 31.0/99.8 MB 822.5 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 31.0/99.8 MB 822.5 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 31.0/99.8 MB 822.5 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 31.0/99.8 MB 822.5 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 31.0/99.8 MB 810.3 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 31.0/99.8 MB 810.3 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 31.0/99.8 MB 810.3 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 31.0/99.8 MB 802.3 kB/s eta 0:01:26\n",
      "   ------------ --------------------------- 31.0/99.8 MB 803.3 kB/s eta 0:01:26\n",
      "   ------------ --------------------------- 31.0/99.8 MB 803.3 kB/s eta 0:01:26\n",
      "   ------------ --------------------------- 31.0/99.8 MB 803.3 kB/s eta 0:01:26\n",
      "   ------------ --------------------------- 31.0/99.8 MB 803.3 kB/s eta 0:01:26\n",
      "   ------------ --------------------------- 31.0/99.8 MB 803.3 kB/s eta 0:01:26\n",
      "   ------------ --------------------------- 31.0/99.8 MB 803.3 kB/s eta 0:01:26\n",
      "   ------------ --------------------------- 31.1/99.8 MB 788.8 kB/s eta 0:01:28\n",
      "   ------------ --------------------------- 31.1/99.8 MB 788.8 kB/s eta 0:01:28\n",
      "   ------------ --------------------------- 31.1/99.8 MB 786.0 kB/s eta 0:01:28\n",
      "   ------------ --------------------------- 31.2/99.8 MB 785.9 kB/s eta 0:01:28\n",
      "   ------------ --------------------------- 31.2/99.8 MB 782.2 kB/s eta 0:01:28\n",
      "   ------------ --------------------------- 31.2/99.8 MB 782.2 kB/s eta 0:01:28\n",
      "   ------------ --------------------------- 31.2/99.8 MB 778.5 kB/s eta 0:01:29\n",
      "   ------------ --------------------------- 31.3/99.8 MB 779.4 kB/s eta 0:01:28\n",
      "   ------------ --------------------------- 31.3/99.8 MB 779.4 kB/s eta 0:01:28\n",
      "   ------------ --------------------------- 31.3/99.8 MB 776.7 kB/s eta 0:01:29\n",
      "   ------------ --------------------------- 31.3/99.8 MB 773.9 kB/s eta 0:01:29\n",
      "   ------------ --------------------------- 31.4/99.8 MB 776.6 kB/s eta 0:01:29\n",
      "   ------------ --------------------------- 31.4/99.8 MB 776.6 kB/s eta 0:01:29\n",
      "   ------------ --------------------------- 31.4/99.8 MB 776.6 kB/s eta 0:01:29\n",
      "   ------------ --------------------------- 31.4/99.8 MB 772.1 kB/s eta 0:01:29\n",
      "   ------------ --------------------------- 31.5/99.8 MB 788.8 kB/s eta 0:01:27\n",
      "   ------------ --------------------------- 31.6/99.8 MB 804.3 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 31.6/99.8 MB 804.3 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 31.7/99.8 MB 807.3 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 31.7/99.8 MB 806.3 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 31.7/99.8 MB 806.3 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 31.7/99.8 MB 805.3 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 31.7/99.8 MB 804.3 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 31.8/99.8 MB 803.3 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 31.8/99.8 MB 807.3 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 31.8/99.8 MB 807.3 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 31.8/99.8 MB 799.4 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 31.9/99.8 MB 810.3 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 31.9/99.8 MB 810.3 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 31.9/99.8 MB 807.3 kB/s eta 0:01:25\n",
      "   ------------ --------------------------- 31.9/99.8 MB 812.3 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 32.0/99.8 MB 811.2 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 32.1/99.8 MB 813.3 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 32.1/99.8 MB 814.3 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 32.1/99.8 MB 814.3 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 32.2/99.8 MB 816.3 kB/s eta 0:01:23\n",
      "   ------------ --------------------------- 32.2/99.8 MB 816.4 kB/s eta 0:01:23\n",
      "   ------------ --------------------------- 32.2/99.8 MB 818.4 kB/s eta 0:01:23\n",
      "   ------------ --------------------------- 32.2/99.8 MB 818.4 kB/s eta 0:01:23\n",
      "   ------------ --------------------------- 32.2/99.8 MB 814.3 kB/s eta 0:01:23\n",
      "   ------------ --------------------------- 32.2/99.8 MB 814.3 kB/s eta 0:01:23\n",
      "   ------------ --------------------------- 32.2/99.8 MB 814.3 kB/s eta 0:01:23\n",
      "   ------------ --------------------------- 32.2/99.8 MB 814.3 kB/s eta 0:01:23\n",
      "   ------------ --------------------------- 32.2/99.8 MB 814.3 kB/s eta 0:01:23\n",
      "   ------------ --------------------------- 32.2/99.8 MB 814.3 kB/s eta 0:01:23\n",
      "   ------------ --------------------------- 32.2/99.8 MB 814.3 kB/s eta 0:01:23\n",
      "   ------------ --------------------------- 32.2/99.8 MB 814.3 kB/s eta 0:01:23\n",
      "   ------------ --------------------------- 32.2/99.8 MB 814.3 kB/s eta 0:01:23\n",
      "   ------------ --------------------------- 32.2/99.8 MB 814.3 kB/s eta 0:01:23\n",
      "   ------------ --------------------------- 32.4/99.8 MB 803.3 kB/s eta 0:01:24\n",
      "   ------------ --------------------------- 32.4/99.8 MB 803.3 kB/s eta 0:01:24\n",
      "   ------------- -------------------------- 32.4/99.8 MB 805.2 kB/s eta 0:01:24\n",
      "   ------------- -------------------------- 32.4/99.8 MB 805.2 kB/s eta 0:01:24\n",
      "   ------------- -------------------------- 32.5/99.8 MB 804.4 kB/s eta 0:01:24\n",
      "   ------------- -------------------------- 32.5/99.8 MB 804.3 kB/s eta 0:01:24\n",
      "   ------------- -------------------------- 32.6/99.8 MB 814.3 kB/s eta 0:01:23\n",
      "   ------------- -------------------------- 32.6/99.8 MB 825.6 kB/s eta 0:01:22\n",
      "   ------------- -------------------------- 32.6/99.8 MB 822.5 kB/s eta 0:01:22\n",
      "   ------------- -------------------------- 32.7/99.8 MB 822.5 kB/s eta 0:01:22\n",
      "   ------------- -------------------------- 32.7/99.8 MB 824.6 kB/s eta 0:01:22\n",
      "   ------------- -------------------------- 32.8/99.8 MB 825.6 kB/s eta 0:01:22\n",
      "   ------------- -------------------------- 32.8/99.8 MB 827.6 kB/s eta 0:01:21\n",
      "   ------------- -------------------------- 32.9/99.8 MB 824.6 kB/s eta 0:01:22\n",
      "   ------------- -------------------------- 32.9/99.8 MB 824.6 kB/s eta 0:01:22\n",
      "   ------------- -------------------------- 32.9/99.8 MB 823.5 kB/s eta 0:01:22\n",
      "   ------------- -------------------------- 33.0/99.8 MB 823.5 kB/s eta 0:01:22\n",
      "   ------------- -------------------------- 33.0/99.8 MB 822.5 kB/s eta 0:01:22\n",
      "   ------------- -------------------------- 33.0/99.8 MB 822.5 kB/s eta 0:01:22\n",
      "   ------------- -------------------------- 33.0/99.8 MB 817.3 kB/s eta 0:01:22\n",
      "   ------------- -------------------------- 33.0/99.8 MB 817.3 kB/s eta 0:01:22\n",
      "   ------------- -------------------------- 33.0/99.8 MB 812.3 kB/s eta 0:01:23\n",
      "   ------------- -------------------------- 33.1/99.8 MB 814.3 kB/s eta 0:01:22\n",
      "   ------------- -------------------------- 33.1/99.8 MB 814.3 kB/s eta 0:01:22\n",
      "   ------------- -------------------------- 33.1/99.8 MB 810.3 kB/s eta 0:01:23\n",
      "   ------------- -------------------------- 33.1/99.8 MB 810.3 kB/s eta 0:01:23\n",
      "   ------------- -------------------------- 33.1/99.8 MB 807.3 kB/s eta 0:01:23\n",
      "   ------------- -------------------------- 33.1/99.8 MB 807.3 kB/s eta 0:01:23\n",
      "   ------------- -------------------------- 33.1/99.8 MB 807.3 kB/s eta 0:01:23\n",
      "   ------------- -------------------------- 33.1/99.8 MB 799.4 kB/s eta 0:01:24\n",
      "   ------------- -------------------------- 33.1/99.8 MB 799.4 kB/s eta 0:01:24\n",
      "   ------------- -------------------------- 33.2/99.8 MB 796.5 kB/s eta 0:01:24\n",
      "   ------------- -------------------------- 33.2/99.8 MB 796.5 kB/s eta 0:01:24\n",
      "   ------------- -------------------------- 33.2/99.8 MB 790.7 kB/s eta 0:01:25\n",
      "   ------------- -------------------------- 33.2/99.8 MB 788.8 kB/s eta 0:01:25\n",
      "   ------------- -------------------------- 33.3/99.8 MB 789.8 kB/s eta 0:01:25\n",
      "   ------------- -------------------------- 33.3/99.8 MB 787.9 kB/s eta 0:01:25\n",
      "   ------------- -------------------------- 33.3/99.8 MB 786.0 kB/s eta 0:01:25\n",
      "   ------------- -------------------------- 33.3/99.8 MB 784.1 kB/s eta 0:01:25\n",
      "   ------------- -------------------------- 33.4/99.8 MB 783.1 kB/s eta 0:01:25\n",
      "   ------------- -------------------------- 33.4/99.8 MB 783.1 kB/s eta 0:01:25\n",
      "   ------------- -------------------------- 33.4/99.8 MB 783.1 kB/s eta 0:01:25\n",
      "   ------------- -------------------------- 33.4/99.8 MB 779.4 kB/s eta 0:01:26\n",
      "   ------------- -------------------------- 33.5/99.8 MB 778.5 kB/s eta 0:01:26\n",
      "   ------------- -------------------------- 33.5/99.8 MB 778.5 kB/s eta 0:01:26\n",
      "   ------------- -------------------------- 33.6/99.8 MB 779.4 kB/s eta 0:01:25\n",
      "   ------------- -------------------------- 33.6/99.8 MB 777.6 kB/s eta 0:01:26\n",
      "   ------------- -------------------------- 33.6/99.8 MB 777.6 kB/s eta 0:01:26\n",
      "   ------------- -------------------------- 33.6/99.8 MB 776.6 kB/s eta 0:01:26\n",
      "   ------------- -------------------------- 33.7/99.8 MB 773.9 kB/s eta 0:01:26\n",
      "   ------------- -------------------------- 33.7/99.8 MB 771.1 kB/s eta 0:01:26\n",
      "   ------------- -------------------------- 33.8/99.8 MB 769.3 kB/s eta 0:01:26\n",
      "   ------------- -------------------------- 33.8/99.8 MB 770.3 kB/s eta 0:01:26\n",
      "   ------------- -------------------------- 33.8/99.8 MB 769.4 kB/s eta 0:01:26\n",
      "   ------------- -------------------------- 33.8/99.8 MB 769.4 kB/s eta 0:01:26\n",
      "   ------------- -------------------------- 33.9/99.8 MB 767.5 kB/s eta 0:01:26\n",
      "   ------------- -------------------------- 33.9/99.8 MB 770.3 kB/s eta 0:01:26\n",
      "   ------------- -------------------------- 33.9/99.8 MB 770.3 kB/s eta 0:01:26\n",
      "   ------------- -------------------------- 34.0/99.8 MB 765.8 kB/s eta 0:01:26\n",
      "   ------------- -------------------------- 34.0/99.8 MB 763.9 kB/s eta 0:01:27\n",
      "   ------------- -------------------------- 34.0/99.8 MB 761.3 kB/s eta 0:01:27\n",
      "   ------------- -------------------------- 34.0/99.8 MB 758.7 kB/s eta 0:01:27\n",
      "   ------------- -------------------------- 34.0/99.8 MB 758.7 kB/s eta 0:01:27\n",
      "   ------------- -------------------------- 34.0/99.8 MB 755.1 kB/s eta 0:01:28\n",
      "   ------------- -------------------------- 34.0/99.8 MB 755.1 kB/s eta 0:01:28\n",
      "   ------------- -------------------------- 34.1/99.8 MB 750.0 kB/s eta 0:01:28\n",
      "   ------------- -------------------------- 34.1/99.8 MB 750.0 kB/s eta 0:01:28\n",
      "   ------------- -------------------------- 34.1/99.8 MB 746.5 kB/s eta 0:01:28\n",
      "   ------------- -------------------------- 34.1/99.8 MB 746.5 kB/s eta 0:01:28\n",
      "   ------------- -------------------------- 34.1/99.8 MB 746.5 kB/s eta 0:01:28\n",
      "   ------------- -------------------------- 34.1/99.8 MB 739.8 kB/s eta 0:01:29\n",
      "   ------------- -------------------------- 34.1/99.8 MB 737.3 kB/s eta 0:01:29\n",
      "   ------------- -------------------------- 34.1/99.8 MB 737.3 kB/s eta 0:01:29\n",
      "   ------------- -------------------------- 34.2/99.8 MB 734.8 kB/s eta 0:01:30\n",
      "   ------------- -------------------------- 34.2/99.8 MB 734.0 kB/s eta 0:01:30\n",
      "   ------------- -------------------------- 34.2/99.8 MB 730.7 kB/s eta 0:01:30\n",
      "   ------------- -------------------------- 34.2/99.8 MB 727.5 kB/s eta 0:01:31\n",
      "   ------------- -------------------------- 34.2/99.8 MB 726.6 kB/s eta 0:01:31\n",
      "   ------------- -------------------------- 34.3/99.8 MB 725.0 kB/s eta 0:01:31\n",
      "   ------------- -------------------------- 34.3/99.8 MB 725.0 kB/s eta 0:01:31\n",
      "   ------------- -------------------------- 34.3/99.8 MB 725.0 kB/s eta 0:01:31\n",
      "   ------------- -------------------------- 34.3/99.8 MB 717.9 kB/s eta 0:01:32\n",
      "   ------------- -------------------------- 34.3/99.8 MB 716.3 kB/s eta 0:01:32\n",
      "   ------------- -------------------------- 34.3/99.8 MB 713.9 kB/s eta 0:01:32\n",
      "   ------------- -------------------------- 34.4/99.8 MB 712.4 kB/s eta 0:01:32\n",
      "   ------------- -------------------------- 34.4/99.8 MB 713.2 kB/s eta 0:01:32\n",
      "   ------------- -------------------------- 34.4/99.8 MB 710.1 kB/s eta 0:01:32\n",
      "   ------------- -------------------------- 34.4/99.8 MB 709.3 kB/s eta 0:01:33\n",
      "   ------------- -------------------------- 34.5/99.8 MB 707.8 kB/s eta 0:01:33\n",
      "   ------------- -------------------------- 34.5/99.8 MB 706.2 kB/s eta 0:01:33\n",
      "   ------------- -------------------------- 34.6/99.8 MB 706.2 kB/s eta 0:01:33\n",
      "   ------------- -------------------------- 34.6/99.8 MB 704.7 kB/s eta 0:01:33\n",
      "   ------------- -------------------------- 34.6/99.8 MB 704.7 kB/s eta 0:01:33\n",
      "   ------------- -------------------------- 34.6/99.8 MB 704.7 kB/s eta 0:01:33\n",
      "   ------------- -------------------------- 34.6/99.8 MB 699.5 kB/s eta 0:01:34\n",
      "   ------------- -------------------------- 34.7/99.8 MB 698.8 kB/s eta 0:01:34\n",
      "   ------------- -------------------------- 34.7/99.8 MB 697.2 kB/s eta 0:01:34\n",
      "   ------------- -------------------------- 34.7/99.8 MB 695.8 kB/s eta 0:01:34\n",
      "   ------------- -------------------------- 34.7/99.8 MB 695.8 kB/s eta 0:01:34\n",
      "   ------------- -------------------------- 34.8/99.8 MB 695.7 kB/s eta 0:01:34\n",
      "   ------------- -------------------------- 34.8/99.8 MB 694.2 kB/s eta 0:01:34\n",
      "   ------------- -------------------------- 34.8/99.8 MB 692.1 kB/s eta 0:01:34\n",
      "   ------------- -------------------------- 34.9/99.8 MB 693.5 kB/s eta 0:01:34\n",
      "   -------------- ------------------------- 34.9/99.8 MB 692.8 kB/s eta 0:01:34\n",
      "   -------------- ------------------------- 35.0/99.8 MB 694.3 kB/s eta 0:01:34\n",
      "   -------------- ------------------------- 35.0/99.8 MB 694.3 kB/s eta 0:01:34\n",
      "   -------------- ------------------------- 35.1/99.8 MB 692.8 kB/s eta 0:01:34\n",
      "   -------------- ------------------------- 35.1/99.8 MB 691.3 kB/s eta 0:01:34\n",
      "   -------------- ------------------------- 35.1/99.8 MB 689.2 kB/s eta 0:01:34\n",
      "   -------------- ------------------------- 35.1/99.8 MB 689.2 kB/s eta 0:01:34\n",
      "   -------------- ------------------------- 35.1/99.8 MB 685.5 kB/s eta 0:01:35\n",
      "   -------------- ------------------------- 35.1/99.8 MB 686.3 kB/s eta 0:01:35\n",
      "   -------------- ------------------------- 35.2/99.8 MB 682.7 kB/s eta 0:01:35\n",
      "   -------------- ------------------------- 35.2/99.8 MB 683.4 kB/s eta 0:01:35\n",
      "   -------------- ------------------------- 35.2/99.8 MB 682.0 kB/s eta 0:01:35\n",
      "   -------------- ------------------------- 35.2/99.8 MB 678.5 kB/s eta 0:01:36\n",
      "   -------------- ------------------------- 35.3/99.8 MB 678.5 kB/s eta 0:01:36\n",
      "   -------------- ------------------------- 35.3/99.8 MB 676.3 kB/s eta 0:01:36\n",
      "   -------------- ------------------------- 35.3/99.8 MB 675.0 kB/s eta 0:01:36\n",
      "   -------------- ------------------------- 35.4/99.8 MB 673.5 kB/s eta 0:01:36\n",
      "   -------------- ------------------------- 35.4/99.8 MB 673.5 kB/s eta 0:01:36\n",
      "   -------------- ------------------------- 35.4/99.8 MB 670.1 kB/s eta 0:01:37\n",
      "   -------------- ------------------------- 35.5/99.8 MB 668.7 kB/s eta 0:01:37\n",
      "   -------------- ------------------------- 35.5/99.8 MB 668.0 kB/s eta 0:01:37\n",
      "   -------------- ------------------------- 35.5/99.8 MB 666.0 kB/s eta 0:01:37\n",
      "   -------------- ------------------------- 35.5/99.8 MB 664.7 kB/s eta 0:01:37\n",
      "   -------------- ------------------------- 35.5/99.8 MB 662.7 kB/s eta 0:01:37\n",
      "   -------------- ------------------------- 35.6/99.8 MB 661.3 kB/s eta 0:01:38\n",
      "   -------------- ------------------------- 35.6/99.8 MB 659.3 kB/s eta 0:01:38\n",
      "   -------------- ------------------------- 35.6/99.8 MB 659.3 kB/s eta 0:01:38\n",
      "   -------------- ------------------------- 35.6/99.8 MB 654.7 kB/s eta 0:01:38\n",
      "   -------------- ------------------------- 35.6/99.8 MB 654.0 kB/s eta 0:01:39\n",
      "   -------------- ------------------------- 35.7/99.8 MB 652.7 kB/s eta 0:01:39\n",
      "   -------------- ------------------------- 35.7/99.8 MB 651.5 kB/s eta 0:01:39\n",
      "   -------------- ------------------------- 35.7/99.8 MB 649.5 kB/s eta 0:01:39\n",
      "   -------------- ------------------------- 35.7/99.8 MB 649.5 kB/s eta 0:01:39\n",
      "   -------------- ------------------------- 35.8/99.8 MB 647.6 kB/s eta 0:01:39\n",
      "   -------------- ------------------------- 35.8/99.8 MB 646.9 kB/s eta 0:01:39\n",
      "   -------------- ------------------------- 35.8/99.8 MB 646.9 kB/s eta 0:01:39\n",
      "   -------------- ------------------------- 35.8/99.8 MB 643.7 kB/s eta 0:01:40\n",
      "   -------------- ------------------------- 35.8/99.8 MB 642.5 kB/s eta 0:01:40\n",
      "   -------------- ------------------------- 35.9/99.8 MB 640.0 kB/s eta 0:01:40\n",
      "   -------------- ------------------------- 35.9/99.8 MB 637.5 kB/s eta 0:01:41\n",
      "   -------------- ------------------------- 35.9/99.8 MB 636.9 kB/s eta 0:01:41\n",
      "   -------------- ------------------------- 35.9/99.8 MB 636.9 kB/s eta 0:01:41\n",
      "   -------------- ------------------------- 36.0/99.8 MB 634.4 kB/s eta 0:01:41\n",
      "   -------------- ------------------------- 36.0/99.8 MB 635.6 kB/s eta 0:01:41\n",
      "   -------------- ------------------------- 36.0/99.8 MB 635.6 kB/s eta 0:01:41\n",
      "   -------------- ------------------------- 36.0/99.8 MB 635.6 kB/s eta 0:01:41\n",
      "   -------------- ------------------------- 36.0/99.8 MB 630.7 kB/s eta 0:01:42\n",
      "   -------------- ------------------------- 36.0/99.8 MB 630.1 kB/s eta 0:01:42\n",
      "   -------------- ------------------------- 36.0/99.8 MB 630.1 kB/s eta 0:01:42\n",
      "   -------------- ------------------------- 36.0/99.8 MB 630.1 kB/s eta 0:01:42\n",
      "   -------------- ------------------------- 36.0/99.8 MB 624.1 kB/s eta 0:01:43\n",
      "   -------------- ------------------------- 36.1/99.8 MB 624.7 kB/s eta 0:01:42\n",
      "   -------------- ------------------------- 36.1/99.8 MB 624.7 kB/s eta 0:01:42\n",
      "   -------------- ------------------------- 36.1/99.8 MB 624.7 kB/s eta 0:01:42\n",
      "   -------------- ------------------------- 36.1/99.8 MB 619.4 kB/s eta 0:01:43\n",
      "   -------------- ------------------------- 36.1/99.8 MB 618.2 kB/s eta 0:01:43\n",
      "   -------------- ------------------------- 36.2/99.8 MB 617.1 kB/s eta 0:01:43\n",
      "   -------------- ------------------------- 36.2/99.8 MB 615.3 kB/s eta 0:01:44\n",
      "   -------------- ------------------------- 36.3/99.8 MB 614.7 kB/s eta 0:01:44\n",
      "   -------------- ------------------------- 36.3/99.8 MB 614.7 kB/s eta 0:01:44\n",
      "   -------------- ------------------------- 36.3/99.8 MB 613.6 kB/s eta 0:01:44\n",
      "   -------------- ------------------------- 36.3/99.8 MB 612.5 kB/s eta 0:01:44\n",
      "   -------------- ------------------------- 36.3/99.8 MB 611.3 kB/s eta 0:01:44\n",
      "   -------------- ------------------------- 36.4/99.8 MB 610.1 kB/s eta 0:01:44\n",
      "   -------------- ------------------------- 36.4/99.8 MB 608.5 kB/s eta 0:01:45\n",
      "   -------------- ------------------------- 36.4/99.8 MB 608.5 kB/s eta 0:01:45\n",
      "   -------------- ------------------------- 36.4/99.8 MB 605.1 kB/s eta 0:01:45\n",
      "   -------------- ------------------------- 36.4/99.8 MB 604.0 kB/s eta 0:01:45\n",
      "   -------------- ------------------------- 36.4/99.8 MB 602.3 kB/s eta 0:01:46\n",
      "   -------------- ------------------------- 36.5/99.8 MB 600.7 kB/s eta 0:01:46\n",
      "   -------------- ------------------------- 36.5/99.8 MB 600.1 kB/s eta 0:01:46\n",
      "   -------------- ------------------------- 36.5/99.8 MB 601.2 kB/s eta 0:01:46\n",
      "   -------------- ------------------------- 36.6/99.8 MB 599.0 kB/s eta 0:01:46\n",
      "   -------------- ------------------------- 36.6/99.8 MB 599.6 kB/s eta 0:01:46\n",
      "   -------------- ------------------------- 36.6/99.8 MB 597.9 kB/s eta 0:01:46\n",
      "   -------------- ------------------------- 36.7/99.8 MB 598.5 kB/s eta 0:01:46\n",
      "   -------------- ------------------------- 36.7/99.8 MB 597.4 kB/s eta 0:01:46\n",
      "   -------------- ------------------------- 36.8/99.8 MB 597.9 kB/s eta 0:01:46\n",
      "   -------------- ------------------------- 36.8/99.8 MB 596.8 kB/s eta 0:01:46\n",
      "   -------------- ------------------------- 36.9/99.8 MB 596.8 kB/s eta 0:01:46\n",
      "   -------------- ------------------------- 36.9/99.8 MB 596.3 kB/s eta 0:01:46\n",
      "   -------------- ------------------------- 36.9/99.8 MB 595.2 kB/s eta 0:01:46\n",
      "   -------------- ------------------------- 36.9/99.8 MB 595.2 kB/s eta 0:01:46\n",
      "   -------------- ------------------------- 37.0/99.8 MB 592.5 kB/s eta 0:01:46\n",
      "   -------------- ------------------------- 37.0/99.8 MB 592.0 kB/s eta 0:01:46\n",
      "   -------------- ------------------------- 37.1/99.8 MB 590.9 kB/s eta 0:01:47\n",
      "   -------------- ------------------------- 37.1/99.8 MB 590.9 kB/s eta 0:01:46\n",
      "   -------------- ------------------------- 37.2/99.8 MB 590.4 kB/s eta 0:01:47\n",
      "   -------------- ------------------------- 37.2/99.8 MB 590.4 kB/s eta 0:01:47\n",
      "   -------------- ------------------------- 37.2/99.8 MB 588.2 kB/s eta 0:01:47\n",
      "   -------------- ------------------------- 37.2/99.8 MB 587.7 kB/s eta 0:01:47\n",
      "   -------------- ------------------------- 37.3/99.8 MB 586.7 kB/s eta 0:01:47\n",
      "   -------------- ------------------------- 37.3/99.8 MB 585.1 kB/s eta 0:01:47\n",
      "   -------------- ------------------------- 37.3/99.8 MB 584.6 kB/s eta 0:01:47\n",
      "   -------------- ------------------------- 37.3/99.8 MB 585.1 kB/s eta 0:01:47\n",
      "   -------------- ------------------------- 37.4/99.8 MB 584.0 kB/s eta 0:01:47\n",
      "   -------------- ------------------------- 37.4/99.8 MB 582.5 kB/s eta 0:01:48\n",
      "   --------------- ------------------------ 37.4/99.8 MB 582.5 kB/s eta 0:01:47\n",
      "   --------------- ------------------------ 37.4/99.8 MB 580.9 kB/s eta 0:01:48\n",
      "   --------------- ------------------------ 37.5/99.8 MB 580.9 kB/s eta 0:01:48\n",
      "   --------------- ------------------------ 37.5/99.8 MB 578.9 kB/s eta 0:01:48\n",
      "   --------------- ------------------------ 37.5/99.8 MB 578.4 kB/s eta 0:01:48\n",
      "   --------------- ------------------------ 37.5/99.8 MB 576.8 kB/s eta 0:01:48\n",
      "   --------------- ------------------------ 37.6/99.8 MB 578.9 kB/s eta 0:01:48\n",
      "   --------------- ------------------------ 37.6/99.8 MB 576.8 kB/s eta 0:01:48\n",
      "   --------------- ------------------------ 37.6/99.8 MB 575.3 kB/s eta 0:01:48\n",
      "   --------------- ------------------------ 37.6/99.8 MB 574.8 kB/s eta 0:01:49\n",
      "   --------------- ------------------------ 37.7/99.8 MB 573.3 kB/s eta 0:01:49\n",
      "   --------------- ------------------------ 37.7/99.8 MB 571.8 kB/s eta 0:01:49\n",
      "   --------------- ------------------------ 37.7/99.8 MB 570.8 kB/s eta 0:01:49\n",
      "   --------------- ------------------------ 37.7/99.8 MB 570.8 kB/s eta 0:01:49\n",
      "   --------------- ------------------------ 37.8/99.8 MB 569.3 kB/s eta 0:01:49\n",
      "   --------------- ------------------------ 37.8/99.8 MB 568.8 kB/s eta 0:01:49\n",
      "   --------------- ------------------------ 37.8/99.8 MB 567.8 kB/s eta 0:01:50\n",
      "   --------------- ------------------------ 37.9/99.8 MB 567.8 kB/s eta 0:01:49\n",
      "   --------------- ------------------------ 37.9/99.8 MB 567.3 kB/s eta 0:01:49\n",
      "   --------------- ------------------------ 37.9/99.8 MB 567.3 kB/s eta 0:01:49\n",
      "   --------------- ------------------------ 38.0/99.8 MB 565.4 kB/s eta 0:01:50\n",
      "   --------------- ------------------------ 38.0/99.8 MB 564.9 kB/s eta 0:01:50\n",
      "   --------------- ------------------------ 38.0/99.8 MB 563.9 kB/s eta 0:01:50\n",
      "   --------------- ------------------------ 38.1/99.8 MB 567.3 kB/s eta 0:01:49\n",
      "   --------------- ------------------------ 38.1/99.8 MB 567.3 kB/s eta 0:01:49\n",
      "   --------------- ------------------------ 38.2/99.8 MB 566.3 kB/s eta 0:01:49\n",
      "   --------------- ------------------------ 38.2/99.8 MB 565.8 kB/s eta 0:01:49\n",
      "   --------------- ------------------------ 38.3/99.8 MB 567.8 kB/s eta 0:01:49\n",
      "   --------------- ------------------------ 38.3/99.8 MB 569.3 kB/s eta 0:01:48\n",
      "   --------------- ------------------------ 38.3/99.8 MB 567.8 kB/s eta 0:01:49\n",
      "   --------------- ------------------------ 38.4/99.8 MB 570.3 kB/s eta 0:01:48\n",
      "   --------------- ------------------------ 38.5/99.8 MB 570.8 kB/s eta 0:01:48\n",
      "   --------------- ------------------------ 38.5/99.8 MB 570.3 kB/s eta 0:01:48\n",
      "   --------------- ------------------------ 38.6/99.8 MB 569.8 kB/s eta 0:01:48\n",
      "   --------------- ------------------------ 38.6/99.8 MB 571.3 kB/s eta 0:01:48\n",
      "   --------------- ------------------------ 38.6/99.8 MB 569.8 kB/s eta 0:01:48\n",
      "   --------------- ------------------------ 38.7/99.8 MB 571.8 kB/s eta 0:01:47\n",
      "   --------------- ------------------------ 38.7/99.8 MB 573.3 kB/s eta 0:01:47\n",
      "   --------------- ------------------------ 38.8/99.8 MB 575.8 kB/s eta 0:01:46\n",
      "   --------------- ------------------------ 38.9/99.8 MB 576.8 kB/s eta 0:01:46\n",
      "   --------------- ------------------------ 38.9/99.8 MB 575.3 kB/s eta 0:01:46\n",
      "   --------------- ------------------------ 38.9/99.8 MB 574.3 kB/s eta 0:01:46\n",
      "   --------------- ------------------------ 39.0/99.8 MB 575.3 kB/s eta 0:01:46\n",
      "   --------------- ------------------------ 39.0/99.8 MB 575.8 kB/s eta 0:01:46\n",
      "   --------------- ------------------------ 39.1/99.8 MB 575.8 kB/s eta 0:01:46\n",
      "   --------------- ------------------------ 39.1/99.8 MB 574.8 kB/s eta 0:01:46\n",
      "   --------------- ------------------------ 39.2/99.8 MB 574.8 kB/s eta 0:01:46\n",
      "   --------------- ------------------------ 39.2/99.8 MB 573.8 kB/s eta 0:01:46\n",
      "   --------------- ------------------------ 39.2/99.8 MB 573.3 kB/s eta 0:01:46\n",
      "   --------------- ------------------------ 39.2/99.8 MB 573.3 kB/s eta 0:01:46\n",
      "   --------------- ------------------------ 39.2/99.8 MB 571.8 kB/s eta 0:01:46\n",
      "   --------------- ------------------------ 39.2/99.8 MB 571.8 kB/s eta 0:01:46\n",
      "   --------------- ------------------------ 39.3/99.8 MB 570.8 kB/s eta 0:01:46\n",
      "   --------------- ------------------------ 39.3/99.8 MB 570.8 kB/s eta 0:01:46\n",
      "   --------------- ------------------------ 39.3/99.8 MB 571.3 kB/s eta 0:01:46\n",
      "   --------------- ------------------------ 39.4/99.8 MB 570.8 kB/s eta 0:01:46\n",
      "   --------------- ------------------------ 39.4/99.8 MB 575.3 kB/s eta 0:01:45\n",
      "   --------------- ------------------------ 39.5/99.8 MB 580.4 kB/s eta 0:01:44\n",
      "   --------------- ------------------------ 39.5/99.8 MB 580.4 kB/s eta 0:01:44\n",
      "   --------------- ------------------------ 39.5/99.8 MB 579.4 kB/s eta 0:01:44\n",
      "   --------------- ------------------------ 39.5/99.8 MB 579.4 kB/s eta 0:01:44\n",
      "   --------------- ------------------------ 39.5/99.8 MB 577.9 kB/s eta 0:01:45\n",
      "   --------------- ------------------------ 39.6/99.8 MB 577.9 kB/s eta 0:01:45\n",
      "   --------------- ------------------------ 39.6/99.8 MB 577.9 kB/s eta 0:01:45\n",
      "   --------------- ------------------------ 39.6/99.8 MB 580.4 kB/s eta 0:01:44\n",
      "   --------------- ------------------------ 39.7/99.8 MB 583.5 kB/s eta 0:01:43\n",
      "   --------------- ------------------------ 39.7/99.8 MB 584.1 kB/s eta 0:01:43\n",
      "   --------------- ------------------------ 39.8/99.8 MB 583.5 kB/s eta 0:01:43\n",
      "   --------------- ------------------------ 39.8/99.8 MB 583.0 kB/s eta 0:01:43\n",
      "   --------------- ------------------------ 39.8/99.8 MB 585.1 kB/s eta 0:01:43\n",
      "   --------------- ------------------------ 39.8/99.8 MB 587.2 kB/s eta 0:01:43\n",
      "   --------------- ------------------------ 39.9/99.8 MB 586.1 kB/s eta 0:01:43\n",
      "   --------------- ------------------------ 39.9/99.8 MB 586.6 kB/s eta 0:01:43\n",
      "   ---------------- ----------------------- 39.9/99.8 MB 585.1 kB/s eta 0:01:43\n",
      "   ---------------- ----------------------- 39.9/99.8 MB 585.1 kB/s eta 0:01:43\n",
      "   ---------------- ----------------------- 40.0/99.8 MB 587.2 kB/s eta 0:01:42\n",
      "   ---------------- ----------------------- 40.1/99.8 MB 587.2 kB/s eta 0:01:42\n",
      "   ---------------- ----------------------- 40.1/99.8 MB 586.6 kB/s eta 0:01:42\n",
      "   ---------------- ----------------------- 40.1/99.8 MB 585.1 kB/s eta 0:01:42\n",
      "   ---------------- ----------------------- 40.2/99.8 MB 589.8 kB/s eta 0:01:42\n",
      "   ---------------- ----------------------- 40.2/99.8 MB 590.4 kB/s eta 0:01:41\n",
      "   ---------------- ----------------------- 40.3/99.8 MB 589.8 kB/s eta 0:01:41\n",
      "   ---------------- ----------------------- 40.3/99.8 MB 589.8 kB/s eta 0:01:41\n",
      "   ---------------- ----------------------- 40.4/99.8 MB 590.4 kB/s eta 0:01:41\n",
      "   ---------------- ----------------------- 40.4/99.8 MB 589.3 kB/s eta 0:01:41\n",
      "   ---------------- ----------------------- 40.5/99.8 MB 589.8 kB/s eta 0:01:41\n",
      "   ---------------- ----------------------- 40.5/99.8 MB 589.8 kB/s eta 0:01:41\n",
      "   ---------------- ----------------------- 40.5/99.8 MB 593.6 kB/s eta 0:01:40\n",
      "   ---------------- ----------------------- 40.6/99.8 MB 596.3 kB/s eta 0:01:40\n",
      "   ---------------- ----------------------- 40.6/99.8 MB 598.4 kB/s eta 0:01:39\n",
      "   ---------------- ----------------------- 40.7/99.8 MB 602.8 kB/s eta 0:01:38\n",
      "   ---------------- ----------------------- 40.7/99.8 MB 602.3 kB/s eta 0:01:39\n",
      "   ---------------- ----------------------- 40.8/99.8 MB 602.3 kB/s eta 0:01:38\n",
      "   ---------------- ----------------------- 40.8/99.8 MB 602.3 kB/s eta 0:01:38\n",
      "   ---------------- ----------------------- 40.8/99.8 MB 601.8 kB/s eta 0:01:38\n",
      "   ---------------- ----------------------- 40.9/99.8 MB 601.8 kB/s eta 0:01:38\n",
      "   ---------------- ----------------------- 40.9/99.8 MB 600.1 kB/s eta 0:01:39\n",
      "   ---------------- ----------------------- 41.0/99.8 MB 599.0 kB/s eta 0:01:39\n",
      "   ---------------- ----------------------- 41.0/99.8 MB 600.7 kB/s eta 0:01:38\n",
      "   ---------------- ----------------------- 41.0/99.8 MB 600.7 kB/s eta 0:01:38\n",
      "   ---------------- ----------------------- 41.1/99.8 MB 602.3 kB/s eta 0:01:38\n",
      "   ---------------- ----------------------- 41.1/99.8 MB 601.8 kB/s eta 0:01:38\n",
      "   ---------------- ----------------------- 41.1/99.8 MB 601.8 kB/s eta 0:01:38\n",
      "   ---------------- ----------------------- 41.1/99.8 MB 602.3 kB/s eta 0:01:38\n",
      "   ---------------- ----------------------- 41.2/99.8 MB 600.1 kB/s eta 0:01:38\n",
      "   ---------------- ----------------------- 41.2/99.8 MB 611.3 kB/s eta 0:01:36\n",
      "   ---------------- ----------------------- 41.2/99.8 MB 611.9 kB/s eta 0:01:36\n",
      "   ---------------- ----------------------- 41.3/99.8 MB 611.9 kB/s eta 0:01:36\n",
      "   ---------------- ----------------------- 41.3/99.8 MB 618.3 kB/s eta 0:01:35\n",
      "   ---------------- ----------------------- 41.3/99.8 MB 620.5 kB/s eta 0:01:35\n",
      "   ---------------- ----------------------- 41.4/99.8 MB 620.0 kB/s eta 0:01:35\n",
      "   ---------------- ----------------------- 41.4/99.8 MB 622.9 kB/s eta 0:01:34\n",
      "   ---------------- ----------------------- 41.5/99.8 MB 622.4 kB/s eta 0:01:34\n",
      "   ---------------- ----------------------- 41.5/99.8 MB 624.7 kB/s eta 0:01:34\n",
      "   ---------------- ----------------------- 41.5/99.8 MB 624.1 kB/s eta 0:01:34\n",
      "   ---------------- ----------------------- 41.6/99.8 MB 624.7 kB/s eta 0:01:34\n",
      "   ---------------- ----------------------- 41.6/99.8 MB 624.1 kB/s eta 0:01:34\n",
      "   ---------------- ----------------------- 41.7/99.8 MB 627.7 kB/s eta 0:01:33\n",
      "   ---------------- ----------------------- 41.8/99.8 MB 627.1 kB/s eta 0:01:33\n",
      "   ---------------- ----------------------- 41.8/99.8 MB 629.5 kB/s eta 0:01:33\n",
      "   ---------------- ----------------------- 41.9/99.8 MB 628.9 kB/s eta 0:01:33\n",
      "   ---------------- ----------------------- 41.9/99.8 MB 631.3 kB/s eta 0:01:32\n",
      "   ---------------- ----------------------- 42.0/99.8 MB 633.2 kB/s eta 0:01:32\n",
      "   ---------------- ----------------------- 42.1/99.8 MB 637.5 kB/s eta 0:01:31\n",
      "   ---------------- ----------------------- 42.1/99.8 MB 637.5 kB/s eta 0:01:31\n",
      "   ---------------- ----------------------- 42.2/99.8 MB 641.2 kB/s eta 0:01:30\n",
      "   ---------------- ----------------------- 42.2/99.8 MB 641.9 kB/s eta 0:01:30\n",
      "   ---------------- ----------------------- 42.3/99.8 MB 645.7 kB/s eta 0:01:29\n",
      "   ---------------- ----------------------- 42.4/99.8 MB 645.7 kB/s eta 0:01:29\n",
      "   ----------------- ---------------------- 42.5/99.8 MB 671.5 kB/s eta 0:01:26\n",
      "   ----------------- ---------------------- 42.6/99.8 MB 669.4 kB/s eta 0:01:26\n",
      "   ----------------- ---------------------- 42.6/99.8 MB 668.0 kB/s eta 0:01:26\n",
      "   ----------------- ---------------------- 42.7/99.8 MB 668.8 kB/s eta 0:01:26\n",
      "   ----------------- ---------------------- 42.7/99.8 MB 672.2 kB/s eta 0:01:25\n",
      "   ----------------- ---------------------- 42.8/99.8 MB 672.9 kB/s eta 0:01:25\n",
      "   ----------------- ---------------------- 42.8/99.8 MB 672.9 kB/s eta 0:01:25\n",
      "   ----------------- ---------------------- 42.8/99.8 MB 672.9 kB/s eta 0:01:25\n",
      "   ----------------- ---------------------- 42.9/99.8 MB 671.5 kB/s eta 0:01:25\n",
      "   ----------------- ---------------------- 42.9/99.8 MB 670.8 kB/s eta 0:01:25\n",
      "   ----------------- ---------------------- 42.9/99.8 MB 669.4 kB/s eta 0:01:25\n",
      "   ----------------- ---------------------- 42.9/99.8 MB 669.4 kB/s eta 0:01:25\n",
      "   ----------------- ---------------------- 43.0/99.8 MB 668.0 kB/s eta 0:01:26\n",
      "   ----------------- ---------------------- 43.0/99.8 MB 666.0 kB/s eta 0:01:26\n",
      "   ----------------- ---------------------- 43.1/99.8 MB 665.4 kB/s eta 0:01:26\n",
      "   ----------------- ---------------------- 43.1/99.8 MB 666.7 kB/s eta 0:01:25\n",
      "   ----------------- ---------------------- 43.2/99.8 MB 668.0 kB/s eta 0:01:25\n",
      "   ----------------- ---------------------- 43.2/99.8 MB 666.0 kB/s eta 0:01:25\n",
      "   ----------------- ---------------------- 43.2/99.8 MB 666.0 kB/s eta 0:01:25\n",
      "   ----------------- ---------------------- 43.2/99.8 MB 667.4 kB/s eta 0:01:25\n",
      "   ----------------- ---------------------- 43.3/99.8 MB 672.2 kB/s eta 0:01:25\n",
      "   ----------------- ---------------------- 43.3/99.8 MB 678.4 kB/s eta 0:01:24\n",
      "   ----------------- ---------------------- 43.4/99.8 MB 687.7 kB/s eta 0:01:22\n",
      "   ----------------- ---------------------- 43.4/99.8 MB 692.8 kB/s eta 0:01:22\n",
      "   ----------------- ---------------------- 43.5/99.8 MB 693.5 kB/s eta 0:01:22\n",
      "   ----------------- ---------------------- 43.6/99.8 MB 699.5 kB/s eta 0:01:21\n",
      "   ----------------- ---------------------- 43.7/99.8 MB 701.7 kB/s eta 0:01:20\n",
      "   ----------------- ---------------------- 43.7/99.8 MB 705.5 kB/s eta 0:01:20\n",
      "   ----------------- ---------------------- 43.8/99.8 MB 705.5 kB/s eta 0:01:20\n",
      "   ----------------- ---------------------- 43.8/99.8 MB 710.1 kB/s eta 0:01:19\n",
      "   ----------------- ---------------------- 43.9/99.8 MB 713.2 kB/s eta 0:01:19\n",
      "   ----------------- ---------------------- 44.0/99.8 MB 713.2 kB/s eta 0:01:19\n",
      "   ----------------- ---------------------- 44.0/99.8 MB 713.9 kB/s eta 0:01:19\n",
      "   ----------------- ---------------------- 44.1/99.8 MB 717.1 kB/s eta 0:01:18\n",
      "   ----------------- ---------------------- 44.2/99.8 MB 715.5 kB/s eta 0:01:18\n",
      "   ----------------- ---------------------- 44.2/99.8 MB 722.6 kB/s eta 0:01:17\n",
      "   ----------------- ---------------------- 44.3/99.8 MB 725.8 kB/s eta 0:01:17\n",
      "   ----------------- ---------------------- 44.3/99.8 MB 732.3 kB/s eta 0:01:16\n",
      "   ----------------- ---------------------- 44.3/99.8 MB 734.0 kB/s eta 0:01:16\n",
      "   ----------------- ---------------------- 44.4/99.8 MB 746.5 kB/s eta 0:01:15\n",
      "   ----------------- ---------------------- 44.5/99.8 MB 755.1 kB/s eta 0:01:14\n",
      "   ----------------- ---------------------- 44.5/99.8 MB 766.7 kB/s eta 0:01:13\n",
      "   ----------------- ---------------------- 44.6/99.8 MB 765.8 kB/s eta 0:01:13\n",
      "   ----------------- ---------------------- 44.6/99.8 MB 765.8 kB/s eta 0:01:13\n",
      "   ----------------- ---------------------- 44.6/99.8 MB 763.9 kB/s eta 0:01:13\n",
      "   ----------------- ---------------------- 44.6/99.8 MB 763.1 kB/s eta 0:01:13\n",
      "   ----------------- ---------------------- 44.6/99.8 MB 761.3 kB/s eta 0:01:13\n",
      "   ----------------- ---------------------- 44.7/99.8 MB 767.5 kB/s eta 0:01:12\n",
      "   ----------------- ---------------------- 44.8/99.8 MB 773.0 kB/s eta 0:01:12\n",
      "   ----------------- ---------------------- 44.8/99.8 MB 773.0 kB/s eta 0:01:12\n",
      "   ----------------- ---------------------- 44.8/99.8 MB 773.0 kB/s eta 0:01:12\n",
      "   ----------------- ---------------------- 44.8/99.8 MB 773.0 kB/s eta 0:01:12\n",
      "   ------------------ --------------------- 45.0/99.8 MB 785.0 kB/s eta 0:01:10\n",
      "   ------------------ --------------------- 45.0/99.8 MB 785.0 kB/s eta 0:01:10\n",
      "   ------------------ --------------------- 45.0/99.8 MB 785.0 kB/s eta 0:01:10\n",
      "   ------------------ --------------------- 45.0/99.8 MB 785.0 kB/s eta 0:01:10\n",
      "   ------------------ --------------------- 45.0/99.8 MB 785.0 kB/s eta 0:01:10\n",
      "   ------------------ --------------------- 45.2/99.8 MB 786.9 kB/s eta 0:01:10\n",
      "   ------------------ --------------------- 45.3/99.8 MB 789.8 kB/s eta 0:01:09\n",
      "   ------------------ --------------------- 45.4/99.8 MB 794.5 kB/s eta 0:01:09\n",
      "   ------------------ --------------------- 45.4/99.8 MB 800.4 kB/s eta 0:01:08\n",
      "   ------------------ --------------------- 45.4/99.8 MB 800.4 kB/s eta 0:01:08\n",
      "   ------------------ --------------------- 45.5/99.8 MB 806.3 kB/s eta 0:01:08\n",
      "   ------------------ --------------------- 45.6/99.8 MB 807.3 kB/s eta 0:01:08\n",
      "   ------------------ --------------------- 45.6/99.8 MB 813.3 kB/s eta 0:01:07\n",
      "   ------------------ --------------------- 45.7/99.8 MB 812.3 kB/s eta 0:01:07\n",
      "   ------------------ --------------------- 45.7/99.8 MB 812.3 kB/s eta 0:01:07\n",
      "   ------------------ --------------------- 45.7/99.8 MB 812.3 kB/s eta 0:01:07\n",
      "   ------------------ --------------------- 45.7/99.8 MB 804.4 kB/s eta 0:01:08\n",
      "   ------------------ --------------------- 45.7/99.8 MB 807.3 kB/s eta 0:01:07\n",
      "   ------------------ --------------------- 45.8/99.8 MB 808.2 kB/s eta 0:01:07\n",
      "   ------------------ --------------------- 45.8/99.8 MB 810.3 kB/s eta 0:01:07\n",
      "   ------------------ --------------------- 45.8/99.8 MB 807.3 kB/s eta 0:01:07\n",
      "   ------------------ --------------------- 45.8/99.8 MB 807.3 kB/s eta 0:01:07\n",
      "   ------------------ --------------------- 45.9/99.8 MB 814.3 kB/s eta 0:01:07\n",
      "   ------------------ --------------------- 45.9/99.8 MB 814.3 kB/s eta 0:01:07\n",
      "   ------------------ --------------------- 45.9/99.8 MB 809.3 kB/s eta 0:01:07\n",
      "   ------------------ --------------------- 45.9/99.8 MB 809.3 kB/s eta 0:01:07\n",
      "   ------------------ --------------------- 46.0/99.8 MB 814.3 kB/s eta 0:01:07\n",
      "   ------------------ --------------------- 46.0/99.8 MB 815.3 kB/s eta 0:01:06\n",
      "   ------------------ --------------------- 46.0/99.8 MB 816.4 kB/s eta 0:01:06\n",
      "   ------------------ --------------------- 46.1/99.8 MB 826.6 kB/s eta 0:01:05\n",
      "   ------------------ --------------------- 46.1/99.8 MB 825.6 kB/s eta 0:01:05\n",
      "   ------------------ --------------------- 46.2/99.8 MB 827.7 kB/s eta 0:01:05\n",
      "   ------------------ --------------------- 46.2/99.8 MB 824.6 kB/s eta 0:01:05\n",
      "   ------------------ --------------------- 46.3/99.8 MB 838.3 kB/s eta 0:01:04\n",
      "   ------------------ --------------------- 46.3/99.8 MB 848.1 kB/s eta 0:01:04\n",
      "   ------------------ --------------------- 46.4/99.8 MB 855.8 kB/s eta 0:01:03\n",
      "   ------------------ --------------------- 46.4/99.8 MB 859.1 kB/s eta 0:01:03\n",
      "   ------------------ --------------------- 46.5/99.8 MB 861.5 kB/s eta 0:01:02\n",
      "   ------------------ --------------------- 46.5/99.8 MB 869.5 kB/s eta 0:01:02\n",
      "   ------------------ --------------------- 46.5/99.8 MB 869.5 kB/s eta 0:01:02\n",
      "   ------------------ --------------------- 46.6/99.8 MB 883.6 kB/s eta 0:01:01\n",
      "   ------------------ --------------------- 46.6/99.8 MB 883.6 kB/s eta 0:01:01\n",
      "   ------------------ --------------------- 46.7/99.8 MB 881.2 kB/s eta 0:01:01\n",
      "   ------------------ --------------------- 46.7/99.8 MB 883.6 kB/s eta 0:01:01\n",
      "   ------------------ --------------------- 46.8/99.8 MB 887.2 kB/s eta 0:01:00\n",
      "   ------------------ --------------------- 46.8/99.8 MB 884.7 kB/s eta 0:01:00\n",
      "   ------------------ --------------------- 47.0/99.8 MB 894.4 kB/s eta 0:01:00\n",
      "   ------------------ --------------------- 47.0/99.8 MB 898.1 kB/s eta 0:00:59\n",
      "   ------------------ --------------------- 47.1/99.8 MB 899.3 kB/s eta 0:00:59\n",
      "   ------------------ --------------------- 47.1/99.8 MB 899.3 kB/s eta 0:00:59\n",
      "   ------------------ --------------------- 47.2/99.8 MB 903.0 kB/s eta 0:00:59\n",
      "   ------------------ --------------------- 47.2/99.8 MB 900.5 kB/s eta 0:00:59\n",
      "   ------------------ --------------------- 47.3/99.8 MB 903.0 kB/s eta 0:00:59\n",
      "   ------------------ --------------------- 47.3/99.8 MB 903.0 kB/s eta 0:00:59\n",
      "   ------------------- -------------------- 47.4/99.8 MB 911.9 kB/s eta 0:00:58\n",
      "   ------------------- -------------------- 47.5/99.8 MB 914.4 kB/s eta 0:00:58\n",
      "   ------------------- -------------------- 47.5/99.8 MB 913.1 kB/s eta 0:00:58\n",
      "   ------------------- -------------------- 47.6/99.8 MB 923.4 kB/s eta 0:00:57\n",
      "   ------------------- -------------------- 47.7/99.8 MB 928.7 kB/s eta 0:00:57\n",
      "   ------------------- -------------------- 47.7/99.8 MB 939.3 kB/s eta 0:00:56\n",
      "   ------------------- -------------------- 47.8/99.8 MB 946.1 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 47.9/99.8 MB 952.9 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 47.9/99.8 MB 952.9 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 47.9/99.8 MB 952.9 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 47.9/99.8 MB 951.6 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.0/99.8 MB 954.4 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.0/99.8 MB 953.0 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.0/99.8 MB 953.0 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.1/99.8 MB 951.6 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.1/99.8 MB 950.3 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.1/99.8 MB 944.8 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.1/99.8 MB 948.9 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.2/99.8 MB 944.7 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.2/99.8 MB 947.5 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.2/99.8 MB 944.8 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.3/99.8 MB 947.5 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.3/99.8 MB 947.5 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.4/99.8 MB 950.2 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.4/99.8 MB 946.1 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.5/99.8 MB 950.3 kB/s eta 0:00:54\n",
      "   ------------------- -------------------- 48.6/99.8 MB 955.8 kB/s eta 0:00:54\n",
      "   ------------------- -------------------- 48.6/99.8 MB 953.0 kB/s eta 0:00:54\n",
      "   ------------------- -------------------- 48.6/99.8 MB 953.0 kB/s eta 0:00:54\n",
      "   ------------------- -------------------- 48.6/99.8 MB 953.0 kB/s eta 0:00:54\n",
      "   ------------------- -------------------- 48.6/99.8 MB 943.4 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.7/99.8 MB 943.4 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.7/99.8 MB 940.7 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.7/99.8 MB 937.9 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.8/99.8 MB 935.3 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.8/99.8 MB 935.3 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.8/99.8 MB 931.3 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.9/99.8 MB 932.7 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.9/99.8 MB 930.0 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 48.9/99.8 MB 928.7 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 49.0/99.8 MB 927.4 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 49.0/99.8 MB 927.4 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 49.0/99.8 MB 922.1 kB/s eta 0:00:56\n",
      "   ------------------- -------------------- 49.0/99.8 MB 922.1 kB/s eta 0:00:56\n",
      "   ------------------- -------------------- 49.1/99.8 MB 916.9 kB/s eta 0:00:56\n",
      "   ------------------- -------------------- 49.1/99.8 MB 919.5 kB/s eta 0:00:56\n",
      "   ------------------- -------------------- 49.2/99.8 MB 919.5 kB/s eta 0:00:56\n",
      "   ------------------- -------------------- 49.2/99.8 MB 919.5 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 49.3/99.8 MB 919.5 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 49.3/99.8 MB 918.3 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 49.3/99.8 MB 914.4 kB/s eta 0:00:56\n",
      "   ------------------- -------------------- 49.3/99.8 MB 915.7 kB/s eta 0:00:56\n",
      "   ------------------- -------------------- 49.3/99.8 MB 915.7 kB/s eta 0:00:56\n",
      "   ------------------- -------------------- 49.4/99.8 MB 910.5 kB/s eta 0:00:56\n",
      "   ------------------- -------------------- 49.4/99.8 MB 909.3 kB/s eta 0:00:56\n",
      "   ------------------- -------------------- 49.4/99.8 MB 914.4 kB/s eta 0:00:56\n",
      "   ------------------- -------------------- 49.5/99.8 MB 917.0 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 49.5/99.8 MB 920.8 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 49.6/99.8 MB 920.9 kB/s eta 0:00:55\n",
      "   ------------------- -------------------- 49.6/99.8 MB 930.0 kB/s eta 0:00:54\n",
      "   ------------------- -------------------- 49.7/99.8 MB 935.3 kB/s eta 0:00:54\n",
      "   ------------------- -------------------- 49.8/99.8 MB 943.4 kB/s eta 0:00:53\n",
      "   ------------------- -------------------- 49.8/99.8 MB 944.8 kB/s eta 0:00:53\n",
      "   -------------------- ------------------- 49.9/99.8 MB 943.4 kB/s eta 0:00:53\n",
      "   -------------------- ------------------- 50.0/99.8 MB 948.9 kB/s eta 0:00:53\n",
      "   -------------------- ------------------- 50.0/99.8 MB 960.0 kB/s eta 0:00:52\n",
      "   -------------------- ------------------- 50.2/99.8 MB 972.9 kB/s eta 0:00:51\n",
      "   -------------------- ------------------- 50.2/99.8 MB 971.4 kB/s eta 0:00:51\n",
      "   -------------------- ------------------- 50.3/99.8 MB 971.4 kB/s eta 0:00:51\n",
      "   -------------------- ------------------- 50.4/99.8 MB 975.7 kB/s eta 0:00:51\n",
      "   -------------------- ------------------- 50.4/99.8 MB 975.7 kB/s eta 0:00:51\n",
      "   -------------------- ------------------- 50.4/99.8 MB 977.2 kB/s eta 0:00:51\n",
      "   -------------------- ------------------- 50.5/99.8 MB 983.1 kB/s eta 0:00:51\n",
      "   -------------------- ------------------- 50.6/99.8 MB 981.6 kB/s eta 0:00:51\n",
      "   -------------------- ------------------- 50.7/99.8 MB 984.5 kB/s eta 0:00:50\n",
      "   -------------------- ------------------- 50.7/99.8 MB 990.5 kB/s eta 0:00:50\n",
      "   -------------------- ------------------- 50.8/99.8 MB 990.5 kB/s eta 0:00:50\n",
      "   -------------------- ------------------- 50.8/99.8 MB 987.5 kB/s eta 0:00:50\n",
      "   -------------------- ------------------- 50.9/99.8 MB 992.0 kB/s eta 0:00:50\n",
      "   -------------------- ------------------- 50.9/99.8 MB 993.5 kB/s eta 0:00:50\n",
      "   -------------------- ------------------- 51.0/99.8 MB 993.5 kB/s eta 0:00:50\n",
      "   -------------------- ------------------- 51.1/99.8 MB 995.0 kB/s eta 0:00:49\n",
      "   -------------------- ------------------- 51.2/99.8 MB 1.0 MB/s eta 0:00:49\n",
      "   -------------------- ------------------- 51.2/99.8 MB 1.0 MB/s eta 0:00:49\n",
      "   -------------------- ------------------- 51.3/99.8 MB 1.0 MB/s eta 0:00:49\n",
      "   -------------------- ------------------- 51.3/99.8 MB 1.0 MB/s eta 0:00:49\n",
      "   -------------------- ------------------- 51.4/99.8 MB 1.0 MB/s eta 0:00:48\n",
      "   -------------------- ------------------- 51.4/99.8 MB 1.0 MB/s eta 0:00:48\n",
      "   -------------------- ------------------- 51.5/99.8 MB 1.0 MB/s eta 0:00:48\n",
      "   -------------------- ------------------- 51.6/99.8 MB 1.0 MB/s eta 0:00:47\n",
      "   -------------------- ------------------- 51.7/99.8 MB 1.0 MB/s eta 0:00:47\n",
      "   -------------------- ------------------- 51.7/99.8 MB 1.0 MB/s eta 0:00:47\n",
      "   -------------------- ------------------- 51.7/99.8 MB 1.0 MB/s eta 0:00:47\n",
      "   -------------------- ------------------- 51.8/99.8 MB 1.0 MB/s eta 0:00:47\n",
      "   -------------------- ------------------- 51.9/99.8 MB 1.0 MB/s eta 0:00:47\n",
      "   -------------------- ------------------- 51.9/99.8 MB 1.0 MB/s eta 0:00:47\n",
      "   -------------------- ------------------- 52.0/99.8 MB 1.0 MB/s eta 0:00:47\n",
      "   -------------------- ------------------- 52.0/99.8 MB 1.0 MB/s eta 0:00:47\n",
      "   -------------------- ------------------- 52.0/99.8 MB 1.0 MB/s eta 0:00:47\n",
      "   -------------------- ------------------- 52.2/99.8 MB 1.0 MB/s eta 0:00:46\n",
      "   -------------------- ------------------- 52.2/99.8 MB 1.0 MB/s eta 0:00:46\n",
      "   -------------------- ------------------- 52.3/99.8 MB 1.0 MB/s eta 0:00:46\n",
      "   -------------------- ------------------- 52.4/99.8 MB 1.0 MB/s eta 0:00:46\n",
      "   --------------------- ------------------ 52.4/99.8 MB 1.0 MB/s eta 0:00:46\n",
      "   --------------------- ------------------ 52.5/99.8 MB 1.0 MB/s eta 0:00:46\n",
      "   --------------------- ------------------ 52.6/99.8 MB 1.0 MB/s eta 0:00:46\n",
      "   --------------------- ------------------ 52.7/99.8 MB 1.0 MB/s eta 0:00:46\n",
      "   --------------------- ------------------ 52.7/99.8 MB 1.0 MB/s eta 0:00:46\n",
      "   --------------------- ------------------ 52.8/99.8 MB 1.0 MB/s eta 0:00:46\n",
      "   --------------------- ------------------ 52.9/99.8 MB 1.0 MB/s eta 0:00:45\n",
      "   --------------------- ------------------ 53.0/99.8 MB 1.0 MB/s eta 0:00:45\n",
      "   --------------------- ------------------ 53.1/99.8 MB 1.0 MB/s eta 0:00:45\n",
      "   --------------------- ------------------ 53.1/99.8 MB 1.1 MB/s eta 0:00:44\n",
      "   --------------------- ------------------ 53.2/99.8 MB 1.1 MB/s eta 0:00:44\n",
      "   --------------------- ------------------ 53.2/99.8 MB 1.1 MB/s eta 0:00:44\n",
      "   --------------------- ------------------ 53.3/99.8 MB 1.1 MB/s eta 0:00:44\n",
      "   --------------------- ------------------ 53.3/99.8 MB 1.1 MB/s eta 0:00:44\n",
      "   --------------------- ------------------ 53.4/99.8 MB 1.1 MB/s eta 0:00:44\n",
      "   --------------------- ------------------ 53.4/99.8 MB 1.1 MB/s eta 0:00:44\n",
      "   --------------------- ------------------ 53.5/99.8 MB 1.1 MB/s eta 0:00:44\n",
      "   --------------------- ------------------ 53.6/99.8 MB 1.1 MB/s eta 0:00:43\n",
      "   --------------------- ------------------ 53.6/99.8 MB 1.1 MB/s eta 0:00:43\n",
      "   --------------------- ------------------ 53.7/99.8 MB 1.1 MB/s eta 0:00:43\n",
      "   --------------------- ------------------ 53.7/99.8 MB 1.1 MB/s eta 0:00:43\n",
      "   --------------------- ------------------ 53.7/99.8 MB 1.1 MB/s eta 0:00:43\n",
      "   --------------------- ------------------ 53.7/99.8 MB 1.1 MB/s eta 0:00:43\n",
      "   --------------------- ------------------ 53.8/99.8 MB 1.1 MB/s eta 0:00:44\n",
      "   --------------------- ------------------ 53.9/99.8 MB 1.1 MB/s eta 0:00:44\n",
      "   --------------------- ------------------ 53.9/99.8 MB 1.1 MB/s eta 0:00:44\n",
      "   --------------------- ------------------ 53.9/99.8 MB 1.1 MB/s eta 0:00:44\n",
      "   --------------------- ------------------ 54.0/99.8 MB 1.1 MB/s eta 0:00:44\n",
      "   --------------------- ------------------ 54.1/99.8 MB 1.1 MB/s eta 0:00:43\n",
      "   --------------------- ------------------ 54.2/99.8 MB 1.1 MB/s eta 0:00:43\n",
      "   --------------------- ------------------ 54.3/99.8 MB 1.1 MB/s eta 0:00:43\n",
      "   --------------------- ------------------ 54.4/99.8 MB 1.1 MB/s eta 0:00:43\n",
      "   --------------------- ------------------ 54.5/99.8 MB 1.1 MB/s eta 0:00:43\n",
      "   --------------------- ------------------ 54.5/99.8 MB 1.1 MB/s eta 0:00:43\n",
      "   --------------------- ------------------ 54.6/99.8 MB 1.1 MB/s eta 0:00:42\n",
      "   --------------------- ------------------ 54.6/99.8 MB 1.1 MB/s eta 0:00:43\n",
      "   --------------------- ------------------ 54.7/99.8 MB 1.1 MB/s eta 0:00:42\n",
      "   --------------------- ------------------ 54.8/99.8 MB 1.1 MB/s eta 0:00:42\n",
      "   --------------------- ------------------ 54.8/99.8 MB 1.1 MB/s eta 0:00:42\n",
      "   --------------------- ------------------ 54.8/99.8 MB 1.1 MB/s eta 0:00:42\n",
      "   ---------------------- ----------------- 54.9/99.8 MB 1.1 MB/s eta 0:00:42\n",
      "   ---------------------- ----------------- 55.0/99.8 MB 1.1 MB/s eta 0:00:42\n",
      "   ---------------------- ----------------- 55.0/99.8 MB 1.1 MB/s eta 0:00:42\n",
      "   ---------------------- ----------------- 55.0/99.8 MB 1.1 MB/s eta 0:00:42\n",
      "   ---------------------- ----------------- 55.1/99.8 MB 1.1 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 55.2/99.8 MB 1.1 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 55.3/99.8 MB 1.1 MB/s eta 0:00:42\n",
      "   ---------------------- ----------------- 55.3/99.8 MB 1.1 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 55.3/99.8 MB 1.1 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 55.4/99.8 MB 1.1 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 55.4/99.8 MB 1.1 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 55.4/99.8 MB 1.1 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 55.5/99.8 MB 1.1 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 55.5/99.8 MB 1.1 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 55.6/99.8 MB 1.1 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 55.6/99.8 MB 1.1 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 55.7/99.8 MB 1.1 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 55.7/99.8 MB 1.1 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 55.7/99.8 MB 1.1 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 55.8/99.8 MB 1.1 MB/s eta 0:00:42\n",
      "   ---------------------- ----------------- 55.8/99.8 MB 1.1 MB/s eta 0:00:42\n",
      "   ---------------------- ----------------- 55.8/99.8 MB 1.1 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 55.9/99.8 MB 1.1 MB/s eta 0:00:42\n",
      "   ---------------------- ----------------- 56.0/99.8 MB 1.1 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 56.1/99.8 MB 1.1 MB/s eta 0:00:40\n",
      "   ---------------------- ----------------- 56.2/99.8 MB 1.1 MB/s eta 0:00:40\n",
      "   ---------------------- ----------------- 56.3/99.8 MB 1.1 MB/s eta 0:00:39\n",
      "   ---------------------- ----------------- 56.3/99.8 MB 1.1 MB/s eta 0:00:39\n",
      "   ---------------------- ----------------- 56.5/99.8 MB 1.1 MB/s eta 0:00:39\n",
      "   ---------------------- ----------------- 56.5/99.8 MB 1.1 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 56.6/99.8 MB 1.1 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 56.6/99.8 MB 1.1 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 56.7/99.8 MB 1.1 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 56.7/99.8 MB 1.1 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 56.8/99.8 MB 1.1 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 56.9/99.8 MB 1.2 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 56.9/99.8 MB 1.2 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 56.9/99.8 MB 1.1 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 57.0/99.8 MB 1.2 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 57.1/99.8 MB 1.2 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 57.2/99.8 MB 1.2 MB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 57.2/99.8 MB 1.2 MB/s eta 0:00:37\n",
      "   ---------------------- ----------------- 57.3/99.8 MB 1.1 MB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 57.3/99.8 MB 1.1 MB/s eta 0:00:38\n",
      "   ----------------------- ---------------- 57.4/99.8 MB 1.1 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 57.5/99.8 MB 1.2 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 57.5/99.8 MB 1.1 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 57.6/99.8 MB 1.2 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 57.7/99.8 MB 1.2 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 57.8/99.8 MB 1.2 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 57.8/99.8 MB 1.2 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 57.8/99.8 MB 1.2 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 57.9/99.8 MB 1.1 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 57.9/99.8 MB 1.2 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 58.0/99.8 MB 1.1 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 58.1/99.8 MB 1.2 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 58.2/99.8 MB 1.2 MB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 58.3/99.8 MB 1.2 MB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 58.3/99.8 MB 1.2 MB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 58.3/99.8 MB 1.2 MB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 58.4/99.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 58.4/99.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 58.4/99.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 58.5/99.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 58.6/99.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 58.6/99.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 58.7/99.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 58.7/99.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 58.8/99.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 58.8/99.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 58.9/99.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 58.9/99.8 MB 1.2 MB/s eta 0:00:34\n",
      "   ----------------------- ---------------- 58.9/99.8 MB 1.2 MB/s eta 0:00:34\n",
      "   ----------------------- ---------------- 59.0/99.8 MB 1.2 MB/s eta 0:00:34\n",
      "   ----------------------- ---------------- 59.0/99.8 MB 1.2 MB/s eta 0:00:34\n",
      "   ----------------------- ---------------- 59.2/99.8 MB 1.2 MB/s eta 0:00:33\n",
      "   ----------------------- ---------------- 59.2/99.8 MB 1.2 MB/s eta 0:00:33\n",
      "   ----------------------- ---------------- 59.3/99.8 MB 1.2 MB/s eta 0:00:33\n",
      "   ----------------------- ---------------- 59.4/99.8 MB 1.3 MB/s eta 0:00:33\n",
      "   ----------------------- ---------------- 59.4/99.8 MB 1.3 MB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 59.5/99.8 MB 1.3 MB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 59.6/99.8 MB 1.3 MB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 59.7/99.8 MB 1.3 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 59.7/99.8 MB 1.3 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 59.8/99.8 MB 1.3 MB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 59.8/99.8 MB 1.3 MB/s eta 0:00:31\n",
      "   ------------------------ --------------- 59.9/99.8 MB 1.3 MB/s eta 0:00:31\n",
      "   ------------------------ --------------- 59.9/99.8 MB 1.3 MB/s eta 0:00:31\n",
      "   ------------------------ --------------- 59.9/99.8 MB 1.3 MB/s eta 0:00:31\n",
      "   ------------------------ --------------- 59.9/99.8 MB 1.3 MB/s eta 0:00:32\n",
      "   ------------------------ --------------- 60.0/99.8 MB 1.3 MB/s eta 0:00:32\n",
      "   ------------------------ --------------- 60.0/99.8 MB 1.3 MB/s eta 0:00:32\n",
      "   ------------------------ --------------- 60.0/99.8 MB 1.3 MB/s eta 0:00:32\n",
      "   ------------------------ --------------- 60.0/99.8 MB 1.3 MB/s eta 0:00:32\n",
      "   ------------------------ --------------- 60.1/99.8 MB 1.3 MB/s eta 0:00:32\n",
      "   ------------------------ --------------- 60.1/99.8 MB 1.3 MB/s eta 0:00:32\n",
      "   ------------------------ --------------- 60.1/99.8 MB 1.3 MB/s eta 0:00:32\n",
      "   ------------------------ --------------- 60.1/99.8 MB 1.3 MB/s eta 0:00:32\n",
      "   ------------------------ --------------- 60.2/99.8 MB 1.2 MB/s eta 0:00:32\n",
      "   ------------------------ --------------- 60.2/99.8 MB 1.2 MB/s eta 0:00:32\n",
      "   ------------------------ --------------- 60.2/99.8 MB 1.2 MB/s eta 0:00:33\n",
      "   ------------------------ --------------- 60.3/99.8 MB 1.2 MB/s eta 0:00:33\n",
      "   ------------------------ --------------- 60.3/99.8 MB 1.2 MB/s eta 0:00:33\n",
      "   ------------------------ --------------- 60.3/99.8 MB 1.2 MB/s eta 0:00:33\n",
      "   ------------------------ --------------- 60.3/99.8 MB 1.2 MB/s eta 0:00:33\n",
      "   ------------------------ --------------- 60.4/99.8 MB 1.2 MB/s eta 0:00:33\n",
      "   ------------------------ --------------- 60.4/99.8 MB 1.2 MB/s eta 0:00:33\n",
      "   ------------------------ --------------- 60.4/99.8 MB 1.2 MB/s eta 0:00:33\n",
      "   ------------------------ --------------- 60.5/99.8 MB 1.2 MB/s eta 0:00:33\n",
      "   ------------------------ --------------- 60.5/99.8 MB 1.2 MB/s eta 0:00:33\n",
      "   ------------------------ --------------- 60.5/99.8 MB 1.2 MB/s eta 0:00:33\n",
      "   ------------------------ --------------- 60.6/99.8 MB 1.2 MB/s eta 0:00:33\n",
      "   ------------------------ --------------- 60.7/99.8 MB 1.2 MB/s eta 0:00:33\n",
      "   ------------------------ --------------- 60.7/99.8 MB 1.2 MB/s eta 0:00:33\n",
      "   ------------------------ --------------- 60.7/99.8 MB 1.2 MB/s eta 0:00:33\n",
      "   ------------------------ --------------- 60.7/99.8 MB 1.2 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 60.7/99.8 MB 1.2 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 60.8/99.8 MB 1.2 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 60.8/99.8 MB 1.2 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 60.8/99.8 MB 1.2 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 60.9/99.8 MB 1.2 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 60.9/99.8 MB 1.2 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 60.9/99.8 MB 1.2 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 61.0/99.8 MB 1.2 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 61.0/99.8 MB 1.2 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 61.0/99.8 MB 1.1 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 61.1/99.8 MB 1.1 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 61.1/99.8 MB 1.1 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 61.2/99.8 MB 1.1 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 61.2/99.8 MB 1.1 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 61.2/99.8 MB 1.1 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 61.3/99.8 MB 1.1 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 61.3/99.8 MB 1.1 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 61.3/99.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 61.3/99.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 61.3/99.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 61.4/99.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 61.4/99.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 61.4/99.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 61.4/99.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 61.4/99.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 61.5/99.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 61.5/99.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 61.5/99.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 61.6/99.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 61.6/99.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 61.6/99.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 61.7/99.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 61.7/99.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 61.7/99.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 61.7/99.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 61.8/99.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 61.8/99.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 61.8/99.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 61.9/99.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 61.9/99.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 61.9/99.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 61.9/99.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 62.0/99.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 62.0/99.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 62.1/99.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 62.1/99.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 62.1/99.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 62.1/99.8 MB 1.0 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 62.2/99.8 MB 1.0 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 62.2/99.8 MB 1.0 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 62.2/99.8 MB 1.0 MB/s eta 0:00:37\n",
      "   ------------------------ --------------- 62.2/99.8 MB 1.0 MB/s eta 0:00:37\n",
      "   ------------------------ --------------- 62.3/99.8 MB 1.0 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 62.3/99.8 MB 1.0 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 62.4/99.8 MB 1.0 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 62.4/99.8 MB 1.0 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 62.4/99.8 MB 1.0 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 62.4/99.8 MB 1.0 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 62.5/99.8 MB 1.0 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 62.5/99.8 MB 1.0 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 62.5/99.8 MB 1.0 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 62.6/99.8 MB 1.0 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 62.6/99.8 MB 1.0 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 62.6/99.8 MB 1.0 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 62.6/99.8 MB 1.0 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 62.7/99.8 MB 998.0 kB/s eta 0:00:38\n",
      "   ------------------------- -------------- 62.7/99.8 MB 996.5 kB/s eta 0:00:38\n",
      "   ------------------------- -------------- 62.7/99.8 MB 995.0 kB/s eta 0:00:38\n",
      "   ------------------------- -------------- 62.8/99.8 MB 990.4 kB/s eta 0:00:38\n",
      "   ------------------------- -------------- 62.8/99.8 MB 986.0 kB/s eta 0:00:38\n",
      "   ------------------------- -------------- 62.8/99.8 MB 989.0 kB/s eta 0:00:38\n",
      "   ------------------------- -------------- 62.8/99.8 MB 984.5 kB/s eta 0:00:38\n",
      "   ------------------------- -------------- 62.9/99.8 MB 980.1 kB/s eta 0:00:38\n",
      "   ------------------------- -------------- 62.9/99.8 MB 978.6 kB/s eta 0:00:38\n",
      "   ------------------------- -------------- 63.0/99.8 MB 975.7 kB/s eta 0:00:38\n",
      "   ------------------------- -------------- 63.0/99.8 MB 974.3 kB/s eta 0:00:38\n",
      "   ------------------------- -------------- 63.0/99.8 MB 974.3 kB/s eta 0:00:38\n",
      "   ------------------------- -------------- 63.1/99.8 MB 969.9 kB/s eta 0:00:38\n",
      "   ------------------------- -------------- 63.1/99.8 MB 967.1 kB/s eta 0:00:38\n",
      "   ------------------------- -------------- 63.1/99.8 MB 962.8 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.1/99.8 MB 962.8 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.2/99.8 MB 957.2 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.2/99.8 MB 957.2 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.2/99.8 MB 950.2 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.2/99.8 MB 950.3 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.3/99.8 MB 947.5 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.3/99.8 MB 943.4 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.3/99.8 MB 942.0 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.4/99.8 MB 939.4 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.4/99.8 MB 938.0 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.5/99.8 MB 939.4 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.5/99.8 MB 946.1 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.5/99.8 MB 946.1 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.5/99.8 MB 939.3 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.6/99.8 MB 935.2 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.7/99.8 MB 933.9 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.7/99.8 MB 934.0 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.7/99.8 MB 931.2 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.8/99.8 MB 932.7 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.8/99.8 MB 927.4 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 63.8/99.8 MB 926.0 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 64.0/99.8 MB 934.0 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 64.0/99.8 MB 939.3 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 64.0/99.8 MB 936.6 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 64.0/99.8 MB 936.6 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 64.0/99.8 MB 928.6 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 64.1/99.8 MB 924.8 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 64.1/99.8 MB 924.8 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 64.1/99.8 MB 918.3 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 64.1/99.8 MB 918.3 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 64.1/99.8 MB 918.3 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 64.1/99.8 MB 918.3 kB/s eta 0:00:39\n",
      "   ------------------------- -------------- 64.1/99.8 MB 904.3 kB/s eta 0:00:40\n",
      "   ------------------------- -------------- 64.1/99.8 MB 904.3 kB/s eta 0:00:40\n",
      "   ------------------------- -------------- 64.1/99.8 MB 898.1 kB/s eta 0:00:40\n",
      "   ------------------------- -------------- 64.1/99.8 MB 898.1 kB/s eta 0:00:40\n",
      "   ------------------------- -------------- 64.1/99.8 MB 898.1 kB/s eta 0:00:40\n",
      "   ------------------------- -------------- 64.1/99.8 MB 898.1 kB/s eta 0:00:40\n",
      "   ------------------------- -------------- 64.2/99.8 MB 888.3 kB/s eta 0:00:41\n",
      "   ------------------------- -------------- 64.2/99.8 MB 888.3 kB/s eta 0:00:41\n",
      "   ------------------------- -------------- 64.2/99.8 MB 888.3 kB/s eta 0:00:41\n",
      "   ------------------------- -------------- 64.2/99.8 MB 880.0 kB/s eta 0:00:41\n",
      "   ------------------------- -------------- 64.2/99.8 MB 878.8 kB/s eta 0:00:41\n",
      "   ------------------------- -------------- 64.2/99.8 MB 878.8 kB/s eta 0:00:41\n",
      "   ------------------------- -------------- 64.2/99.8 MB 878.8 kB/s eta 0:00:41\n",
      "   ------------------------- -------------- 64.2/99.8 MB 878.8 kB/s eta 0:00:41\n",
      "   ------------------------- -------------- 64.2/99.8 MB 878.8 kB/s eta 0:00:41\n",
      "   ------------------------- -------------- 64.2/99.8 MB 878.8 kB/s eta 0:00:41\n",
      "   ------------------------- -------------- 64.2/99.8 MB 878.8 kB/s eta 0:00:41\n",
      "   ------------------------- -------------- 64.2/99.8 MB 878.8 kB/s eta 0:00:41\n",
      "   ------------------------- -------------- 64.2/99.8 MB 878.8 kB/s eta 0:00:41\n",
      "   ------------------------- -------------- 64.2/99.8 MB 878.8 kB/s eta 0:00:41\n",
      "   ------------------------- -------------- 64.2/99.8 MB 878.8 kB/s eta 0:00:41\n",
      "   ------------------------- -------------- 64.2/99.8 MB 878.8 kB/s eta 0:00:41\n",
      "   ------------------------- -------------- 64.2/99.8 MB 878.8 kB/s eta 0:00:41\n",
      "   ------------------------- -------------- 64.2/99.8 MB 878.8 kB/s eta 0:00:41\n",
      "   ------------------------- -------------- 64.2/99.8 MB 878.8 kB/s eta 0:00:41\n",
      "   ------------------------- -------------- 64.2/99.8 MB 878.8 kB/s eta 0:00:41\n",
      "   ------------------------- -------------- 64.3/99.8 MB 825.6 kB/s eta 0:00:43\n",
      "   ------------------------- -------------- 64.3/99.8 MB 823.6 kB/s eta 0:00:44\n",
      "   ------------------------- -------------- 64.3/99.8 MB 823.6 kB/s eta 0:00:44\n",
      "   ------------------------- -------------- 64.7/99.8 MB 836.1 kB/s eta 0:00:42\n",
      "   ------------------------- -------------- 64.8/99.8 MB 834.0 kB/s eta 0:00:42\n",
      "   -------------------------- ------------- 64.8/99.8 MB 837.3 kB/s eta 0:00:42\n",
      "   -------------------------- ------------- 64.9/99.8 MB 834.0 kB/s eta 0:00:42\n",
      "   -------------------------- ------------- 64.9/99.8 MB 830.8 kB/s eta 0:00:42\n",
      "   -------------------------- ------------- 64.9/99.8 MB 829.7 kB/s eta 0:00:42\n",
      "   -------------------------- ------------- 65.0/99.8 MB 828.7 kB/s eta 0:00:42\n",
      "   -------------------------- ------------- 65.0/99.8 MB 828.7 kB/s eta 0:00:42\n",
      "   -------------------------- ------------- 65.0/99.8 MB 822.5 kB/s eta 0:00:43\n",
      "   -------------------------- ------------- 65.0/99.8 MB 819.4 kB/s eta 0:00:43\n",
      "   -------------------------- ------------- 65.0/99.8 MB 818.4 kB/s eta 0:00:43\n",
      "   -------------------------- ------------- 65.0/99.8 MB 819.4 kB/s eta 0:00:43\n",
      "   -------------------------- ------------- 65.1/99.8 MB 819.4 kB/s eta 0:00:43\n",
      "   -------------------------- ------------- 65.1/99.8 MB 819.4 kB/s eta 0:00:43\n",
      "   -------------------------- ------------- 65.1/99.8 MB 819.4 kB/s eta 0:00:43\n",
      "   -------------------------- ------------- 65.1/99.8 MB 808.3 kB/s eta 0:00:43\n",
      "   -------------------------- ------------- 65.1/99.8 MB 808.2 kB/s eta 0:00:43\n",
      "   -------------------------- ------------- 65.1/99.8 MB 805.3 kB/s eta 0:00:43\n",
      "   -------------------------- ------------- 65.2/99.8 MB 803.3 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.2/99.8 MB 801.3 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.2/99.8 MB 797.5 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.2/99.8 MB 802.3 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.3/99.8 MB 801.4 kB/s eta 0:00:43\n",
      "   -------------------------- ------------- 65.3/99.8 MB 801.4 kB/s eta 0:00:43\n",
      "   -------------------------- ------------- 65.3/99.8 MB 796.5 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.4/99.8 MB 795.5 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.4/99.8 MB 794.5 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.4/99.8 MB 791.7 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.5/99.8 MB 788.8 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.5/99.8 MB 788.8 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.5/99.8 MB 788.8 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.5/99.8 MB 784.1 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.5/99.8 MB 783.2 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.6/99.8 MB 780.4 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.6/99.8 MB 780.4 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.6/99.8 MB 779.4 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.6/99.8 MB 775.7 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.6/99.8 MB 775.7 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.7/99.8 MB 777.6 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.7/99.8 MB 777.6 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.8/99.8 MB 777.6 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.8/99.8 MB 776.7 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.9/99.8 MB 777.5 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.9/99.8 MB 776.6 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 65.9/99.8 MB 774.8 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.0/99.8 MB 776.6 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.0/99.8 MB 780.4 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.1/99.8 MB 777.5 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.1/99.8 MB 780.3 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.2/99.8 MB 780.3 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.2/99.8 MB 778.5 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.3/99.8 MB 776.6 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.3/99.8 MB 774.8 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.4/99.8 MB 773.0 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.4/99.8 MB 771.1 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.4/99.8 MB 769.3 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.5/99.8 MB 768.4 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.5/99.8 MB 767.5 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.5/99.8 MB 764.0 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.6/99.8 MB 763.0 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.6/99.8 MB 763.1 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.6/99.8 MB 760.4 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.7/99.8 MB 759.5 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.7/99.8 MB 756.9 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.7/99.8 MB 754.2 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.8/99.8 MB 752.5 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.8/99.8 MB 751.7 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.8/99.8 MB 750.8 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.9/99.8 MB 750.8 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 66.9/99.8 MB 752.6 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 67.0/99.8 MB 751.6 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 67.0/99.8 MB 751.6 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 67.0/99.8 MB 746.5 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 67.1/99.8 MB 747.4 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 67.1/99.8 MB 746.5 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 67.2/99.8 MB 748.2 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 67.2/99.8 MB 747.4 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 67.3/99.8 MB 745.7 kB/s eta 0:00:44\n",
      "   -------------------------- ------------- 67.3/99.8 MB 744.0 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 67.3/99.8 MB 744.0 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 67.4/99.8 MB 740.6 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 67.4/99.8 MB 739.8 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 67.5/99.8 MB 742.3 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 67.5/99.8 MB 740.6 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 67.5/99.8 MB 740.6 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 67.6/99.8 MB 739.8 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 67.6/99.8 MB 738.1 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 67.7/99.8 MB 737.3 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 67.8/99.8 MB 738.9 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 67.9/99.8 MB 737.3 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 67.9/99.8 MB 738.1 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 67.9/99.8 MB 737.3 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 67.9/99.8 MB 734.8 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 68.0/99.8 MB 733.2 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 68.0/99.8 MB 731.5 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 68.0/99.8 MB 731.5 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 68.0/99.8 MB 729.1 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 68.1/99.8 MB 729.0 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 68.1/99.8 MB 728.3 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 68.1/99.8 MB 726.6 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 68.1/99.8 MB 726.6 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 68.1/99.8 MB 726.6 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 68.2/99.8 MB 721.8 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 68.2/99.8 MB 719.4 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 68.2/99.8 MB 717.1 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 68.3/99.8 MB 715.5 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 68.3/99.8 MB 714.0 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.3/99.8 MB 713.2 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.4/99.8 MB 711.6 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.4/99.8 MB 710.9 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.4/99.8 MB 707.7 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.4/99.8 MB 706.2 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.4/99.8 MB 704.7 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.5/99.8 MB 702.5 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.5/99.8 MB 701.7 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.5/99.8 MB 701.0 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.5/99.8 MB 701.0 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.5/99.8 MB 700.2 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.5/99.8 MB 700.2 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.5/99.8 MB 700.2 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.5/99.8 MB 700.2 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.6/99.8 MB 692.8 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.6/99.8 MB 691.3 kB/s eta 0:00:46\n",
      "   --------------------------- ------------ 68.7/99.8 MB 692.0 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.7/99.8 MB 695.0 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.8/99.8 MB 693.5 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.8/99.8 MB 692.1 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.9/99.8 MB 692.8 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 68.9/99.8 MB 692.1 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 69.0/99.8 MB 694.3 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 69.0/99.8 MB 692.1 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 69.0/99.8 MB 690.6 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 69.1/99.8 MB 692.1 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 69.2/99.8 MB 690.6 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 69.2/99.8 MB 692.8 kB/s eta 0:00:45\n",
      "   --------------------------- ------------ 69.3/99.8 MB 692.8 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 69.3/99.8 MB 692.8 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 69.4/99.8 MB 690.6 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 69.4/99.8 MB 690.6 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 69.5/99.8 MB 689.9 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 69.5/99.8 MB 688.4 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 69.6/99.8 MB 687.0 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 69.6/99.8 MB 687.0 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 69.7/99.8 MB 687.7 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 69.7/99.8 MB 685.5 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 69.8/99.8 MB 683.4 kB/s eta 0:00:44\n",
      "   --------------------------- ------------ 69.8/99.8 MB 683.4 kB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 69.8/99.8 MB 682.7 kB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 69.9/99.8 MB 681.3 kB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 69.9/99.8 MB 680.5 kB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 70.0/99.8 MB 680.6 kB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 70.0/99.8 MB 679.1 kB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 70.1/99.8 MB 678.5 kB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 70.1/99.8 MB 681.3 kB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 70.1/99.8 MB 680.6 kB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 70.2/99.8 MB 683.4 kB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 70.2/99.8 MB 684.8 kB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 70.3/99.8 MB 687.7 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 70.3/99.8 MB 688.4 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 70.3/99.8 MB 687.7 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 70.3/99.8 MB 687.0 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 70.4/99.8 MB 687.7 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 70.4/99.8 MB 687.7 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 70.4/99.8 MB 684.1 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 70.4/99.8 MB 687.7 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 70.4/99.8 MB 687.7 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 70.4/99.8 MB 687.7 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 70.5/99.8 MB 682.0 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 70.5/99.8 MB 682.0 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 70.5/99.8 MB 682.0 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 70.5/99.8 MB 682.0 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 70.5/99.8 MB 677.0 kB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 70.5/99.8 MB 676.3 kB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 70.5/99.8 MB 676.3 kB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 70.7/99.8 MB 681.3 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 70.7/99.8 MB 683.4 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 70.8/99.8 MB 687.0 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 70.9/99.8 MB 687.0 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 70.9/99.8 MB 687.0 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 70.9/99.8 MB 684.1 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 70.9/99.8 MB 685.5 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 71.0/99.8 MB 684.9 kB/s eta 0:00:43\n",
      "   ---------------------------- ----------- 71.0/99.8 MB 684.8 kB/s eta 0:00:42\n",
      "   ---------------------------- ----------- 71.1/99.8 MB 688.5 kB/s eta 0:00:42\n",
      "   ---------------------------- ----------- 71.1/99.8 MB 692.0 kB/s eta 0:00:42\n",
      "   ---------------------------- ----------- 71.3/99.8 MB 698.7 kB/s eta 0:00:41\n",
      "   ---------------------------- ----------- 71.4/99.8 MB 698.7 kB/s eta 0:00:41\n",
      "   ---------------------------- ----------- 71.4/99.8 MB 697.2 kB/s eta 0:00:41\n",
      "   ---------------------------- ----------- 71.5/99.8 MB 697.2 kB/s eta 0:00:41\n",
      "   ---------------------------- ----------- 71.5/99.8 MB 704.8 kB/s eta 0:00:41\n",
      "   ---------------------------- ----------- 71.5/99.8 MB 705.5 kB/s eta 0:00:41\n",
      "   ---------------------------- ----------- 71.5/99.8 MB 703.2 kB/s eta 0:00:41\n",
      "   ---------------------------- ----------- 71.6/99.8 MB 702.5 kB/s eta 0:00:41\n",
      "   ---------------------------- ----------- 71.6/99.8 MB 703.3 kB/s eta 0:00:41\n",
      "   ---------------------------- ----------- 71.6/99.8 MB 704.8 kB/s eta 0:00:40\n",
      "   ---------------------------- ----------- 71.7/99.8 MB 704.7 kB/s eta 0:00:40\n",
      "   ---------------------------- ----------- 71.7/99.8 MB 707.8 kB/s eta 0:00:40\n",
      "   ---------------------------- ----------- 71.7/99.8 MB 706.2 kB/s eta 0:00:40\n",
      "   ---------------------------- ----------- 71.8/99.8 MB 706.3 kB/s eta 0:00:40\n",
      "   ---------------------------- ----------- 71.8/99.8 MB 707.0 kB/s eta 0:00:40\n",
      "   ---------------------------- ----------- 71.9/99.8 MB 710.1 kB/s eta 0:00:40\n",
      "   ---------------------------- ----------- 71.9/99.8 MB 710.8 kB/s eta 0:00:40\n",
      "   ---------------------------- ----------- 72.0/99.8 MB 717.9 kB/s eta 0:00:39\n",
      "   ---------------------------- ----------- 72.1/99.8 MB 719.5 kB/s eta 0:00:39\n",
      "   ---------------------------- ----------- 72.2/99.8 MB 725.8 kB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 72.2/99.8 MB 725.0 kB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 72.3/99.8 MB 727.5 kB/s eta 0:00:38\n",
      "   ----------------------------- ---------- 72.4/99.8 MB 733.2 kB/s eta 0:00:38\n",
      "   ----------------------------- ---------- 72.5/99.8 MB 742.3 kB/s eta 0:00:37\n",
      "   ----------------------------- ---------- 72.5/99.8 MB 739.8 kB/s eta 0:00:37\n",
      "   ----------------------------- ---------- 72.6/99.8 MB 744.8 kB/s eta 0:00:37\n",
      "   ----------------------------- ---------- 72.7/99.8 MB 750.8 kB/s eta 0:00:37\n",
      "   ----------------------------- ---------- 72.8/99.8 MB 755.1 kB/s eta 0:00:36\n",
      "   ----------------------------- ---------- 72.8/99.8 MB 756.0 kB/s eta 0:00:36\n",
      "   ----------------------------- ---------- 72.9/99.8 MB 759.6 kB/s eta 0:00:36\n",
      "   ----------------------------- ---------- 72.9/99.8 MB 763.0 kB/s eta 0:00:36\n",
      "   ----------------------------- ---------- 73.0/99.8 MB 767.5 kB/s eta 0:00:35\n",
      "   ----------------------------- ---------- 73.1/99.8 MB 772.1 kB/s eta 0:00:35\n",
      "   ----------------------------- ---------- 73.1/99.8 MB 772.1 kB/s eta 0:00:35\n",
      "   ----------------------------- ---------- 73.2/99.8 MB 772.1 kB/s eta 0:00:35\n",
      "   ----------------------------- ---------- 73.3/99.8 MB 775.7 kB/s eta 0:00:35\n",
      "   ----------------------------- ---------- 73.3/99.8 MB 778.5 kB/s eta 0:00:34\n",
      "   ----------------------------- ---------- 73.3/99.8 MB 780.4 kB/s eta 0:00:34\n",
      "   ----------------------------- ---------- 73.4/99.8 MB 778.5 kB/s eta 0:00:34\n",
      "   ----------------------------- ---------- 73.4/99.8 MB 782.2 kB/s eta 0:00:34\n",
      "   ----------------------------- ---------- 73.5/99.8 MB 780.3 kB/s eta 0:00:34\n",
      "   ----------------------------- ---------- 73.5/99.8 MB 782.2 kB/s eta 0:00:34\n",
      "   ----------------------------- ---------- 73.6/99.8 MB 785.0 kB/s eta 0:00:34\n",
      "   ----------------------------- ---------- 73.6/99.8 MB 785.9 kB/s eta 0:00:34\n",
      "   ----------------------------- ---------- 73.7/99.8 MB 786.9 kB/s eta 0:00:34\n",
      "   ----------------------------- ---------- 73.7/99.8 MB 786.9 kB/s eta 0:00:34\n",
      "   ----------------------------- ---------- 73.8/99.8 MB 790.7 kB/s eta 0:00:33\n",
      "   ----------------------------- ---------- 73.8/99.8 MB 791.7 kB/s eta 0:00:33\n",
      "   ----------------------------- ---------- 73.9/99.8 MB 788.8 kB/s eta 0:00:33\n",
      "   ----------------------------- ---------- 73.9/99.8 MB 788.8 kB/s eta 0:00:33\n",
      "   ----------------------------- ---------- 74.0/99.8 MB 789.8 kB/s eta 0:00:33\n",
      "   ----------------------------- ---------- 74.1/99.8 MB 793.6 kB/s eta 0:00:33\n",
      "   ----------------------------- ---------- 74.1/99.8 MB 793.6 kB/s eta 0:00:33\n",
      "   ----------------------------- ---------- 74.1/99.8 MB 790.7 kB/s eta 0:00:33\n",
      "   ----------------------------- ---------- 74.2/99.8 MB 787.8 kB/s eta 0:00:33\n",
      "   ----------------------------- ---------- 74.2/99.8 MB 786.9 kB/s eta 0:00:33\n",
      "   ----------------------------- ---------- 74.2/99.8 MB 786.9 kB/s eta 0:00:33\n",
      "   ----------------------------- ---------- 74.2/99.8 MB 785.0 kB/s eta 0:00:33\n",
      "   ----------------------------- ---------- 74.2/99.8 MB 783.2 kB/s eta 0:00:33\n",
      "   ----------------------------- ---------- 74.3/99.8 MB 786.9 kB/s eta 0:00:33\n",
      "   ----------------------------- ---------- 74.3/99.8 MB 786.9 kB/s eta 0:00:33\n",
      "   ----------------------------- ---------- 74.3/99.8 MB 785.0 kB/s eta 0:00:33\n",
      "   ----------------------------- ---------- 74.3/99.8 MB 798.4 kB/s eta 0:00:32\n",
      "   ----------------------------- ---------- 74.4/99.8 MB 813.3 kB/s eta 0:00:32\n",
      "   ----------------------------- ---------- 74.4/99.8 MB 820.4 kB/s eta 0:00:31\n",
      "   ----------------------------- ---------- 74.4/99.8 MB 817.3 kB/s eta 0:00:31\n",
      "   ----------------------------- ---------- 74.5/99.8 MB 866.0 kB/s eta 0:00:30\n",
      "   ----------------------------- ---------- 74.5/99.8 MB 871.8 kB/s eta 0:00:29\n",
      "   ----------------------------- ---------- 74.6/99.8 MB 870.6 kB/s eta 0:00:29\n",
      "   ----------------------------- ---------- 74.6/99.8 MB 866.0 kB/s eta 0:00:30\n",
      "   ----------------------------- ---------- 74.6/99.8 MB 862.6 kB/s eta 0:00:30\n",
      "   ----------------------------- ---------- 74.7/99.8 MB 860.4 kB/s eta 0:00:30\n",
      "   ----------------------------- ---------- 74.7/99.8 MB 858.1 kB/s eta 0:00:30\n",
      "   ----------------------------- ---------- 74.8/99.8 MB 852.5 kB/s eta 0:00:30\n",
      "   ------------------------------ --------- 74.8/99.8 MB 849.2 kB/s eta 0:00:30\n",
      "   ------------------------------ --------- 75.0/99.8 MB 845.9 kB/s eta 0:00:30\n",
      "   ------------------------------ --------- 75.0/99.8 MB 842.6 kB/s eta 0:00:30\n",
      "   ------------------------------ --------- 75.0/99.8 MB 843.7 kB/s eta 0:00:30\n",
      "   ------------------------------ --------- 75.0/99.8 MB 841.5 kB/s eta 0:00:30\n",
      "   ------------------------------ --------- 75.1/99.8 MB 839.3 kB/s eta 0:00:30\n",
      "   ------------------------------ --------- 75.1/99.8 MB 837.2 kB/s eta 0:00:30\n",
      "   ------------------------------ --------- 75.1/99.8 MB 841.5 kB/s eta 0:00:30\n",
      "   ------------------------------ --------- 75.1/99.8 MB 841.5 kB/s eta 0:00:30\n",
      "   ------------------------------ --------- 75.2/99.8 MB 845.9 kB/s eta 0:00:30\n",
      "   ------------------------------ --------- 75.2/99.8 MB 848.0 kB/s eta 0:00:29\n",
      "   ------------------------------ --------- 75.3/99.8 MB 853.6 kB/s eta 0:00:29\n",
      "   ------------------------------ --------- 75.4/99.8 MB 867.1 kB/s eta 0:00:29\n",
      "   ------------------------------ --------- 75.4/99.8 MB 869.5 kB/s eta 0:00:29\n",
      "   ------------------------------ --------- 75.4/99.8 MB 874.1 kB/s eta 0:00:28\n",
      "   ------------------------------ --------- 75.5/99.8 MB 875.2 kB/s eta 0:00:28\n",
      "   ------------------------------ --------- 75.5/99.8 MB 871.7 kB/s eta 0:00:28\n",
      "   ------------------------------ --------- 75.6/99.8 MB 877.6 kB/s eta 0:00:28\n",
      "   ------------------------------ --------- 75.6/99.8 MB 881.1 kB/s eta 0:00:28\n",
      "   ------------------------------ --------- 75.7/99.8 MB 883.6 kB/s eta 0:00:28\n",
      "   ------------------------------ --------- 75.8/99.8 MB 896.9 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 75.8/99.8 MB 900.5 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 75.9/99.8 MB 905.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 75.9/99.8 MB 901.8 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 75.9/99.8 MB 901.8 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 75.9/99.8 MB 900.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 75.9/99.8 MB 898.1 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.0/99.8 MB 895.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.0/99.8 MB 895.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.0/99.8 MB 895.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.0/99.8 MB 895.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.0/99.8 MB 895.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.0/99.8 MB 895.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.0/99.8 MB 895.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.0/99.8 MB 895.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.0/99.8 MB 895.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.0/99.8 MB 895.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.0/99.8 MB 895.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.0/99.8 MB 895.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.0/99.8 MB 895.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.0/99.8 MB 895.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.0/99.8 MB 895.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.0/99.8 MB 895.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.0/99.8 MB 895.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.0/99.8 MB 895.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.0/99.8 MB 895.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.0/99.8 MB 895.6 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.2/99.8 MB 844.8 kB/s eta 0:00:28\n",
      "   ------------------------------ --------- 76.5/99.8 MB 862.5 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.5/99.8 MB 861.5 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.5/99.8 MB 862.5 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.6/99.8 MB 860.3 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.6/99.8 MB 858.1 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.6/99.8 MB 858.1 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.7/99.8 MB 863.7 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.8/99.8 MB 866.0 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 76.9/99.8 MB 875.2 kB/s eta 0:00:27\n",
      "   ------------------------------ --------- 77.0/99.8 MB 887.2 kB/s eta 0:00:26\n",
      "   ------------------------------ --------- 77.1/99.8 MB 885.9 kB/s eta 0:00:26\n",
      "   ------------------------------ --------- 77.3/99.8 MB 899.3 kB/s eta 0:00:25\n",
      "   ------------------------------- -------- 77.4/99.8 MB 903.0 kB/s eta 0:00:25\n",
      "   ------------------------------- -------- 77.5/99.8 MB 909.3 kB/s eta 0:00:25\n",
      "   ------------------------------- -------- 77.6/99.8 MB 917.0 kB/s eta 0:00:25\n",
      "   ------------------------------- -------- 77.7/99.8 MB 923.4 kB/s eta 0:00:24\n",
      "   ------------------------------- -------- 77.8/99.8 MB 930.0 kB/s eta 0:00:24\n",
      "   ------------------------------- -------- 77.9/99.8 MB 931.3 kB/s eta 0:00:24\n",
      "   ------------------------------- -------- 78.0/99.8 MB 932.6 kB/s eta 0:00:24\n",
      "   ------------------------------- -------- 78.1/99.8 MB 931.3 kB/s eta 0:00:24\n",
      "   ------------------------------- -------- 78.2/99.8 MB 942.1 kB/s eta 0:00:23\n",
      "   ------------------------------- -------- 78.3/99.8 MB 962.8 kB/s eta 0:00:23\n",
      "   ------------------------------- -------- 78.5/99.8 MB 991.9 kB/s eta 0:00:22\n",
      "   ------------------------------- -------- 78.6/99.8 MB 994.9 kB/s eta 0:00:22\n",
      "   ------------------------------- -------- 78.7/99.8 MB 1.0 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 78.7/99.8 MB 1.0 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 78.8/99.8 MB 1.0 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 78.8/99.8 MB 1.0 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 78.8/99.8 MB 1.0 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 78.9/99.8 MB 1.0 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 78.9/99.8 MB 1.0 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 79.0/99.8 MB 1.0 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 79.1/99.8 MB 1.0 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 79.1/99.8 MB 1.0 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 79.2/99.8 MB 1.0 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 79.2/99.8 MB 1.0 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 79.3/99.8 MB 1.0 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 79.4/99.8 MB 1.0 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 79.5/99.8 MB 1.0 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 79.5/99.8 MB 1.0 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 79.6/99.8 MB 1.1 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 79.6/99.8 MB 1.1 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 79.7/99.8 MB 1.1 MB/s eta 0:00:20\n",
      "   -------------------------------- ------- 79.8/99.8 MB 1.1 MB/s eta 0:00:19\n",
      "   -------------------------------- ------- 79.8/99.8 MB 1.1 MB/s eta 0:00:19\n",
      "   -------------------------------- ------- 79.9/99.8 MB 1.1 MB/s eta 0:00:19\n",
      "   -------------------------------- ------- 80.0/99.8 MB 1.1 MB/s eta 0:00:19\n",
      "   -------------------------------- ------- 80.0/99.8 MB 1.1 MB/s eta 0:00:19\n",
      "   -------------------------------- ------- 80.1/99.8 MB 1.1 MB/s eta 0:00:19\n",
      "   -------------------------------- ------- 80.1/99.8 MB 1.1 MB/s eta 0:00:19\n",
      "   -------------------------------- ------- 80.2/99.8 MB 1.1 MB/s eta 0:00:19\n",
      "   -------------------------------- ------- 80.4/99.8 MB 1.1 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 80.4/99.8 MB 1.1 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 80.5/99.8 MB 1.1 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 80.6/99.8 MB 1.1 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 80.7/99.8 MB 1.1 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 80.7/99.8 MB 1.1 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 80.8/99.8 MB 1.2 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 80.8/99.8 MB 1.1 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 80.8/99.8 MB 1.1 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 80.8/99.8 MB 1.1 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 80.9/99.8 MB 1.1 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 80.9/99.8 MB 1.1 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 81.0/99.8 MB 1.1 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 81.0/99.8 MB 1.1 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 81.0/99.8 MB 1.1 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 81.0/99.8 MB 1.1 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 81.1/99.8 MB 1.1 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 81.2/99.8 MB 1.1 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 81.3/99.8 MB 1.1 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 81.3/99.8 MB 1.1 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 81.4/99.8 MB 1.1 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 81.5/99.8 MB 1.1 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 81.6/99.8 MB 1.1 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 81.7/99.8 MB 1.1 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 81.7/99.8 MB 1.1 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 81.8/99.8 MB 1.1 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 81.8/99.8 MB 1.1 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 81.9/99.8 MB 1.2 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 82.0/99.8 MB 1.2 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 82.0/99.8 MB 1.2 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 82.1/99.8 MB 1.2 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 82.1/99.8 MB 1.2 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 82.2/99.8 MB 1.2 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 82.2/99.8 MB 1.2 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 82.3/99.8 MB 1.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 82.4/99.8 MB 1.2 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 82.5/99.8 MB 1.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 82.5/99.8 MB 1.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 82.6/99.8 MB 1.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 82.6/99.8 MB 1.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 82.7/99.8 MB 1.1 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 82.7/99.8 MB 1.1 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 82.8/99.8 MB 1.1 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 82.9/99.8 MB 1.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 82.9/99.8 MB 1.1 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 83.0/99.8 MB 1.1 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 83.0/99.8 MB 1.1 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 83.1/99.8 MB 1.1 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 83.1/99.8 MB 1.1 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 83.2/99.8 MB 1.1 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 83.3/99.8 MB 1.1 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 83.3/99.8 MB 1.1 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 83.4/99.8 MB 1.1 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 83.5/99.8 MB 1.1 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 83.5/99.8 MB 1.1 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 83.6/99.8 MB 1.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 83.6/99.8 MB 1.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 83.6/99.8 MB 1.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 83.6/99.8 MB 1.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 83.6/99.8 MB 1.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 83.6/99.8 MB 1.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 83.6/99.8 MB 1.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 83.9/99.8 MB 1.2 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 84.0/99.8 MB 1.2 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 84.0/99.8 MB 1.2 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 84.0/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 84.1/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 84.1/99.8 MB 1.2 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 84.2/99.8 MB 1.2 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 84.2/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 84.3/99.8 MB 1.2 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 84.4/99.8 MB 1.2 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 84.5/99.8 MB 1.2 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.5/99.8 MB 1.2 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.6/99.8 MB 1.2 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.6/99.8 MB 1.2 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.6/99.8 MB 1.2 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.6/99.8 MB 1.2 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.6/99.8 MB 1.2 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.7/99.8 MB 1.2 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.7/99.8 MB 1.2 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.7/99.8 MB 1.2 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.7/99.8 MB 1.2 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.7/99.8 MB 1.2 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.7/99.8 MB 1.2 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.7/99.8 MB 1.2 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.7/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 84.7/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 84.7/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 84.7/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 84.8/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 84.8/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 84.8/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 84.9/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 84.9/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 84.9/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 84.9/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 84.9/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.0/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.0/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.0/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.0/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.0/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.0/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.0/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.1/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.1/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.1/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.1/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.2/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.2/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.2/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.3/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.3/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.3/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.3/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.4/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.4/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.4/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.4/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.4/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.5/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.5/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.6/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.7/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.7/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.7/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 85.9/99.8 MB 1.1 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 85.9/99.8 MB 1.1 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.0/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 86.0/99.8 MB 1.1 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 86.1/99.8 MB 1.1 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.1/99.8 MB 1.1 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.1/99.8 MB 1.1 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.1/99.8 MB 1.1 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.2/99.8 MB 1.2 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 86.2/99.8 MB 1.2 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 86.3/99.8 MB 1.2 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 86.3/99.8 MB 1.2 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 86.3/99.8 MB 1.2 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 86.3/99.8 MB 1.2 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 86.4/99.8 MB 1.1 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 86.4/99.8 MB 1.1 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 86.4/99.8 MB 1.1 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 86.4/99.8 MB 1.1 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 86.5/99.8 MB 1.1 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 86.5/99.8 MB 1.1 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 86.5/99.8 MB 1.1 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 86.5/99.8 MB 1.1 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 86.5/99.8 MB 1.1 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.5/99.8 MB 1.1 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.5/99.8 MB 1.1 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.5/99.8 MB 1.1 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.6/99.8 MB 1.1 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.6/99.8 MB 1.1 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.6/99.8 MB 1.1 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.6/99.8 MB 1.1 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.6/99.8 MB 1.1 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.6/99.8 MB 1.1 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.6/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.7/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.7/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.7/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.7/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.8/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.8/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.9/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.9/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 86.9/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 87.0/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 87.0/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 87.1/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 87.1/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 87.1/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 87.1/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 87.2/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 87.2/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 87.3/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 87.3/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 87.3/99.8 MB 1.0 MB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 87.4/99.8 MB 999.6 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 87.4/99.8 MB 995.0 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 87.5/99.8 MB 991.9 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 87.5/99.8 MB 989.0 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 87.5/99.8 MB 989.0 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 87.6/99.8 MB 983.1 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 87.6/99.8 MB 980.1 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 87.7/99.8 MB 975.7 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 87.7/99.8 MB 971.4 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 87.7/99.8 MB 971.4 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 87.8/99.8 MB 968.5 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 87.8/99.8 MB 964.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 87.8/99.8 MB 964.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 87.8/99.8 MB 955.8 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 87.8/99.8 MB 954.4 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 87.9/99.8 MB 950.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 87.9/99.8 MB 947.5 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.0/99.8 MB 947.5 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.0/99.8 MB 947.5 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.1/99.8 MB 942.1 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.1/99.8 MB 940.7 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.1/99.8 MB 939.4 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.1/99.8 MB 936.6 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.2/99.8 MB 936.6 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.2/99.8 MB 932.6 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.3/99.8 MB 931.2 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.4/99.8 MB 928.6 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.4/99.8 MB 927.4 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.4/99.8 MB 923.4 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.5/99.8 MB 922.1 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.5/99.8 MB 918.2 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.5/99.8 MB 917.0 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.5/99.8 MB 911.8 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.6/99.8 MB 908.1 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.7/99.8 MB 906.8 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.7/99.8 MB 904.2 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.8/99.8 MB 900.6 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.8/99.8 MB 900.6 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.8/99.8 MB 896.9 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.9/99.8 MB 894.4 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.9/99.8 MB 894.4 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.9/99.8 MB 890.7 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.9/99.8 MB 890.7 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.9/99.8 MB 890.7 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 88.9/99.8 MB 881.2 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.0/99.8 MB 877.6 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.0/99.8 MB 878.8 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.0/99.8 MB 876.4 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.0/99.8 MB 872.9 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.0/99.8 MB 870.6 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.0/99.8 MB 864.9 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.0/99.8 MB 867.1 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.1/99.8 MB 867.1 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.1/99.8 MB 867.1 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.1/99.8 MB 864.9 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.1/99.8 MB 864.9 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.2/99.8 MB 859.1 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.2/99.8 MB 859.1 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.2/99.8 MB 854.8 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.3/99.8 MB 855.8 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.4/99.8 MB 857.0 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.4/99.8 MB 858.1 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.5/99.8 MB 854.7 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.5/99.8 MB 854.7 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.5/99.8 MB 851.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.5/99.8 MB 851.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.5/99.8 MB 845.9 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.5/99.8 MB 845.9 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.6/99.8 MB 840.4 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 89.7/99.8 MB 838.3 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 89.9/99.8 MB 773.0 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 89.9/99.8 MB 773.0 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 89.9/99.8 MB 773.0 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 89.9/99.8 MB 773.0 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 89.9/99.8 MB 773.0 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 89.9/99.8 MB 762.2 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 89.9/99.8 MB 762.2 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.0/99.8 MB 756.9 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.0/99.8 MB 756.9 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.0/99.8 MB 750.8 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.2/99.8 MB 757.8 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.3/99.8 MB 760.4 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.3/99.8 MB 758.7 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.3/99.8 MB 759.5 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.4/99.8 MB 756.0 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.4/99.8 MB 756.0 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.4/99.8 MB 756.0 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.4/99.8 MB 751.7 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.4/99.8 MB 749.1 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.5/99.8 MB 748.2 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.5/99.8 MB 746.5 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.5/99.8 MB 746.5 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.5/99.8 MB 746.5 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.5/99.8 MB 746.5 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.5/99.8 MB 746.5 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.5/99.8 MB 746.5 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.5/99.8 MB 746.5 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.5/99.8 MB 746.5 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.5/99.8 MB 746.5 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.5/99.8 MB 746.5 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.5/99.8 MB 746.5 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.5/99.8 MB 746.5 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.8/99.8 MB 725.8 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.8/99.8 MB 725.8 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.8/99.8 MB 725.8 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.8/99.8 MB 719.4 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.8/99.8 MB 719.4 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.8/99.8 MB 719.4 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.8/99.8 MB 719.4 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.8/99.8 MB 711.6 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.8/99.8 MB 710.8 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.9/99.8 MB 708.5 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.9/99.8 MB 708.6 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.9/99.8 MB 707.0 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.9/99.8 MB 707.0 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.9/99.8 MB 707.0 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.9/99.8 MB 701.0 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 90.9/99.8 MB 698.0 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.0/99.8 MB 697.3 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.0/99.8 MB 697.3 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.0/99.8 MB 695.0 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.0/99.8 MB 695.0 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.0/99.8 MB 692.1 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.0/99.8 MB 692.1 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.0/99.8 MB 692.1 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.0/99.8 MB 692.1 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.0/99.8 MB 686.3 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.0/99.8 MB 686.3 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.0/99.8 MB 686.3 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.0/99.8 MB 686.3 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.1/99.8 MB 681.3 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.1/99.8 MB 677.8 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.1/99.8 MB 681.3 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.1/99.8 MB 681.3 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.2/99.8 MB 679.2 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.3/99.8 MB 682.0 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.3/99.8 MB 682.0 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.3/99.8 MB 679.2 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.3/99.8 MB 679.9 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.4/99.8 MB 676.3 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.4/99.8 MB 677.0 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.5/99.8 MB 677.1 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.6/99.8 MB 678.5 kB/s eta 0:00:13\n",
      "   ------------------------------------ --- 91.7/99.8 MB 678.5 kB/s eta 0:00:12\n",
      "   ------------------------------------ --- 91.7/99.8 MB 677.7 kB/s eta 0:00:12\n",
      "   ------------------------------------ --- 91.8/99.8 MB 678.5 kB/s eta 0:00:12\n",
      "   ------------------------------------ --- 91.9/99.8 MB 676.3 kB/s eta 0:00:12\n",
      "   ------------------------------------ --- 91.9/99.8 MB 675.6 kB/s eta 0:00:12\n",
      "   ------------------------------------ --- 92.1/99.8 MB 679.9 kB/s eta 0:00:12\n",
      "   ------------------------------------ --- 92.2/99.8 MB 682.0 kB/s eta 0:00:12\n",
      "   ------------------------------------- -- 92.3/99.8 MB 684.9 kB/s eta 0:00:11\n",
      "   ------------------------------------- -- 92.5/99.8 MB 688.5 kB/s eta 0:00:11\n",
      "   ------------------------------------- -- 92.5/99.8 MB 687.0 kB/s eta 0:00:11\n",
      "   ------------------------------------- -- 92.6/99.8 MB 689.2 kB/s eta 0:00:11\n",
      "   ------------------------------------- -- 92.7/99.8 MB 689.9 kB/s eta 0:00:11\n",
      "   ------------------------------------- -- 92.7/99.8 MB 689.2 kB/s eta 0:00:11\n",
      "   ------------------------------------- -- 92.8/99.8 MB 689.2 kB/s eta 0:00:11\n",
      "   ------------------------------------- -- 92.8/99.8 MB 687.0 kB/s eta 0:00:11\n",
      "   ------------------------------------- -- 92.8/99.8 MB 687.0 kB/s eta 0:00:11\n",
      "   ------------------------------------- -- 92.9/99.8 MB 687.0 kB/s eta 0:00:10\n",
      "   ------------------------------------- -- 92.9/99.8 MB 687.7 kB/s eta 0:00:10\n",
      "   ------------------------------------- -- 93.0/99.8 MB 685.5 kB/s eta 0:00:10\n",
      "   ------------------------------------- -- 93.0/99.8 MB 685.5 kB/s eta 0:00:10\n",
      "   ------------------------------------- -- 93.0/99.8 MB 683.4 kB/s eta 0:00:10\n",
      "   ------------------------------------- -- 93.0/99.8 MB 679.9 kB/s eta 0:00:10\n",
      "   ------------------------------------- -- 93.1/99.8 MB 679.9 kB/s eta 0:00:10\n",
      "   ------------------------------------- -- 93.1/99.8 MB 679.1 kB/s eta 0:00:10\n",
      "   ------------------------------------- -- 93.2/99.8 MB 680.6 kB/s eta 0:00:10\n",
      "   ------------------------------------- -- 93.2/99.8 MB 681.3 kB/s eta 0:00:10\n",
      "   ------------------------------------- -- 93.3/99.8 MB 681.3 kB/s eta 0:00:10\n",
      "   ------------------------------------- -- 93.4/99.8 MB 681.3 kB/s eta 0:00:10\n",
      "   ------------------------------------- -- 93.4/99.8 MB 681.3 kB/s eta 0:00:10\n",
      "   ------------------------------------- -- 93.5/99.8 MB 682.0 kB/s eta 0:00:10\n",
      "   ------------------------------------- -- 93.6/99.8 MB 681.3 kB/s eta 0:00:10\n",
      "   ------------------------------------- -- 93.6/99.8 MB 679.1 kB/s eta 0:00:10\n",
      "   ------------------------------------- -- 93.6/99.8 MB 679.1 kB/s eta 0:00:10\n",
      "   ------------------------------------- -- 93.6/99.8 MB 676.3 kB/s eta 0:00:10\n",
      "   ------------------------------------- -- 93.7/99.8 MB 676.3 kB/s eta 0:00:10\n",
      "   ------------------------------------- -- 93.7/99.8 MB 676.3 kB/s eta 0:00:09\n",
      "   ------------------------------------- -- 93.8/99.8 MB 675.0 kB/s eta 0:00:09\n",
      "   ------------------------------------- -- 93.8/99.8 MB 672.9 kB/s eta 0:00:09\n",
      "   ------------------------------------- -- 93.8/99.8 MB 685.5 kB/s eta 0:00:09\n",
      "   ------------------------------------- -- 93.9/99.8 MB 683.4 kB/s eta 0:00:09\n",
      "   ------------------------------------- -- 94.0/99.8 MB 680.6 kB/s eta 0:00:09\n",
      "   ------------------------------------- -- 94.0/99.8 MB 678.5 kB/s eta 0:00:09\n",
      "   ------------------------------------- -- 94.2/99.8 MB 677.1 kB/s eta 0:00:09\n",
      "   ------------------------------------- -- 94.3/99.8 MB 679.9 kB/s eta 0:00:09\n",
      "   ------------------------------------- -- 94.3/99.8 MB 682.0 kB/s eta 0:00:08\n",
      "   ------------------------------------- -- 94.4/99.8 MB 683.4 kB/s eta 0:00:08\n",
      "   ------------------------------------- -- 94.4/99.8 MB 680.6 kB/s eta 0:00:08\n",
      "   ------------------------------------- -- 94.4/99.8 MB 680.6 kB/s eta 0:00:08\n",
      "   ------------------------------------- -- 94.5/99.8 MB 679.9 kB/s eta 0:00:08\n",
      "   ------------------------------------- -- 94.5/99.8 MB 679.9 kB/s eta 0:00:08\n",
      "   ------------------------------------- -- 94.5/99.8 MB 679.9 kB/s eta 0:00:08\n",
      "   ------------------------------------- -- 94.5/99.8 MB 679.9 kB/s eta 0:00:08\n",
      "   ------------------------------------- -- 94.5/99.8 MB 679.9 kB/s eta 0:00:08\n",
      "   ------------------------------------- -- 94.5/99.8 MB 679.9 kB/s eta 0:00:08\n",
      "   ------------------------------------- -- 94.5/99.8 MB 679.9 kB/s eta 0:00:08\n",
      "   ------------------------------------- -- 94.7/99.8 MB 670.8 kB/s eta 0:00:08\n",
      "   ------------------------------------- -- 94.7/99.8 MB 670.1 kB/s eta 0:00:08\n",
      "   ------------------------------------- -- 94.7/99.8 MB 670.1 kB/s eta 0:00:08\n",
      "   -------------------------------------- - 94.8/99.8 MB 666.7 kB/s eta 0:00:08\n",
      "   -------------------------------------- - 94.8/99.8 MB 666.7 kB/s eta 0:00:08\n",
      "   -------------------------------------- - 94.8/99.8 MB 666.7 kB/s eta 0:00:08\n",
      "   -------------------------------------- - 95.0/99.8 MB 690.6 kB/s eta 0:00:07\n",
      "   -------------------------------------- - 95.0/99.8 MB 696.5 kB/s eta 0:00:07\n",
      "   -------------------------------------- - 95.0/99.8 MB 696.5 kB/s eta 0:00:07\n",
      "   -------------------------------------- - 95.1/99.8 MB 698.0 kB/s eta 0:00:07\n",
      "   -------------------------------------- - 95.2/99.8 MB 703.9 kB/s eta 0:00:07\n",
      "   -------------------------------------- - 95.2/99.8 MB 708.5 kB/s eta 0:00:07\n",
      "   -------------------------------------- - 95.3/99.8 MB 717.9 kB/s eta 0:00:07\n",
      "   -------------------------------------- - 95.3/99.8 MB 720.3 kB/s eta 0:00:07\n",
      "   -------------------------------------- - 95.4/99.8 MB 718.6 kB/s eta 0:00:07\n",
      "   -------------------------------------- - 95.4/99.8 MB 721.0 kB/s eta 0:00:06\n",
      "   -------------------------------------- - 95.5/99.8 MB 721.0 kB/s eta 0:00:06\n",
      "   -------------------------------------- - 95.5/99.8 MB 722.6 kB/s eta 0:00:06\n",
      "   -------------------------------------- - 95.5/99.8 MB 724.2 kB/s eta 0:00:06\n",
      "   -------------------------------------- - 95.5/99.8 MB 724.2 kB/s eta 0:00:06\n",
      "   -------------------------------------- - 95.5/99.8 MB 724.2 kB/s eta 0:00:06\n",
      "   -------------------------------------- - 95.5/99.8 MB 724.2 kB/s eta 0:00:06\n",
      "   -------------------------------------- - 95.7/99.8 MB 729.9 kB/s eta 0:00:06\n",
      "   -------------------------------------- - 95.8/99.8 MB 729.1 kB/s eta 0:00:06\n",
      "   -------------------------------------- - 95.8/99.8 MB 729.0 kB/s eta 0:00:06\n",
      "   -------------------------------------- - 95.9/99.8 MB 728.3 kB/s eta 0:00:06\n",
      "   -------------------------------------- - 95.9/99.8 MB 732.4 kB/s eta 0:00:06\n",
      "   -------------------------------------- - 96.0/99.8 MB 729.9 kB/s eta 0:00:06\n",
      "   -------------------------------------- - 96.1/99.8 MB 727.5 kB/s eta 0:00:06\n",
      "   -------------------------------------- - 96.1/99.8 MB 726.6 kB/s eta 0:00:06\n",
      "   -------------------------------------- - 96.2/99.8 MB 729.1 kB/s eta 0:00:05\n",
      "   -------------------------------------- - 96.3/99.8 MB 729.0 kB/s eta 0:00:05\n",
      "   -------------------------------------- - 96.3/99.8 MB 728.3 kB/s eta 0:00:05\n",
      "   -------------------------------------- - 96.3/99.8 MB 728.3 kB/s eta 0:00:05\n",
      "   -------------------------------------- - 96.5/99.8 MB 735.6 kB/s eta 0:00:05\n",
      "   -------------------------------------- - 96.5/99.8 MB 734.8 kB/s eta 0:00:05\n",
      "   -------------------------------------- - 96.5/99.8 MB 737.3 kB/s eta 0:00:05\n",
      "   -------------------------------------- - 96.6/99.8 MB 739.0 kB/s eta 0:00:05\n",
      "   -------------------------------------- - 96.6/99.8 MB 738.1 kB/s eta 0:00:05\n",
      "   -------------------------------------- - 96.6/99.8 MB 736.5 kB/s eta 0:00:05\n",
      "   -------------------------------------- - 96.7/99.8 MB 739.8 kB/s eta 0:00:05\n",
      "   -------------------------------------- - 96.7/99.8 MB 742.3 kB/s eta 0:00:05\n",
      "   -------------------------------------- - 96.7/99.8 MB 745.7 kB/s eta 0:00:05\n",
      "   -------------------------------------- - 96.7/99.8 MB 745.7 kB/s eta 0:00:05\n",
      "   -------------------------------------- - 96.8/99.8 MB 750.8 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 96.8/99.8 MB 754.2 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 96.8/99.8 MB 760.4 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 96.9/99.8 MB 762.2 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 96.9/99.8 MB 762.2 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 96.9/99.8 MB 764.8 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 97.0/99.8 MB 766.6 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 97.0/99.8 MB 767.5 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 97.1/99.8 MB 766.6 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 97.1/99.8 MB 764.8 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 97.1/99.8 MB 764.8 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 97.1/99.8 MB 762.2 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 97.2/99.8 MB 763.0 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 97.2/99.8 MB 763.9 kB/s eta 0:00:04\n",
      "   ---------------------------------------  97.3/99.8 MB 764.8 kB/s eta 0:00:04\n",
      "   ---------------------------------------  97.3/99.8 MB 768.5 kB/s eta 0:00:04\n",
      "   ---------------------------------------  97.3/99.8 MB 769.3 kB/s eta 0:00:04\n",
      "   ---------------------------------------  97.3/99.8 MB 769.3 kB/s eta 0:00:04\n",
      "   ---------------------------------------  97.4/99.8 MB 764.8 kB/s eta 0:00:04\n",
      "   ---------------------------------------  97.4/99.8 MB 764.0 kB/s eta 0:00:04\n",
      "   ---------------------------------------  97.4/99.8 MB 764.8 kB/s eta 0:00:04\n",
      "   ---------------------------------------  97.5/99.8 MB 763.0 kB/s eta 0:00:04\n",
      "   ---------------------------------------  97.5/99.8 MB 764.0 kB/s eta 0:00:03\n",
      "   ---------------------------------------  97.6/99.8 MB 763.1 kB/s eta 0:00:03\n",
      "   ---------------------------------------  97.6/99.8 MB 764.8 kB/s eta 0:00:03\n",
      "   ---------------------------------------  97.6/99.8 MB 763.1 kB/s eta 0:00:03\n",
      "   ---------------------------------------  97.6/99.8 MB 763.1 kB/s eta 0:00:03\n",
      "   ---------------------------------------  97.6/99.8 MB 763.1 kB/s eta 0:00:03\n",
      "   ---------------------------------------  97.7/99.8 MB 756.0 kB/s eta 0:00:03\n",
      "   ---------------------------------------  97.7/99.8 MB 755.1 kB/s eta 0:00:03\n",
      "   ---------------------------------------  97.7/99.8 MB 752.6 kB/s eta 0:00:03\n",
      "   ---------------------------------------  97.8/99.8 MB 753.4 kB/s eta 0:00:03\n",
      "   ---------------------------------------  97.8/99.8 MB 754.3 kB/s eta 0:00:03\n",
      "   ---------------------------------------  97.8/99.8 MB 755.1 kB/s eta 0:00:03\n",
      "   ---------------------------------------  97.9/99.8 MB 756.9 kB/s eta 0:00:03\n",
      "   ---------------------------------------  97.9/99.8 MB 757.8 kB/s eta 0:00:03\n",
      "   ---------------------------------------  98.0/99.8 MB 757.8 kB/s eta 0:00:03\n",
      "   ---------------------------------------  98.0/99.8 MB 756.9 kB/s eta 0:00:03\n",
      "   ---------------------------------------  98.1/99.8 MB 761.3 kB/s eta 0:00:03\n",
      "   ---------------------------------------  98.1/99.8 MB 760.4 kB/s eta 0:00:03\n",
      "   ---------------------------------------  98.1/99.8 MB 760.4 kB/s eta 0:00:03\n",
      "   ---------------------------------------  98.1/99.8 MB 758.7 kB/s eta 0:00:03\n",
      "   ---------------------------------------  98.2/99.8 MB 759.6 kB/s eta 0:00:03\n",
      "   ---------------------------------------  98.2/99.8 MB 759.5 kB/s eta 0:00:03\n",
      "   ---------------------------------------  98.2/99.8 MB 756.0 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.3/99.8 MB 758.6 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.3/99.8 MB 756.9 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.4/99.8 MB 759.5 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.4/99.8 MB 757.8 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.5/99.8 MB 760.4 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.5/99.8 MB 759.6 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.5/99.8 MB 758.6 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.6/99.8 MB 756.9 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.6/99.8 MB 756.0 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.6/99.8 MB 755.2 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.7/99.8 MB 756.0 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.7/99.8 MB 759.5 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.7/99.8 MB 759.6 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.8/99.8 MB 758.7 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.8/99.8 MB 756.0 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.8/99.8 MB 756.0 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.8/99.8 MB 752.5 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.8/99.8 MB 750.8 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.9/99.8 MB 748.2 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.9/99.8 MB 747.4 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.9/99.8 MB 747.4 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.9/99.8 MB 747.4 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.9/99.8 MB 747.4 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.9/99.8 MB 740.6 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.9/99.8 MB 740.6 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.9/99.8 MB 736.4 kB/s eta 0:00:02\n",
      "   ---------------------------------------  98.9/99.8 MB 736.4 kB/s eta 0:00:02\n",
      "   ---------------------------------------  99.0/99.8 MB 731.5 kB/s eta 0:00:02\n",
      "   ---------------------------------------  99.0/99.8 MB 731.5 kB/s eta 0:00:02\n",
      "   ---------------------------------------  99.0/99.8 MB 726.6 kB/s eta 0:00:02\n",
      "   ---------------------------------------  99.0/99.8 MB 726.6 kB/s eta 0:00:02\n",
      "   ---------------------------------------  99.0/99.8 MB 725.8 kB/s eta 0:00:02\n",
      "   ---------------------------------------  99.0/99.8 MB 725.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.0/99.8 MB 723.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.0/99.8 MB 723.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.1/99.8 MB 719.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.1/99.8 MB 721.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.1/99.8 MB 721.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.1/99.8 MB 717.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.2/99.8 MB 722.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.2/99.8 MB 722.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.2/99.8 MB 721.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.2/99.8 MB 719.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.2/99.8 MB 718.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.2/99.8 MB 718.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.2/99.8 MB 718.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.2/99.8 MB 718.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.2/99.8 MB 718.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.2/99.8 MB 712.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.2/99.8 MB 712.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.3/99.8 MB 711.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.3/99.8 MB 712.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.3/99.8 MB 710.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.3/99.8 MB 709.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.3/99.8 MB 709.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.4/99.8 MB 713.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.4/99.8 MB 712.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.4/99.8 MB 714.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.4/99.8 MB 714.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.4/99.8 MB 710.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.4/99.8 MB 708.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.5/99.8 MB 706.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.5/99.8 MB 704.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.5/99.8 MB 703.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.5/99.8 MB 701.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.5/99.8 MB 701.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.5/99.8 MB 701.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.5/99.8 MB 701.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.6/99.8 MB 694.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.6/99.8 MB 694.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.6/99.8 MB 691.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.6/99.8 MB 689.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.6/99.8 MB 687.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.6/99.8 MB 686.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 685.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 687.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 686.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 684.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 640.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 640.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 640.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 640.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 640.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 640.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 640.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 640.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 640.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 640.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 640.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 99.8/99.8 MB 620.7 kB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n",
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e0ca179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes (Filtered): ['hr' 'ai' 'r' 'content creation' 'excel' 'research' 'market research'\n",
      " 'proto' 'seo' 'aws' 'sql' 'rest' 'python' 'react' 'tableau' 'power bi'\n",
      " 'java' 'javascript' 'b2b']\n",
      "Counts per Class (Filtered):\n",
      "r                   136\n",
      "ai                  110\n",
      "research             44\n",
      "excel                27\n",
      "hr                   19\n",
      "market research      19\n",
      "rest                 15\n",
      "sql                  14\n",
      "python                7\n",
      "aws                   7\n",
      "content creation      6\n",
      "proto                 5\n",
      "react                 5\n",
      "java                  4\n",
      "javascript            4\n",
      "b2b                   3\n",
      "seo                   2\n",
      "tableau               2\n",
      "power bi              2\n",
      "Name: skills, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6d6c9fd3644e4d9b8bc774cb9c6946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   2%|2         | 10.5M/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "RandomForestClassifier\n",
      "F1 Score (Micro): 0.7283950617283951\n",
      "Hamming Loss: 0.08270676691729323\n",
      "Accuracy Score: 0.25\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "value 0 for Parameter num_class should be greater equal to 1\nnum_class: Number of output class in the multi-class classification.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 169\u001b[0m\n\u001b[0;32m    167\u001b[0m xgb \u001b[38;5;241m=\u001b[39m XGBClassifier(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti:softprob\u001b[39m\u001b[38;5;124m'\u001b[39m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    168\u001b[0m model_xgb \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(xgb)\n\u001b[1;32m--> 169\u001b[0m \u001b[43mmodel_xgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# Predict on the test set using XGBoost\u001b[39;00m\n\u001b[0;32m    172\u001b[0m y_pred_xgb \u001b[38;5;241m=\u001b[39m model_xgb\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:1519\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1491\u001b[0m (\n\u001b[0;32m   1492\u001b[0m     model,\n\u001b[0;32m   1493\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1499\u001b[0m )\n\u001b[0;32m   1500\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1501\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1502\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1517\u001b[0m )\n\u001b[1;32m-> 1519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1531\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:2050\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2050\u001b[0m     \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2051\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2054\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:282\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \n\u001b[0;32m    273\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: value 0 for Parameter num_class should be greater equal to 1\nnum_class: Number of output class in the multi-class classification."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Fill NaN values with empty strings in the relevant column\n",
    "data['role_description'].fillna('', inplace=True)\n",
    "\n",
    "# Function for text cleaning with stemming and lemmatization\n",
    "def preprocess_text(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove all non-word characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple whitespace with single space\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    tokens = [lemmatizer.lemmatize(stemmer.stem(word)) for word in tokens if word not in stopwords.words('english')]  # Stem and lemmatize, remove stopwords\n",
    "    return ' '.join(tokens)  # Join tokens back into a single string\n",
    "\n",
    "# Apply preprocessing to the role_description column\n",
    "data['cleaned_text'] = data['role_description'].apply(preprocess_text)\n",
    "\n",
    "# Define the skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction to the cleaned_text column\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Count the number of samples per class (skill)\n",
    "class_counts = data['skills'].explode().value_counts()\n",
    "\n",
    "# Filter classes with at least two samples\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "\n",
    "# Filter data to keep only samples with valid classes\n",
    "data_filtered = data[data['skills'].apply(lambda x: any(skill in valid_classes for skill in x))]\n",
    "\n",
    "# Remove samples belonging to classes with only one sample\n",
    "data_filtered = data_filtered[data_filtered['skills'].apply(lambda x: len(x) > 1)]\n",
    "\n",
    "# Filter out outliers and delete them\n",
    "outlier_classes = class_counts[class_counts < 2].index\n",
    "data_filtered['skills'] = data_filtered['skills'].apply(lambda x: [skill for skill in x if skill not in outlier_classes])\n",
    "\n",
    "# Reset index after deleting rows\n",
    "data_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert filtered data to features and labels\n",
    "X_filtered = data_filtered['cleaned_text']\n",
    "y_filtered = data_filtered.drop(columns=['cleaned_text'])\n",
    "\n",
    "# Ensure there are at least two unique classes present after filtering again\n",
    "unique_classes_filtered = data_filtered['skills'].explode().unique()\n",
    "if len(unique_classes_filtered) < 2:\n",
    "    print(\"There are not enough unique classes present in the filtered data after removing classes with fewer than two samples.\")\n",
    "else:\n",
    "    # Print unique classes and their counts\n",
    "    print(\"Unique Classes (Filtered):\", unique_classes_filtered)\n",
    "    print(\"Counts per Class (Filtered):\")\n",
    "    print(data_filtered['skills'].explode().value_counts())\n",
    "\n",
    "    # Transform skills into binary labels\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    labels = mlb.fit_transform(data_filtered['skills'])\n",
    "\n",
    "    # TF-IDF Vectorization with trigrams\n",
    "    vectorizer = TfidfVectorizer(max_features=3000, ngram_range=(1, 3), lowercase=False)\n",
    "    X_tfidf = vectorizer.fit_transform(data_filtered['cleaned_text'])\n",
    "\n",
    "    # Load BERT model and tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Function to extract BERT embeddings\n",
    "    def get_bert_embeddings(text):\n",
    "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        outputs = bert_model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "        return embeddings\n",
    "\n",
    "    # Apply BERT embeddings to the cleaned_text column\n",
    "    X_bert = np.array([get_bert_embeddings(text) for text in data_filtered['cleaned_text']])\n",
    "    X_bert = np.squeeze(X_bert)\n",
    "\n",
    "    # Combine TF-IDF and BERT embeddings\n",
    "    X_combined = np.hstack((X_tfidf.toarray(), X_bert))\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_combined, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the model with RandomForestClassifier\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    # Define the parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best model\n",
    "    best_rf = grid_search.best_estimator_\n",
    "\n",
    "    # Train a multi-label classifier on filtered data using the best RandomForestClassifier\n",
    "    model_rf = MultiOutputClassifier(best_rf)\n",
    "    model_rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set using RandomForestClassifier\n",
    "    y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "    # Evaluate the RandomForestClassifier model\n",
    "    f1_rf = f1_score(y_test, y_pred_rf, average='micro')\n",
    "    hamming_rf = hamming_loss(y_test, y_pred_rf)\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "    print(\"RandomForestClassifier\")\n",
    "    print(\"F1 Score (Micro):\", f1_rf)\n",
    "    print(\"Hamming Loss:\", hamming_rf)\n",
    "    print(\"Accuracy Score:\", accuracy_rf)\n",
    "\n",
    "    # Train a multi-label classifier on filtered data using XGBoost\n",
    "    xgb = XGBClassifier(objective='multi:softprob', eval_metric='mlogloss')\n",
    "    model_xgb = MultiOutputClassifier(xgb)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set using XGBoost\n",
    "    y_pred_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "    # Evaluate the XGBoost model\n",
    "    f1_xgb = f1_score(y_test, y_pred_xgb, average='micro')\n",
    "    hamming_xgb = hamming_loss(y_test, y_pred_xgb)\n",
    "    accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "\n",
    "    print(\"XGBoost\")\n",
    "    print(\"F1 Score (Micro):\", f1_xgb)\n",
    "    print(\"Hamming Loss:\", hamming_xgb)\n",
    "    print(\"Accuracy Score:\", accuracy_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49e44445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "RandomForestClassifier\n",
      "F1 Score (Micro): 0.804733727810651\n",
      "Hamming Loss: 0.040993788819875775\n",
      "Accuracy Score: 0.4\n",
      "XGBoost\n",
      "F1 Score (Micro): 0.9060773480662984\n",
      "Hamming Loss: 0.02111801242236025\n",
      "Accuracy Score: 0.6285714285714286\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Function for text cleaning with stemming and lemmatization\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):  # Check if the input is a string\n",
    "        stemmer = PorterStemmer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        text = re.sub(r'\\W', ' ', text)  # Remove all non-word characters\n",
    "        text = re.sub(r'\\s+', ' ', text)  # Replace multiple whitespace with single space\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        tokens = word_tokenize(text)  # Tokenize the text\n",
    "        tokens = [lemmatizer.lemmatize(stemmer.stem(word)) for word in tokens if word not in stopwords.words('english')]  # Stem and lemmatize, remove stopwords\n",
    "        return ' '.join(tokens)  # Join tokens back into a single string\n",
    "    else:\n",
    "        return \"\"  # Return an empty string if the input is not a string\n",
    "\n",
    "# Apply preprocessing to the role_description column\n",
    "data['cleaned_text'] = data['role_description'].apply(preprocess_text)\n",
    "\n",
    "# Define the skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction to the cleaned_text column\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Convert skills into binary labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(data['skills'])\n",
    "\n",
    "# TF-IDF Vectorization with trigrams\n",
    "vectorizer = TfidfVectorizer(max_features=3000, ngram_range=(1, 3), lowercase=False)\n",
    "X_tfidf = vectorizer.fit_transform(data['cleaned_text'])\n",
    "\n",
    "# Load BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to extract BERT embeddings\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    outputs = bert_model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "    return embeddings\n",
    "\n",
    "# Apply BERT embeddings to the cleaned_text column\n",
    "X_bert = np.array([get_bert_embeddings(text) for text in data['cleaned_text']])\n",
    "X_bert = np.squeeze(X_bert)\n",
    "\n",
    "# Combine TF-IDF and BERT embeddings\n",
    "X_combined = np.hstack((X_tfidf.toarray(), X_bert))\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model with RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Train a multi-label classifier on filtered data using the best RandomForestClassifier\n",
    "model_rf = MultiOutputClassifier(best_rf)\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using RandomForestClassifier\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the RandomForestClassifier model\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='micro')\n",
    "hamming_rf = hamming_loss(y_test, y_pred_rf)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"RandomForestClassifier\")\n",
    "print(\"F1 Score (Micro):\", f1_rf)\n",
    "print(\"Hamming Loss:\", hamming_rf)\n",
    "print(\"Accuracy Score:\", accuracy_rf)\n",
    "\n",
    "# Train a multi-label classifier on filtered data using XGBoost\n",
    "xgb = XGBClassifier(objective='binary:logistic')\n",
    "model_xgb = MultiOutputClassifier(xgb)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using XGBoost\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "# Evaluate the XGBoost model\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb, average='micro')\n",
    "hamming_xgb = hamming_loss(y_test, y_pred_xgb)\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"XGBoost\")\n",
    "print(\"F1 Score (Micro):\", f1_xgb)\n",
    "print(\"Hamming Loss:\", hamming_xgb)\n",
    "print(\"Accuracy Score:\", accuracy_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8cb2880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 91\u001b[0m\n\u001b[0;32m     88\u001b[0m cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     90\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mxgb, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39mcv, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 91\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Best model\u001b[39;00m\n\u001b[0;32m     94\u001b[0m best_xgb \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:833\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[0;32m    821\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[1;32m--> 833\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:352\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    346\u001b[0m         (\n\u001b[0;32m    347\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    348\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    349\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[0;32m    350\u001b[0m     )\n\u001b[1;32m--> 352\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:85\u001b[0m, in \u001b[0;36mBaseCrossValidator.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m     83\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m     84\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(_num_samples(X))\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_test_masks(X, y, groups):\n\u001b[0;32m     86\u001b[0m     train_index \u001b[38;5;241m=\u001b[39m indices[np\u001b[38;5;241m.\u001b[39mlogical_not(test_index)]\n\u001b[0;32m     87\u001b[0m     test_index \u001b[38;5;241m=\u001b[39m indices[test_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:733\u001b[0m, in \u001b[0;36mStratifiedKFold._iter_test_masks\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_test_masks\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 733\u001b[0m     test_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_test_folds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits):\n\u001b[0;32m    735\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m test_folds \u001b[38;5;241m==\u001b[39m i\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676\u001b[0m, in \u001b[0;36mStratifiedKFold._make_test_folds\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    674\u001b[0m allowed_target_types \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_of_target_y \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_target_types:\n\u001b[1;32m--> 676\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    677\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported target types are: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    678\u001b[0m             allowed_target_types, type_of_target_y\n\u001b[0;32m    679\u001b[0m         )\n\u001b[0;32m    680\u001b[0m     )\n\u001b[0;32m    682\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y)\n\u001b[0;32m    684\u001b[0m _, y_idx, y_inv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y, return_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Function for text cleaning with stemming and lemmatization\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):  # Check if the input is a string\n",
    "        stemmer = PorterStemmer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        text = re.sub(r'\\W', ' ', text)  # Remove all non-word characters\n",
    "        text = re.sub(r'\\s+', ' ', text)  # Replace multiple whitespace with single space\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        tokens = word_tokenize(text)  # Tokenize the text\n",
    "        tokens = [lemmatizer.lemmatize(stemmer.stem(word)) for word in tokens if word not in stopwords.words('english')]  # Stem and lemmatize, remove stopwords\n",
    "        return ' '.join(tokens)  # Join tokens back into a single string\n",
    "    else:\n",
    "        return \"\"  # Return an empty string if the input is not a string\n",
    "\n",
    "# Apply preprocessing to the role_description column\n",
    "data['cleaned_text'] = data['role_description'].apply(preprocess_text)\n",
    "\n",
    "# Define the skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction to the cleaned_text column\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Convert skills into binary labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(data['skills'])\n",
    "\n",
    "# TF-IDF Vectorization with trigrams\n",
    "vectorizer = TfidfVectorizer(max_features=3000, ngram_range=(1, 3), lowercase=False)\n",
    "X_tfidf = vectorizer.fit_transform(data['cleaned_text'])\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the XGBoost classifier\n",
    "xgb = XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3]\n",
    "}\n",
    "\n",
    "# Perform grid search with stratified k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "# Train the best XGBoost model\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "# Evaluate the XGBoost model\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb, average='micro')\n",
    "hamming_xgb = hamming_loss(y_test, y_pred_xgb)\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"XGBoost (with Grid Search and Stratified K-Fold CV)\")\n",
    "print(\"F1 Score (Micro):\", f1_xgb)\n",
    "print(\"Hamming Loss:\", hamming_xgb)\n",
    "print(\"Accuracy Score:\", accuracy_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d366df1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 99\u001b[0m\n\u001b[0;32m     96\u001b[0m cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     98\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mxgb, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39mcv, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 99\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Best model for binary classification\u001b[39;00m\n\u001b[0;32m    102\u001b[0m best_xgb \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:833\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[0;32m    821\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[1;32m--> 833\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:352\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    346\u001b[0m         (\n\u001b[0;32m    347\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    348\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    349\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[0;32m    350\u001b[0m     )\n\u001b[1;32m--> 352\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:85\u001b[0m, in \u001b[0;36mBaseCrossValidator.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m     83\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m     84\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(_num_samples(X))\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_test_masks(X, y, groups):\n\u001b[0;32m     86\u001b[0m     train_index \u001b[38;5;241m=\u001b[39m indices[np\u001b[38;5;241m.\u001b[39mlogical_not(test_index)]\n\u001b[0;32m     87\u001b[0m     test_index \u001b[38;5;241m=\u001b[39m indices[test_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:733\u001b[0m, in \u001b[0;36mStratifiedKFold._iter_test_masks\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_test_masks\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 733\u001b[0m     test_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_test_folds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits):\n\u001b[0;32m    735\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m test_folds \u001b[38;5;241m==\u001b[39m i\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676\u001b[0m, in \u001b[0;36mStratifiedKFold._make_test_folds\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    674\u001b[0m allowed_target_types \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_of_target_y \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_target_types:\n\u001b[1;32m--> 676\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    677\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported target types are: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    678\u001b[0m             allowed_target_types, type_of_target_y\n\u001b[0;32m    679\u001b[0m         )\n\u001b[0;32m    680\u001b[0m     )\n\u001b[0;32m    682\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y)\n\u001b[0;32m    684\u001b[0m _, y_idx, y_inv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y, return_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Function for text cleaning with stemming and lemmatization\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):  # Check if the input is a string\n",
    "        stemmer = PorterStemmer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        text = re.sub(r'\\W', ' ', text)  # Remove all non-word characters\n",
    "        text = re.sub(r'\\s+', ' ', text)  # Replace multiple whitespace with single space\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        tokens = word_tokenize(text)  # Tokenize the text\n",
    "        tokens = [lemmatizer.lemmatize(stemmer.stem(word)) for word in tokens if word not in stopwords.words('english')]  # Stem and lemmatize, remove stopwords\n",
    "        return ' '.join(tokens)  # Join tokens back into a single string\n",
    "    else:\n",
    "        return \"\"  # Return an empty string if the input is not a string\n",
    "\n",
    "# Apply preprocessing to the role_description column\n",
    "data['cleaned_text'] = data['role_description'].apply(preprocess_text)\n",
    "\n",
    "# Define the skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction to the cleaned_text column\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Convert skills into binary labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(data['skills'])\n",
    "\n",
    "# TF-IDF Vectorization with trigrams\n",
    "vectorizer = TfidfVectorizer(max_features=3000, ngram_range=(1, 3), lowercase=False)\n",
    "X_tfidf = vectorizer.fit_transform(data['cleaned_text'])\n",
    "\n",
    "# Convert multilabel indicator matrix to separate binary classification tasks\n",
    "binary_labels = np.zeros_like(labels)\n",
    "\n",
    "for i in range(labels.shape[1]):\n",
    "    col_labels = labels[:, i]\n",
    "    unique_labels = np.unique(col_labels)\n",
    "    if len(unique_labels) > 1:  # Skip columns with only one class\n",
    "        binary_labels[:, i] = col_labels\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, binary_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the XGBoost classifier for binary classification\n",
    "xgb = XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3]\n",
    "}\n",
    "\n",
    "# Perform grid search with stratified k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model for binary classification\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "# Train the best XGBoost model for binary classification\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for each label for binary classification\n",
    "y_pred_proba = best_xgb.predict_proba(X_test)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the binary XGBoost model\n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "hamming_loss_score = hamming_loss(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Binary XGBoost (with Grid Search and Stratified K-Fold CV)\")\n",
    "print(\"F1 Score (Micro):\", f1_micro)\n",
    "print(\"Hamming Loss:\", hamming_loss_score)\n",
    "print(\"Accuracy Score:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de9e2386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Multi-Label Classification\n",
      "F1 Score (Micro): 0.88268156424581\n",
      "Hamming Loss: 0.02608695652173913\n",
      "Accuracy Score: 0.5142857142857142\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Function for text cleaning with stemming and lemmatization\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):  # Check if the input is a string\n",
    "        stemmer = PorterStemmer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        text = re.sub(r'\\W', ' ', text)  # Remove all non-word characters\n",
    "        text = re.sub(r'\\s+', ' ', text)  # Replace multiple whitespace with single space\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        tokens = word_tokenize(text)  # Tokenize the text\n",
    "        tokens = [lemmatizer.lemmatize(stemmer.stem(word)) for word in tokens if word not in stopwords.words('english')]  # Stem and lemmatize, remove stopwords\n",
    "        return ' '.join(tokens)  # Join tokens back into a single string\n",
    "    else:\n",
    "        return \"\"  # Return an empty string if the input is not a string\n",
    "\n",
    "# Apply preprocessing to the role_description column\n",
    "data['cleaned_text'] = data['role_description'].apply(preprocess_text)\n",
    "\n",
    "# Define the skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction to the cleaned_text column\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Convert skills into binary labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(data['skills'])\n",
    "\n",
    "# TF-IDF Vectorization with trigrams\n",
    "vectorizer = TfidfVectorizer(max_features=3000, ngram_range=(1, 3), lowercase=False)\n",
    "X_tfidf = vectorizer.fit_transform(data['cleaned_text'])\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the XGBoost classifier\n",
    "xgb = XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False)\n",
    "\n",
    "# Define the MultiOutputClassifier\n",
    "multi_target_xgb = MultiOutputClassifier(xgb, n_jobs=-1)\n",
    "\n",
    "# Fit the classifier\n",
    "multi_target_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels\n",
    "y_pred = multi_target_xgb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "hamming_loss_score = hamming_loss(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"XGBoost Multi-Label Classification\")\n",
    "print(\"F1 Score (Micro):\", f1_micro)\n",
    "print(\"Hamming Loss:\", hamming_loss_score)\n",
    "print(\"Accuracy Score:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e3b9e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Multi-Label Classification\n",
      "F1 Score (Micro): 0.783132530120482\n",
      "Hamming Loss: 0.04472049689440994\n",
      "Accuracy Score: 0.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Function for text cleaning with stemming and lemmatization\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):  # Check if the input is a string\n",
    "        stemmer = PorterStemmer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        text = re.sub(r'\\W', ' ', text)  # Remove all non-word characters\n",
    "        text = re.sub(r'\\s+', ' ', text)  # Replace multiple whitespace with single space\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        tokens = word_tokenize(text)  # Tokenize the text\n",
    "        tokens = [lemmatizer.lemmatize(stemmer.stem(word)) for word in tokens if word not in stopwords.words('english')]  # Stem and lemmatize, remove stopwords\n",
    "        return ' '.join(tokens)  # Join tokens back into a single string\n",
    "    else:\n",
    "        return \"\"  # Return an empty string if the input is not a string\n",
    "\n",
    "# Apply preprocessing to the role_description column\n",
    "data['cleaned_text'] = data['role_description'].apply(preprocess_text)\n",
    "\n",
    "# Define the skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction to the cleaned_text column\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Convert skills into binary labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(data['skills'])\n",
    "\n",
    "# TF-IDF Vectorization with trigrams\n",
    "vectorizer = TfidfVectorizer(max_features=3000, ngram_range=(1, 3), lowercase=False)\n",
    "X_tfidf = vectorizer.fit_transform(data['cleaned_text'])\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Define the MultiOutputClassifier\n",
    "multi_target_rf = MultiOutputClassifier(rf, n_jobs=-1)\n",
    "\n",
    "# Fit the classifier\n",
    "multi_target_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels\n",
    "y_pred = multi_target_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "hamming_loss_score = hamming_loss(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Random Forest Multi-Label Classification\")\n",
    "print(\"F1 Score (Micro):\", f1_micro)\n",
    "print(\"Hamming Loss:\", hamming_loss_score)\n",
    "print(\"Accuracy Score:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4759d2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hsahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\hsahn\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\hsahn\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\hsahn\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\hsahn\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\hsahn\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\hsahn\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\Users\\hsahn\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py\", line 49, in _fit_estimator\n    estimator.fit(X, y, **fit_params)\n  File \"C:\\Users\\hsahn\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 440, in fit\n    y = self._validate_y(y, sample_weight)\n  File \"C:\\Users\\hsahn\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 1232, in _validate_y\n    raise ValueError(\nValueError: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 84\u001b[0m\n\u001b[0;32m     81\u001b[0m multi_target_gb \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(gb, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Fit the classifier\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m \u001b[43mmulti_target_gb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Predict the labels\u001b[39;00m\n\u001b[0;32m     87\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m multi_target_gb\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y, sample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details.csv\")\n",
    "\n",
    "# Function for text cleaning with stemming and lemmatization\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):  # Check if the input is a string\n",
    "        stemmer = PorterStemmer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        text = re.sub(r'\\W', ' ', text)  # Remove all non-word characters\n",
    "        text = re.sub(r'\\s+', ' ', text)  # Replace multiple whitespace with single space\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        tokens = word_tokenize(text)  # Tokenize the text\n",
    "        tokens = [lemmatizer.lemmatize(stemmer.stem(word)) for word in tokens if word not in stopwords.words('english')]  # Stem and lemmatize, remove stopwords\n",
    "        return ' '.join(tokens)  # Join tokens back into a single string\n",
    "    else:\n",
    "        return \"\"  # Return an empty string if the input is not a string\n",
    "\n",
    "# Apply preprocessing to the role_description column\n",
    "data['cleaned_text'] = data['role_description'].apply(preprocess_text)\n",
    "\n",
    "# Define the skills list\n",
    "skills_list = [\n",
    "    \"python\", \"java\", \"kotlin\", \"jetpack compose\", \"android sdk\", \"firebase\",\n",
    "    \"rest\", \"json\", \"proto\", \"sql\", \"javascript\", \"cloud computing\", \"aws\",\n",
    "    \"excel\", \"data visualization\", \"react\", \"node.js\", \"marketing\", \"social media\",\n",
    "    \"seo\", \"content creation\", \"product management\", \"sales\", \"business development\",\n",
    "    \"hr\", \"research\", \"operations\", \"analytical skills\", \"problem solving\",\n",
    "    \"communication\", \"collaboration\", \"organizational skills\", \"multitasking\",\n",
    "    \"microsoft office\", \"ai\", \"machine learning\", \"big data\", \"deep learning\",\n",
    "    \"neural networks\", \"statistical analysis\", \"pandas\", \"numpy\", \"scikit-learn\",\n",
    "    \"tensorflow\", \"keras\", \"r\", \"sas\", \"sql\", \"tableau\", \"power bi\",\n",
    "    \"lead generation\", \"b2b\", \"b2c\", \"market research\", \"product marketing\",\n",
    "    \"email marketing\", \"content strategy\", \"creative writing\", \"employee engagement\",\n",
    "    \"talent management\", \"recruitment\", \"project management\", \"agile\", \"scrum\",\n",
    "    \"supply chain management\", \"logistics\", \"procurement\", \"inventory management\"\n",
    "]\n",
    "\n",
    "# Function to extract skills from job descriptions\n",
    "def extract_skills(text, skills_list):\n",
    "    text = text.lower()\n",
    "    extracted_skills = [skill for skill in skills_list if skill in text]\n",
    "    return extracted_skills\n",
    "\n",
    "# Apply skills extraction to the cleaned_text column\n",
    "data['skills'] = data['cleaned_text'].apply(lambda x: extract_skills(x, skills_list))\n",
    "\n",
    "# Convert skills into binary labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(data['skills'])\n",
    "\n",
    "# TF-IDF Vectorization with trigrams\n",
    "vectorizer = TfidfVectorizer(max_features=3000, ngram_range=(1, 3), lowercase=False)\n",
    "X_tfidf = vectorizer.fit_transform(data['cleaned_text'])\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the Gradient Boosting classifier\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Define the MultiOutputClassifier\n",
    "multi_target_gb = MultiOutputClassifier(gb, n_jobs=-1)\n",
    "\n",
    "# Fit the classifier\n",
    "multi_target_gb.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels\n",
    "y_pred = multi_target_gb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "hamming_loss_score = hamming_loss(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Gradient Boosting Multi-Label Classification\")\n",
    "print(\"F1 Score (Micro):\", f1_micro)\n",
    "print(\"Hamming Loss:\", hamming_loss_score)\n",
    "print(\"Accuracy Score:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647e31b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
