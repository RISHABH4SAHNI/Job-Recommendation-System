{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e37b341b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, dict found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     combined_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhard_skills\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msoft_skills\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_text\n\u001b[1;32m---> 24\u001b[0m candidates_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_skills\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcandidates_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombine_skills\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Combine relevant text fields for job roles\u001b[39;00m\n\u001b[0;32m     27\u001b[0m job_details_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_job_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m job_details_data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole_description\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequirement\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9557\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9567\u001b[0m )\n\u001b[1;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    909\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    910\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    911\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m, in \u001b[0;36mcombine_skills\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_skills\u001b[39m(row):\n\u001b[1;32m---> 19\u001b[0m     hard_skills \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHardSkills\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     soft_skills \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSoftSkills\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     21\u001b[0m     combined_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhard_skills\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msoft_skills\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, dict found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the CSV files\n",
    "candidates_data = pd.read_csv(\"C:/Users/hsahn/OneDrive/Desktop/all_resumes_data.csv\")\n",
    "job_details_data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details_with_predictions.csv\")\n",
    "\n",
    "# List of columns with JSON data in candidate data\n",
    "json_columns = ['Experiences', 'Projects', 'Achievements', 'Certifications', 'HardSkills', 'SoftSkills', 'RecommendedJobDomains']\n",
    "\n",
    "# Parse JSON columns in candidate data\n",
    "for column in json_columns:\n",
    "    candidates_data[column] = candidates_data[column].apply(json.loads)\n",
    "\n",
    "# Combine relevant text fields into a single text string for each candidate\n",
    "def combine_skills(row):\n",
    "    hard_skills = ' '.join(row['HardSkills'])\n",
    "    soft_skills = ' '.join(row['SoftSkills'])\n",
    "    combined_text = f\"{hard_skills} {soft_skills}\"\n",
    "    return combined_text\n",
    "\n",
    "candidates_data['combined_skills'] = candidates_data.apply(combine_skills, axis=1)\n",
    "\n",
    "# Combine relevant text fields for job roles\n",
    "job_details_data['combined_job_text'] = job_details_data.apply(lambda row: f\"{row['role_description']} {row['requirement']}\", axis=1)\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Combine all texts for fitting the TF-IDF vectorizer\n",
    "all_texts = candidates_data['combined_skills'].tolist() + job_details_data['combined_job_text'].tolist()\n",
    "\n",
    "# Fit and transform the text data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(all_texts)\n",
    "\n",
    "# Split the TF-IDF matrix into candidates' skills and job roles\n",
    "candidates_matrix = tfidf_matrix[:len(candidates_data)]\n",
    "jobs_matrix = tfidf_matrix[len(candidates_data):]\n",
    "\n",
    "# Create a DataFrame to store relevancy scores\n",
    "relevancy_scores = pd.DataFrame(index=candidates_data.index)\n",
    "\n",
    "# Compute cosine similarity between each candidate's skills and each job role\n",
    "for job_index in job_details_data.index:\n",
    "    job_vector = jobs_matrix[job_index]\n",
    "    similarity_scores = cosine_similarity(candidates_matrix, job_vector)\n",
    "    relevancy_scores[job_index] = similarity_scores.flatten()\n",
    "\n",
    "# Add relevancy scores to the job details DataFrame\n",
    "job_details_data['relevancy_scores'] = relevancy_scores.apply(lambda col: col.nlargest(len(candidates_data)).index.tolist(), axis=0)\n",
    "job_details_data['relevancy_candidates'] = relevancy_scores.apply(lambda col: col.nlargest(len(candidates_data)).values.tolist(), axis=0)\n",
    "\n",
    "# Save the updated job details with relevancy scores to a new CSV file\n",
    "job_details_data.to_csv('job_relevancy_scores.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "468344eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, dict found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m     combined_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhard_skills\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msoft_skills\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiences\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprojects\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00machievements\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcertifications\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_text\n\u001b[1;32m---> 28\u001b[0m candidates_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_skills\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcandidates_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombine_skills\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Combine relevant text fields for job roles\u001b[39;00m\n\u001b[0;32m     31\u001b[0m job_details_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_job_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m job_details_data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole_description\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequirement\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9557\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9567\u001b[0m )\n\u001b[1;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    909\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    910\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    911\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[3], line 19\u001b[0m, in \u001b[0;36mcombine_skills\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_skills\u001b[39m(row):\n\u001b[1;32m---> 19\u001b[0m     hard_skills \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHardSkills\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     soft_skills \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSoftSkills\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     21\u001b[0m     experiences \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperiences\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, dict found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the CSV files\n",
    "candidates_data = pd.read_csv(\"C:/Users/hsahn/OneDrive/Desktop/all_resumes_data.csv\")\n",
    "job_details_data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details_with_predictions.csv\")\n",
    "\n",
    "# List of columns with JSON data in candidate data\n",
    "json_columns = ['Experiences', 'Projects', 'Achievements', 'Certifications', 'HardSkills', 'SoftSkills', 'RecommendedJobDomains']\n",
    "\n",
    "# Parse JSON columns in candidate data\n",
    "for column in json_columns:\n",
    "    candidates_data[column] = candidates_data[column].apply(json.loads)\n",
    "\n",
    "# Combine relevant text fields into a single text string for each candidate\n",
    "def combine_skills(row):\n",
    "    hard_skills = ' '.join(row['HardSkills'])\n",
    "    soft_skills = ' '.join(row['SoftSkills'])\n",
    "    experiences = ' '.join([item['description'] for item in row['Experiences']])\n",
    "    projects = ' '.join([item['description'] for item in row['Projects']])\n",
    "    achievements = ' '.join([item['description'] for item in row['Achievements']])\n",
    "    certifications = ' '.join([item['name'] for item in row['Certifications']])\n",
    "    combined_text = f\"{hard_skills} {soft_skills} {experiences} {projects} {achievements} {certifications}\"\n",
    "    return combined_text\n",
    "\n",
    "candidates_data['combined_skills'] = candidates_data.apply(combine_skills, axis=1)\n",
    "\n",
    "# Combine relevant text fields for job roles\n",
    "job_details_data['combined_job_text'] = job_details_data.apply(lambda row: f\"{row['role_description']} {row['requirement']}\", axis=1)\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Combine all texts for fitting the TF-IDF vectorizer\n",
    "all_texts = candidates_data['combined_skills'].tolist() + job_details_data['combined_job_text'].tolist()\n",
    "\n",
    "# Fit and transform the text data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(all_texts)\n",
    "\n",
    "# Split the TF-IDF matrix into candidates' skills and job roles\n",
    "candidates_matrix = tfidf_matrix[:len(candidates_data)]\n",
    "jobs_matrix = tfidf_matrix[len(candidates_data):]\n",
    "\n",
    "# Create a DataFrame to store relevancy scores\n",
    "relevancy_scores = pd.DataFrame(index=candidates_data.index)\n",
    "\n",
    "# Compute cosine similarity between each candidate's skills and each job role\n",
    "for job_index in job_details_data.index:\n",
    "    job_vector = jobs_matrix[job_index]\n",
    "    similarity_scores = cosine_similarity(candidates_matrix, job_vector)\n",
    "    relevancy_scores[job_index] = similarity_scores.flatten()\n",
    "\n",
    "# Convert relevancy scores to lists of candidate indexes and scores\n",
    "job_details_data['relevancy_scores'] = relevancy_scores.apply(lambda col: col.nlargest(len(candidates_data)).tolist(), axis=0)\n",
    "job_details_data['relevancy_candidates'] = relevancy_scores.apply(lambda col: col.nlargest(len(candidates_data)).index.tolist(), axis=0)\n",
    "\n",
    "# Save the updated job details with relevancy scores to a new CSV file\n",
    "job_details_data.to_csv('job_relevancy_scores.csv', index=False)\n",
    "\n",
    "# Flatten the relevancy_scores and relevancy_candidates for each job to create a detailed CSV\n",
    "detailed_rows = []\n",
    "for job_index, job_row in job_details_data.iterrows():\n",
    "    for candidate_index, score in zip(job_row['relevancy_candidates'], job_row['relevancy_scores']):\n",
    "        detailed_rows.append({\n",
    "            'job_id': job_row['job_id'],\n",
    "            'job_title': job_row['role_title'],\n",
    "            'candidate_id': candidates_data.iloc[candidate_index]['Name'],\n",
    "            'candidate_email': candidates_data.iloc[candidate_index]['Email'],\n",
    "            'relevancy_score': score\n",
    "        })\n",
    "\n",
    "detailed_df = pd.DataFrame(detailed_rows)\n",
    "detailed_df.to_csv('detailed_job_relevancy_scores.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1331faff",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, dict found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m     combined_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhard_skills\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msoft_skills\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiences\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprojects\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00machievements\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcertifications\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_text\n\u001b[1;32m---> 28\u001b[0m candidates_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_skills\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcandidates_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombine_skills\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Combine relevant text fields for job roles\u001b[39;00m\n\u001b[0;32m     31\u001b[0m job_details_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_job_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m job_details_data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole_description\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequirement\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9557\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9567\u001b[0m )\n\u001b[1;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    909\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    910\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    911\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m, in \u001b[0;36mcombine_skills\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_skills\u001b[39m(row):\n\u001b[0;32m     19\u001b[0m     hard_skills \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([skill[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskill\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m skill \u001b[38;5;129;01min\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHardSkills\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m---> 20\u001b[0m     soft_skills \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSoftSkills\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     experiences \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperiences\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m     22\u001b[0m     projects \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProjects\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, dict found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the CSV files\n",
    "candidates_data = pd.read_csv(\"C:/Users/hsahn/OneDrive/Desktop/all_resumes_data.csv\")\n",
    "job_details_data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details_with_predictions.csv\")\n",
    "\n",
    "# List of columns with JSON data in candidate data\n",
    "json_columns = ['Experiences', 'Projects', 'Achievements', 'Certifications', 'HardSkills', 'SoftSkills', 'RecommendedJobDomains']\n",
    "\n",
    "# Parse JSON columns in candidate data\n",
    "for column in json_columns:\n",
    "    candidates_data[column] = candidates_data[column].apply(json.loads)\n",
    "\n",
    "# Combine relevant text fields into a single text string for each candidate\n",
    "def combine_skills(row):\n",
    "    hard_skills = ' '.join([skill['skill'] for skill in row['HardSkills']])\n",
    "    soft_skills = ' '.join(row['SoftSkills'])\n",
    "    experiences = ' '.join([item['description'] for item in row['Experiences']])\n",
    "    projects = ' '.join([item['description'] for item in row['Projects']])\n",
    "    achievements = ' '.join([item['achievement'] for item in row['Achievements']])\n",
    "    certifications = ' '.join([item['name'] for item in row['Certifications']])\n",
    "    combined_text = f\"{hard_skills} {soft_skills} {experiences} {projects} {achievements} {certifications}\"\n",
    "    return combined_text\n",
    "\n",
    "candidates_data['combined_skills'] = candidates_data.apply(combine_skills, axis=1)\n",
    "\n",
    "# Combine relevant text fields for job roles\n",
    "job_details_data['combined_job_text'] = job_details_data.apply(lambda row: f\"{row['role_description']} {row['requirement']}\", axis=1)\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Combine all texts for fitting the TF-IDF vectorizer\n",
    "all_texts = candidates_data['combined_skills'].tolist() + job_details_data['combined_job_text'].tolist()\n",
    "\n",
    "# Fit and transform the text data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(all_texts)\n",
    "\n",
    "# Split the TF-IDF matrix into candidates' skills and job roles\n",
    "candidates_matrix = tfidf_matrix[:len(candidates_data)]\n",
    "jobs_matrix = tfidf_matrix[len(candidates_data):]\n",
    "\n",
    "# Create a DataFrame to store relevancy scores\n",
    "relevancy_scores = pd.DataFrame(index=candidates_data.index)\n",
    "\n",
    "# Compute cosine similarity between each candidate's skills and each job role\n",
    "for job_index in job_details_data.index:\n",
    "    job_vector = jobs_matrix[job_index]\n",
    "    similarity_scores = cosine_similarity(candidates_matrix, job_vector)\n",
    "    relevancy_scores[job_index] = similarity_scores.flatten()\n",
    "\n",
    "# Convert relevancy scores to lists of candidate indexes and scores\n",
    "job_details_data['relevancy_scores'] = relevancy_scores.apply(lambda col: col.nlargest(len(candidates_data)).tolist(), axis=0)\n",
    "job_details_data['relevancy_candidates'] = relevancy_scores.apply(lambda col: col.nlargest(len(candidates_data)).index.tolist(), axis=0)\n",
    "\n",
    "# Save the updated job details with relevancy scores to a new CSV file\n",
    "job_details_data.to_csv('job_relevancy_scores.csv', index=False)\n",
    "\n",
    "# Flatten the relevancy_scores and relevancy_candidates for each job to create a detailed CSV\n",
    "detailed_rows = []\n",
    "for job_index, job_row in job_details_data.iterrows():\n",
    "    for candidate_index, score in zip(job_row['relevancy_candidates'], job_row['relevancy_scores']):\n",
    "        detailed_rows.append({\n",
    "            'job_id': job_row['job_id'],\n",
    "            'job_title': job_row['role_title'],\n",
    "            'candidate_id': candidates_data.iloc[candidate_index]['Name'],\n",
    "            'candidate_email': candidates_data.iloc[candidate_index]['Email'],\n",
    "            'relevancy_score': score\n",
    "        })\n",
    "\n",
    "detailed_df = pd.DataFrame(detailed_rows)\n",
    "detailed_df.to_csv('detailed_job_relevancy_scores.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b748a3a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, dict found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m     combined_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhard_skills\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msoft_skills\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiences\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprojects\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00machievements\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcertifications\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_text\n\u001b[1;32m---> 34\u001b[0m candidates_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_skills\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcandidates_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombine_skills\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Combine relevant text fields for job roles\u001b[39;00m\n\u001b[0;32m     37\u001b[0m job_details_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_job_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m job_details_data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole_description\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequirement\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9557\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9567\u001b[0m )\n\u001b[1;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    909\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    910\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    911\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[6], line 26\u001b[0m, in \u001b[0;36mcombine_skills\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_skills\u001b[39m(row):\n\u001b[0;32m     25\u001b[0m     hard_skills \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([skill[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskill\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m skill \u001b[38;5;129;01min\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHardSkills\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m---> 26\u001b[0m     soft_skills \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSoftSkills\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     experiences \u001b[38;5;241m=\u001b[39m extract_text_from_json(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperiences\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     28\u001b[0m     projects \u001b[38;5;241m=\u001b[39m extract_text_from_json(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProjects\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, dict found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the CSV files\n",
    "candidates_data = pd.read_csv(\"C:/Users/hsahn/OneDrive/Desktop/all_resumes_data.csv\")\n",
    "job_details_data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details_with_predictions.csv\")\n",
    "\n",
    "# List of columns with JSON data in candidate data\n",
    "json_columns = ['Experiences', 'Projects', 'Achievements', 'Certifications', 'HardSkills', 'SoftSkills', 'RecommendedJobDomains']\n",
    "\n",
    "# Parse JSON columns in candidate data\n",
    "for column in json_columns:\n",
    "    candidates_data[column] = candidates_data[column].apply(json.loads)\n",
    "\n",
    "# Helper function to safely extract text from JSON fields\n",
    "def extract_text_from_json(json_field, key):\n",
    "    if isinstance(json_field, list):\n",
    "        return ' '.join([item[key] for item in json_field if key in item])\n",
    "    return ''\n",
    "\n",
    "# Combine relevant text fields into a single text string for each candidate\n",
    "def combine_skills(row):\n",
    "    hard_skills = ' '.join([skill['skill'] for skill in row['HardSkills']])\n",
    "    soft_skills = ' '.join(row['SoftSkills'])\n",
    "    experiences = extract_text_from_json(row['Experiences'], 'description')\n",
    "    projects = extract_text_from_json(row['Projects'], 'description')\n",
    "    achievements = extract_text_from_json(row['Achievements'], 'achievement')\n",
    "    certifications = extract_text_from_json(row['Certifications'], 'name')\n",
    "    combined_text = f\"{hard_skills} {soft_skills} {experiences} {projects} {achievements} {certifications}\"\n",
    "    return combined_text\n",
    "\n",
    "candidates_data['combined_skills'] = candidates_data.apply(combine_skills, axis=1)\n",
    "\n",
    "# Combine relevant text fields for job roles\n",
    "job_details_data['combined_job_text'] = job_details_data.apply(lambda row: f\"{row['role_description']} {row['requirement']}\", axis=1)\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Combine all texts for fitting the TF-IDF vectorizer\n",
    "all_texts = candidates_data['combined_skills'].tolist() + job_details_data['combined_job_text'].tolist()\n",
    "\n",
    "# Fit and transform the text data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(all_texts)\n",
    "\n",
    "# Split the TF-IDF matrix into candidates' skills and job roles\n",
    "candidates_matrix = tfidf_matrix[:len(candidates_data)]\n",
    "jobs_matrix = tfidf_matrix[len(candidates_data):]\n",
    "\n",
    "# Create a DataFrame to store relevancy scores\n",
    "relevancy_scores = pd.DataFrame(index=candidates_data.index)\n",
    "\n",
    "# Compute cosine similarity between each candidate's skills and each job role\n",
    "for job_index in job_details_data.index:\n",
    "    job_vector = jobs_matrix[job_index]\n",
    "    similarity_scores = cosine_similarity(candidates_matrix, job_vector)\n",
    "    relevancy_scores[job_index] = similarity_scores.flatten()\n",
    "\n",
    "# Convert relevancy scores to lists of candidate indexes and scores\n",
    "job_details_data['relevancy_scores'] = relevancy_scores.apply(lambda col: col.nlargest(len(candidates_data)).tolist(), axis=0)\n",
    "job_details_data['relevancy_candidates'] = relevancy_scores.apply(lambda col: col.nlargest(len(candidates_data)).index.tolist(), axis=0)\n",
    "\n",
    "# Save the updated job details with relevancy scores to a new CSV file\n",
    "job_details_data.to_csv('job_relevancy_scores.csv', index=False)\n",
    "\n",
    "# Flatten the relevancy_scores and relevancy_candidates for each job to create a detailed CSV\n",
    "detailed_rows = []\n",
    "for job_index, job_row in job_details_data.iterrows():\n",
    "    for candidate_index, score in zip(job_row['relevancy_candidates'], job_row['relevancy_scores']):\n",
    "        detailed_rows.append({\n",
    "            'job_id': job_row['job_id'],\n",
    "            'job_title': job_row['role_title'],\n",
    "            'candidate_name': candidates_data.iloc[candidate_index]['Name'],\n",
    "            'candidate_email': candidates_data.iloc[candidate_index]['Email'],\n",
    "            'relevancy_score': score\n",
    "        })\n",
    "\n",
    "detailed_df = pd.DataFrame(detailed_rows)\n",
    "detailed_df.to_csv('detailed_job_relevancy_scores.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03f1670b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3268772385.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot set a DataFrame with multiple columns to the single column relevancy_scores",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m     relevancy_scores[job_index] \u001b[38;5;241m=\u001b[39m similarity_scores\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Convert relevancy scores to lists of candidate indexes and scores\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m \u001b[43mjob_details_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelevancy_scores\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m relevancy_scores\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m col: col\u001b[38;5;241m.\u001b[39mnlargest(\u001b[38;5;28mlen\u001b[39m(candidates_data))\u001b[38;5;241m.\u001b[39mtolist(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     63\u001b[0m job_details_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelevancy_candidates\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m relevancy_scores\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m col: col\u001b[38;5;241m.\u001b[39mnlargest(\u001b[38;5;28mlen\u001b[39m(candidates_data))\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Save the updated job details with relevancy scores to a new CSV file\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3970\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3968\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array(key, value)\n\u001b[0;32m   3969\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m-> 3970\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_frame_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   3972\u001b[0m     is_list_like(value)\n\u001b[0;32m   3973\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique\n\u001b[0;32m   3974\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_indexer_for([key])) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value)\n\u001b[0;32m   3975\u001b[0m ):\n\u001b[0;32m   3976\u001b[0m     \u001b[38;5;66;03m# Column to set is duplicated\u001b[39;00m\n\u001b[0;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4125\u001b[0m, in \u001b[0;36mDataFrame._set_item_frame_value\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   4124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 4125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   4126\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set a DataFrame with multiple columns to the single \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4127\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4128\u001b[0m     )\n\u001b[0;32m   4130\u001b[0m \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m value[value\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m]]\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set a DataFrame with multiple columns to the single column relevancy_scores"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the CSV files\n",
    "candidates_data = pd.read_csv(\"C:/Users/hsahn/OneDrive/Desktop/all_resumes_data.csv\")\n",
    "job_details_data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details_with_predictions.csv\")\n",
    "\n",
    "# List of columns with JSON data in candidate data\n",
    "json_columns = ['Experiences', 'Projects', 'Achievements', 'Certifications', 'HardSkills', 'SoftSkills', 'RecommendedJobDomains']\n",
    "\n",
    "# Parse JSON columns in candidate data\n",
    "for column in json_columns:\n",
    "    candidates_data[column] = candidates_data[column].apply(json.loads)\n",
    "\n",
    "# Helper function to safely extract text from JSON fields\n",
    "def extract_text_from_json(json_field, key):\n",
    "    if isinstance(json_field, list):\n",
    "        return ' '.join([str(item[key]) for item in json_field if key in item])\n",
    "    return ''\n",
    "\n",
    "# Combine relevant text fields into a single text string for each candidate\n",
    "def combine_skills(row):\n",
    "    hard_skills = ' '.join([skill['skill'] for skill in row['HardSkills']])\n",
    "    soft_skills = ' '.join([str(skill['skill']) if isinstance(skill, dict) else str(skill) for skill in row['SoftSkills']])\n",
    "    experiences = extract_text_from_json(row['Experiences'], 'description')\n",
    "    projects = extract_text_from_json(row['Projects'], 'description')\n",
    "    achievements = extract_text_from_json(row['Achievements'], 'achievement')\n",
    "    certifications = extract_text_from_json(row['Certifications'], 'name')\n",
    "    combined_text = f\"{hard_skills} {soft_skills} {experiences} {projects} {achievements} {certifications}\"\n",
    "    return combined_text\n",
    "\n",
    "candidates_data['combined_skills'] = candidates_data.apply(combine_skills, axis=1)\n",
    "\n",
    "# Combine relevant text fields for job roles\n",
    "job_details_data['combined_job_text'] = job_details_data.apply(lambda row: f\"{row['role_description']} {row['requirement']}\", axis=1)\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Combine all texts for fitting the TF-IDF vectorizer\n",
    "all_texts = candidates_data['combined_skills'].tolist() + job_details_data['combined_job_text'].tolist()\n",
    "\n",
    "# Fit and transform the text data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(all_texts)\n",
    "\n",
    "# Split the TF-IDF matrix into candidates' skills and job roles\n",
    "candidates_matrix = tfidf_matrix[:len(candidates_data)]\n",
    "jobs_matrix = tfidf_matrix[len(candidates_data):]\n",
    "\n",
    "# Create a DataFrame to store relevancy scores\n",
    "relevancy_scores = pd.DataFrame(index=candidates_data.index)\n",
    "\n",
    "# Compute cosine similarity between each candidate's skills and each job role\n",
    "for job_index in job_details_data.index:\n",
    "    job_vector = jobs_matrix[job_index]\n",
    "    similarity_scores = cosine_similarity(candidates_matrix, job_vector)\n",
    "    relevancy_scores[job_index] = similarity_scores.flatten()\n",
    "\n",
    "# Convert relevancy scores to lists of candidate indexes and scores\n",
    "job_details_data['relevancy_scores'] = relevancy_scores.apply(lambda col: col.nlargest(len(candidates_data)).tolist(), axis=0)\n",
    "job_details_data['relevancy_candidates'] = relevancy_scores.apply(lambda col: col.nlargest(len(candidates_data)).index.tolist(), axis=0)\n",
    "\n",
    "# Save the updated job details with relevancy scores to a new CSV file\n",
    "job_details_data.to_csv('job_relevancy_scores.csv', index=False)\n",
    "\n",
    "# Flatten the relevancy_scores and relevancy_candidates for each job to create a detailed CSV\n",
    "detailed_rows = []\n",
    "for job_index, job_row in job_details_data.iterrows():\n",
    "    for candidate_index, score in zip(job_row['relevancy_candidates'], job_row['relevancy_scores']):\n",
    "        detailed_rows.append({\n",
    "            'job_id': job_row['job_id'],\n",
    "            'job_title': job_row['role_title'],\n",
    "            'candidate_name': candidates_data.iloc[candidate_index]['Name'],\n",
    "            'candidate_email': candidates_data.iloc[candidate_index]['Email'],\n",
    "            'relevancy_score': score\n",
    "        })\n",
    "\n",
    "detailed_df = pd.DataFrame(detailed_rows)\n",
    "detailed_df.to_csv('detailed_job_relevancy_scores.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e671255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\512639693.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot set a DataFrame with multiple columns to the single column relevancy_candidates",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m     relevancy_scores[job_index] \u001b[38;5;241m=\u001b[39m similarity_scores\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Extract the top candidate indexes and scores for each job\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m \u001b[43mjob_details_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelevancy_candidates\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m relevancy_scores\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m col: col\u001b[38;5;241m.\u001b[39mnlargest(\u001b[38;5;28mlen\u001b[39m(candidates_data))\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     63\u001b[0m job_details_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelevancy_scores\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m relevancy_scores\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m col: col\u001b[38;5;241m.\u001b[39mnlargest(\u001b[38;5;28mlen\u001b[39m(candidates_data))\u001b[38;5;241m.\u001b[39mtolist(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Save the updated job details with relevancy scores to a new CSV file\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3970\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3968\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array(key, value)\n\u001b[0;32m   3969\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m-> 3970\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_frame_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   3972\u001b[0m     is_list_like(value)\n\u001b[0;32m   3973\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique\n\u001b[0;32m   3974\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_indexer_for([key])) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value)\n\u001b[0;32m   3975\u001b[0m ):\n\u001b[0;32m   3976\u001b[0m     \u001b[38;5;66;03m# Column to set is duplicated\u001b[39;00m\n\u001b[0;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4125\u001b[0m, in \u001b[0;36mDataFrame._set_item_frame_value\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   4124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 4125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   4126\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set a DataFrame with multiple columns to the single \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4127\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4128\u001b[0m     )\n\u001b[0;32m   4130\u001b[0m \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m value[value\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m]]\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set a DataFrame with multiple columns to the single column relevancy_candidates"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the CSV files\n",
    "candidates_data = pd.read_csv(\"C:/Users/hsahn/OneDrive/Desktop/all_resumes_data.csv\")\n",
    "job_details_data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details_with_predictions.csv\")\n",
    "\n",
    "# List of columns with JSON data in candidate data\n",
    "json_columns = ['Experiences', 'Projects', 'Achievements', 'Certifications', 'HardSkills', 'SoftSkills', 'RecommendedJobDomains']\n",
    "\n",
    "# Parse JSON columns in candidate data\n",
    "for column in json_columns:\n",
    "    candidates_data[column] = candidates_data[column].apply(json.loads)\n",
    "\n",
    "# Helper function to safely extract text from JSON fields\n",
    "def extract_text_from_json(json_field, key):\n",
    "    if isinstance(json_field, list):\n",
    "        return ' '.join([str(item[key]) for item in json_field if key in item])\n",
    "    return ''\n",
    "\n",
    "# Combine relevant text fields into a single text string for each candidate\n",
    "def combine_skills(row):\n",
    "    hard_skills = ' '.join([skill['skill'] for skill in row['HardSkills']])\n",
    "    soft_skills = ' '.join([str(skill['skill']) if isinstance(skill, dict) else str(skill) for skill in row['SoftSkills']])\n",
    "    experiences = extract_text_from_json(row['Experiences'], 'description')\n",
    "    projects = extract_text_from_json(row['Projects'], 'description')\n",
    "    achievements = extract_text_from_json(row['Achievements'], 'achievement')\n",
    "    certifications = extract_text_from_json(row['Certifications'], 'name')\n",
    "    combined_text = f\"{hard_skills} {soft_skills} {experiences} {projects} {achievements} {certifications}\"\n",
    "    return combined_text\n",
    "\n",
    "candidates_data['combined_skills'] = candidates_data.apply(combine_skills, axis=1)\n",
    "\n",
    "# Combine relevant text fields for job roles\n",
    "job_details_data['combined_job_text'] = job_details_data.apply(lambda row: f\"{row['role_description']} {row['requirement']}\", axis=1)\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Combine all texts for fitting the TF-IDF vectorizer\n",
    "all_texts = candidates_data['combined_skills'].tolist() + job_details_data['combined_job_text'].tolist()\n",
    "\n",
    "# Fit and transform the text data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(all_texts)\n",
    "\n",
    "# Split the TF-IDF matrix into candidates' skills and job roles\n",
    "candidates_matrix = tfidf_matrix[:len(candidates_data)]\n",
    "jobs_matrix = tfidf_matrix[len(candidates_data):]\n",
    "\n",
    "# Create a DataFrame to store relevancy scores\n",
    "relevancy_scores = pd.DataFrame(index=candidates_data.index)\n",
    "\n",
    "# Compute cosine similarity between each candidate's skills and each job role\n",
    "for job_index in job_details_data.index:\n",
    "    job_vector = jobs_matrix[job_index]\n",
    "    similarity_scores = cosine_similarity(candidates_matrix, job_vector)\n",
    "    relevancy_scores[job_index] = similarity_scores.flatten()\n",
    "\n",
    "# Extract the top candidate indexes and scores for each job\n",
    "job_details_data['relevancy_candidates'] = relevancy_scores.apply(lambda col: col.nlargest(len(candidates_data)).index.tolist(), axis=0)\n",
    "job_details_data['relevancy_scores'] = relevancy_scores.apply(lambda col: col.nlargest(len(candidates_data)).tolist(), axis=0)\n",
    "\n",
    "# Save the updated job details with relevancy scores to a new CSV file\n",
    "job_details_data.to_csv('job_relevancy_scores.csv', index=False)\n",
    "\n",
    "# Flatten the relevancy_scores and relevancy_candidates for each job to create a detailed CSV\n",
    "detailed_rows = []\n",
    "for job_index, job_row in job_details_data.iterrows():\n",
    "    for candidate_index, score in zip(job_row['relevancy_candidates'], job_row['relevancy_scores']):\n",
    "        detailed_rows.append({\n",
    "            'job_id': job_row['job_id'],\n",
    "            'job_title': job_row['role_title'],\n",
    "            'candidate_name': candidates_data.iloc[candidate_index]['Name'],\n",
    "            'candidate_email': candidates_data.iloc[candidate_index]['Email'],\n",
    "            'relevancy_score': score\n",
    "        })\n",
    "\n",
    "detailed_df = pd.DataFrame(detailed_rows)\n",
    "detailed_df.to_csv('detailed_job_relevancy_scores.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66c7db29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\10088843.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot set a DataFrame with multiple columns to the single column relevancy_candidates",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m     relevancy_scores[job_index] \u001b[38;5;241m=\u001b[39m similarity_scores\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Extract the top candidate indexes and scores for each job\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m \u001b[43mjob_details_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelevancy_candidates\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m relevancy_scores\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m col: col\u001b[38;5;241m.\u001b[39mnlargest(\u001b[38;5;28mlen\u001b[39m(candidates_data))\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     63\u001b[0m job_details_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelevancy_scores\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m relevancy_scores\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m col: col\u001b[38;5;241m.\u001b[39mnlargest(\u001b[38;5;28mlen\u001b[39m(candidates_data))\u001b[38;5;241m.\u001b[39mtolist(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Save the updated job details with relevancy scores to a new CSV file\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3970\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3968\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array(key, value)\n\u001b[0;32m   3969\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m-> 3970\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_frame_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   3972\u001b[0m     is_list_like(value)\n\u001b[0;32m   3973\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique\n\u001b[0;32m   3974\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_indexer_for([key])) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value)\n\u001b[0;32m   3975\u001b[0m ):\n\u001b[0;32m   3976\u001b[0m     \u001b[38;5;66;03m# Column to set is duplicated\u001b[39;00m\n\u001b[0;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4125\u001b[0m, in \u001b[0;36mDataFrame._set_item_frame_value\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   4124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 4125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   4126\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set a DataFrame with multiple columns to the single \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4127\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4128\u001b[0m     )\n\u001b[0;32m   4130\u001b[0m \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m value[value\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m]]\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set a DataFrame with multiple columns to the single column relevancy_candidates"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the CSV files\n",
    "candidates_data = pd.read_csv(\"C:/Users/hsahn/OneDrive/Desktop/all_resumes_data.csv\")\n",
    "job_details_data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details_with_predictions.csv\")\n",
    "\n",
    "# List of columns with JSON data in candidate data\n",
    "json_columns = ['Experiences', 'Projects', 'Achievements', 'Certifications', 'HardSkills', 'SoftSkills', 'RecommendedJobDomains']\n",
    "\n",
    "# Parse JSON columns in candidate data\n",
    "for column in json_columns:\n",
    "    candidates_data[column] = candidates_data[column].apply(json.loads)\n",
    "\n",
    "# Helper function to safely extract text from JSON fields\n",
    "def extract_text_from_json(json_field, key):\n",
    "    if isinstance(json_field, list):\n",
    "        return ' '.join([str(item[key]) for item in json_field if key in item])\n",
    "    return ''\n",
    "\n",
    "# Combine relevant text fields into a single text string for each candidate\n",
    "def combine_skills(row):\n",
    "    hard_skills = ' '.join([skill['skill'] for skill in row['HardSkills']])\n",
    "    soft_skills = ' '.join([str(skill) for skill in row['SoftSkills']])\n",
    "    experiences = extract_text_from_json(row['Experiences'], 'description')\n",
    "    projects = extract_text_from_json(row['Projects'], 'description')\n",
    "    achievements = extract_text_from_json(row['Achievements'], 'achievement')\n",
    "    certifications = extract_text_from_json(row['Certifications'], 'name')\n",
    "    combined_text = f\"{hard_skills} {soft_skills} {experiences} {projects} {achievements} {certifications}\"\n",
    "    return combined_text\n",
    "\n",
    "candidates_data['combined_skills'] = candidates_data.apply(combine_skills, axis=1)\n",
    "\n",
    "# Combine relevant text fields for job roles\n",
    "job_details_data['combined_job_text'] = job_details_data.apply(lambda row: f\"{row['role_description']} {row['requirement']}\", axis=1)\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Combine all texts for fitting the TF-IDF vectorizer\n",
    "all_texts = candidates_data['combined_skills'].tolist() + job_details_data['combined_job_text'].tolist()\n",
    "\n",
    "# Fit and transform the text data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(all_texts)\n",
    "\n",
    "# Split the TF-IDF matrix into candidates' skills and job roles\n",
    "candidates_matrix = tfidf_matrix[:len(candidates_data)]\n",
    "jobs_matrix = tfidf_matrix[len(candidates_data):]\n",
    "\n",
    "# Create a DataFrame to store relevancy scores\n",
    "relevancy_scores = pd.DataFrame(index=candidates_data.index)\n",
    "\n",
    "# Compute cosine similarity between each candidate's skills and each job role\n",
    "for job_index in job_details_data.index:\n",
    "    job_vector = jobs_matrix[job_index]\n",
    "    similarity_scores = cosine_similarity(candidates_matrix, job_vector)\n",
    "    relevancy_scores[job_index] = similarity_scores.flatten()\n",
    "\n",
    "# Extract the top candidate indexes and scores for each job\n",
    "job_details_data['relevancy_candidates'] = relevancy_scores.apply(lambda col: col.nlargest(len(candidates_data)).index.tolist(), axis=0)\n",
    "job_details_data['relevancy_scores'] = relevancy_scores.apply(lambda col: col.nlargest(len(candidates_data)).tolist(), axis=0)\n",
    "\n",
    "# Save the updated job details with relevancy scores to a new CSV file\n",
    "job_details_data.to_csv('job_relevancy_scores.csv', index=False)\n",
    "\n",
    "# Flatten the relevancy_scores and relevancy_candidates for each job to create a detailed CSV\n",
    "detailed_rows = []\n",
    "for job_index, job_row in job_details_data.iterrows():\n",
    "    for candidate_index, score in zip(job_row['relevancy_candidates'], job_row['relevancy_scores']):\n",
    "        detailed_rows.append({\n",
    "            'job_id': job_row['job_id'],\n",
    "            'job_title': job_row['role_title'],\n",
    "            'candidate_name': candidates_data.iloc[candidate_index]['Name'],\n",
    "            'candidate_email': candidates_data.iloc[candidate_index]['Email'],\n",
    "            'relevancy_score': score\n",
    "        })\n",
    "\n",
    "detailed_df = pd.DataFrame(detailed_rows)\n",
    "detailed_df.to_csv('detailed_job_relevancy_scores.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e61ac6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\3958888228.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed job relevancy scores saved to 'detailed_job_relevancy_scores.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the CSV files\n",
    "candidates_data = pd.read_csv(\"C:/Users/hsahn/OneDrive/Desktop/all_resumes_data.csv\")\n",
    "job_details_data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details_with_predictions.csv\")\n",
    "\n",
    "# List of columns with JSON data in candidate data\n",
    "json_columns = ['Experiences', 'Projects', 'Achievements', 'Certifications', 'HardSkills', 'SoftSkills', 'RecommendedJobDomains']\n",
    "\n",
    "# Parse JSON columns in candidate data\n",
    "for column in json_columns:\n",
    "    candidates_data[column] = candidates_data[column].apply(json.loads)\n",
    "\n",
    "# Helper function to safely extract text from JSON fields\n",
    "def extract_text_from_json(json_field, key):\n",
    "    if isinstance(json_field, list):\n",
    "        return ' '.join([str(item[key]) for item in json_field if key in item])\n",
    "    return ''\n",
    "\n",
    "# Combine relevant text fields into a single text string for each candidate\n",
    "def combine_skills(row):\n",
    "    hard_skills = ' '.join([skill['skill'] for skill in row['HardSkills']])\n",
    "    soft_skills = ' '.join([str(skill) for skill in row['SoftSkills']])\n",
    "    experiences = extract_text_from_json(row['Experiences'], 'description')\n",
    "    projects = extract_text_from_json(row['Projects'], 'description')\n",
    "    achievements = extract_text_from_json(row['Achievements'], 'achievement')\n",
    "    certifications = extract_text_from_json(row['Certifications'], 'name')\n",
    "    combined_text = f\"{hard_skills} {soft_skills} {experiences} {projects} {achievements} {certifications}\"\n",
    "    return combined_text\n",
    "\n",
    "candidates_data['combined_skills'] = candidates_data.apply(combine_skills, axis=1)\n",
    "\n",
    "# Combine relevant text fields for job roles\n",
    "job_details_data['combined_job_text'] = job_details_data.apply(lambda row: f\"{row['role_description']} {row['requirement']}\", axis=1)\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Combine all texts for fitting the TF-IDF vectorizer\n",
    "all_texts = candidates_data['combined_skills'].tolist() + job_details_data['combined_job_text'].tolist()\n",
    "\n",
    "# Fit and transform the text data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(all_texts)\n",
    "\n",
    "# Split the TF-IDF matrix into candidates' skills and job roles\n",
    "candidates_matrix = tfidf_matrix[:len(candidates_data)]\n",
    "jobs_matrix = tfidf_matrix[len(candidates_data):]\n",
    "\n",
    "# Create a DataFrame to store relevancy scores\n",
    "relevancy_scores = pd.DataFrame(index=candidates_data.index)\n",
    "\n",
    "# Compute cosine similarity between each candidate's skills and each job role\n",
    "for job_index in job_details_data.index:\n",
    "    job_vector = jobs_matrix[job_index]\n",
    "    similarity_scores = cosine_similarity(candidates_matrix, job_vector)\n",
    "    relevancy_scores[job_index] = similarity_scores.flatten()\n",
    "\n",
    "# Initialize an empty list to store data for detailed CSV\n",
    "detailed_rows = []\n",
    "\n",
    "# Iterate through each job index in job_details_data\n",
    "for job_index, job_row in job_details_data.iterrows():\n",
    "    # Extract the top candidate indexes and scores for this job\n",
    "    top_candidates = relevancy_scores[job_index].nlargest(len(candidates_data))\n",
    "    \n",
    "    # Iterate through the top candidates and store detailed information\n",
    "    for candidate_index, score in zip(top_candidates.index, top_candidates):\n",
    "        detailed_rows.append({\n",
    "            'job_id': job_row['job_id'],\n",
    "            'job_title': job_row['role_title'],\n",
    "            'candidate_name': candidates_data.iloc[candidate_index]['Name'],\n",
    "            'candidate_email': candidates_data.iloc[candidate_index]['Email'],\n",
    "            'relevancy_score': score\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from detailed_rows\n",
    "detailed_df = pd.DataFrame(detailed_rows)\n",
    "\n",
    "# Save the detailed DataFrame to CSV\n",
    "detailed_df.to_csv('C:/Users/hsahn/Downloads/detailed_job_relevancy_scores.csv', index=False)\n",
    "\n",
    "# Optionally, print a message indicating successful CSV creation\n",
    "print(\"Detailed job relevancy scores saved to 'detailed_job_relevancy_scores.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70b1378",
   "metadata": {},
   "source": [
    "# Relevancy Score Calculation \n",
    "In the provided code, the relevance score between candidates and job roles is calculated using **cosine similarity**. Here’s a breakdown of how cosine similarity is applied in this context:\n",
    "\n",
    "### Cosine Similarity Calculation\n",
    "\n",
    "1. **TF-IDF Vectorization**:\n",
    "   - The combined texts from candidates' skills and job descriptions are vectorized using `TfidfVectorizer`. This converts text data into numerical vectors based on the Term Frequency-Inverse Document Frequency (TF-IDF) values.\n",
    "   - `fit_transform(all_texts)` is used to fit the vectorizer on all combined texts (`all_texts`) and transform them into TF-IDF weighted vectors.\n",
    "\n",
    "2. **Matrix Splitting**:\n",
    "   - After vectorization, the TF-IDF matrix (`tfidf_matrix`) is split into two parts:\n",
    "     - `candidates_matrix`: Contains TF-IDF vectors for candidates' combined skills.\n",
    "     - `jobs_matrix`: Contains TF-IDF vectors for job descriptions.\n",
    "\n",
    "3. **Cosine Similarity Computation**:\n",
    "   - For each job role (`job_index`), the corresponding vector from `jobs_matrix` is selected (`job_vector`).\n",
    "   - Cosine similarity between the `job_vector` and all vectors in `candidates_matrix` is computed using `cosine_similarity(candidates_matrix, job_vector)`.\n",
    "   - This results in a similarity score for each candidate with respect to the job role.\n",
    "\n",
    "4. **Relevance Scores Storage**:\n",
    "   - The computed similarity scores are stored in the `relevancy_scores` DataFrame, where each column corresponds to a job role (`job_index`) and each row corresponds to a candidate.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **Cosine Similarity**: Measures the cosine of the angle between two non-zero vectors in an n-dimensional space. In this case, it quantifies the similarity between the TF-IDF vectors of candidates' skills and job requirements.\n",
    "- **Higher Scores**: Indicate greater similarity between a candidate’s skills profile and the requirements of a job role.\n",
    "- **Implementation in Code**: The use of `cosine_similarity` from `sklearn.metrics.pairwise` allows efficient calculation across multiple candidates and job roles.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This method leverages TF-IDF vectorization and cosine similarity to provide a numerical measure of how well candidates match each job role based on their skills and the job requirements. Adjustments to the vectorization parameters or similarity metrics can further tailor the relevance scoring based on specific needs or domain knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efead318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n",
      "C:\\Users\\hsahn\\AppData\\Local\\Temp\\ipykernel_15484\\604258976.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  relevancy_scores[job_index] = similarity_scores.flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed job relevancy scores saved to 'detailed_job_relevancy_scores.json.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "candidates_data = pd.read_csv(\"C:/Users/hsahn/OneDrive/Desktop/all_resumes_data.csv\")\n",
    "job_details_data = pd.read_csv(\"C:/Users/hsahn/Downloads/job_details_with_predictions.csv\")\n",
    "\n",
    "json_columns = ['Experiences', 'Projects', 'Achievements', 'Certifications', 'HardSkills', 'SoftSkills', 'RecommendedJobDomains']\n",
    "\n",
    "for column in json_columns:\n",
    "    candidates_data[column] = candidates_data[column].apply(json.loads)\n",
    "\n",
    "def extract_text_from_json(json_field, key):\n",
    "    if isinstance(json_field, list):\n",
    "        return ' '.join([str(item[key]) for item in json_field if key in item])\n",
    "    return ''\n",
    "\n",
    "def combine_skills(row):\n",
    "    hard_skills = ' '.join([skill['skill'] for skill in row['HardSkills']])\n",
    "    soft_skills = ' '.join([str(skill) for skill in row['SoftSkills']])\n",
    "    experiences = extract_text_from_json(row['Experiences'], 'description')\n",
    "    projects = extract_text_from_json(row['Projects'], 'description')\n",
    "    achievements = extract_text_from_json(row['Achievements'], 'achievement')\n",
    "    certifications = extract_text_from_json(row['Certifications'], 'name')\n",
    "    combined_text = f\"{hard_skills} {soft_skills} {experiences} {projects} {achievements} {certifications}\"\n",
    "    return combined_text\n",
    "\n",
    "candidates_data['combined_skills'] = candidates_data.apply(combine_skills, axis=1)\n",
    "\n",
    "job_details_data['combined_job_text'] = job_details_data.apply(lambda row: f\"{row['role_description']} {row['requirement']}\", axis=1)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "all_texts = candidates_data['combined_skills'].tolist() + job_details_data['combined_job_text'].tolist()\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(all_texts)\n",
    "\n",
    "candidates_matrix = tfidf_matrix[:len(candidates_data)]\n",
    "jobs_matrix = tfidf_matrix[len(candidates_data):]\n",
    "\n",
    "relevancy_scores = pd.DataFrame(index=candidates_data.index)\n",
    "\n",
    "for job_index in job_details_data.index:\n",
    "    job_vector = jobs_matrix[job_index]\n",
    "    similarity_scores = cosine_similarity(candidates_matrix, job_vector)\n",
    "    relevancy_scores[job_index] = similarity_scores.flatten()\n",
    "\n",
    "detailed_rows = []\n",
    "\n",
    "for job_index, job_row in job_details_data.iterrows():\n",
    "    top_candidates = relevancy_scores[job_index].nlargest(len(candidates_data))\n",
    "    \n",
    "    candidates_list = []\n",
    "    \n",
    "    for candidate_index, score in zip(top_candidates.index, top_candidates):\n",
    "        candidate_details = {\n",
    "            'candidate_name': candidates_data.iloc[candidate_index]['Name'],\n",
    "            'candidate_email': candidates_data.iloc[candidate_index]['Email'],\n",
    "            'relevancy_score': score\n",
    "        }\n",
    "        candidates_list.append(candidate_details)\n",
    "    \n",
    "    detailed_rows.append({\n",
    "        'job_id': job_row['job_id'],\n",
    "        'job_title': job_row['role_title'],\n",
    "        'candidates': json.dumps(candidates_list)\n",
    "    })\n",
    "\n",
    "detailed_df = pd.DataFrame(detailed_rows)\n",
    "\n",
    "detailed_df.to_csv('C:/Users/hsahn/Downloads/detailed_job_relevancy_scores.json.csv', index=False)\n",
    "\n",
    "print(\"Detailed job relevancy scores saved to 'detailed_job_relevancy_scores.json.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7a9506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e3b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
